!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
ARUCO_CFG	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    ARUCO_CFG = pickle.load(config_dict_file)  # Load the aruco board settings$/;"	kind:variable	line:111
ARUCO_DICT	../panda_autograsp/scripts/aruco_pose_estimation.py	/^ARUCO_DICT = aruco.Dictionary_get(config_dict["ARUCO_DICT_TYPE"])$/;"	kind:variable	line:68
ARUCO_DICT	../panda_autograsp/scripts/generate_arucoboard.py	/^    ARUCO_DICT = aruco.Dictionary_get(ARUCO_DICT_TYPE)$/;"	kind:variable	line:89
ARUCO_DICT	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^ARUCO_DICT = aruco.Dictionary_get(ARUCO_CFG["ARUCO_DICT_TYPE"])$/;"	kind:variable	line:116
ARUCO_DICT_TYPE	../panda_autograsp/scripts/generate_arucoboard.py	/^ARUCO_DICT_TYPE = aruco.DICT_6X6_50  # [ROWSxCOLUMNS_LIBRARY_SIZE]$/;"	kind:variable	line:44
ARUCO_PARAMETERS	../panda_autograsp/scripts/aruco_pose_estimation.py	/^ARUCO_PARAMETERS = aruco.DetectorParameters_create()$/;"	kind:variable	line:76
AUTO	../perception/perception/kinect2_sensor.py	/^    AUTO = 3$/;"	kind:variable	line:37
Action	../gqcnn/gqcnn/grasping/actions.py	/^class Action(with_metaclass(ABCMeta, object)):$/;"	kind:class	line:45
AlexNet	../perception/perception/cnn.py	/^class AlexNet(object):$/;"	kind:class	line:33
AlexNetWeights	../perception/perception/cnn.py	/^class AlexNetWeights(object):$/;"	kind:class	line:9
AntipodalDepthImageGraspSampler	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^class AntipodalDepthImageGraspSampler(ImageGraspSampler):$/;"	kind:class	line:181
ApproachPlanaritySuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class ApproachPlanaritySuctionQualityFunction(SuctionQualityFunction):$/;"	kind:class	line:355
Arcball	../autolab_core/autolab_core/transformations.py	/^class Arcball(object):$/;"	kind:class	line:1356
ArtificialRV	../autolab_core/autolab_core/random_variables.py	/^class ArtificialRV(RandomVariable):$/;"	kind:class	line:153
ArtificialSingleRV	../autolab_core/autolab_core/random_variables.py	/^class ArtificialSingleRV(ArtificialRV):$/;"	kind:class	line:187
BERKLEY_SAVE	../panda_autograsp/scripts/chessboard_calibration.py	/^    BERKLEY_SAVE = os.path.abspath($/;"	kind:variable	line:121
BINARY	../gqcnn/gqcnn/utils/enums.py	/^    BINARY = "binary"$/;"	kind:variable	line:54
BINARY_IM_DEFAULT_THRESH	../perception/perception/image.py	/^BINARY_IM_DEFAULT_THRESH = BINARY_IM_MAX_VAL \/ 2$/;"	kind:variable	line:35
BINARY_IM_MAX_VAL	../perception/perception/image.py	/^BINARY_IM_MAX_VAL = np.iinfo(np.uint8).max$/;"	kind:variable	line:34
BINARY_TF	../gqcnn/gqcnn/utils/enums.py	/^    BINARY_TF = "binary_tf"$/;"	kind:variable	line:56
BINARY_THRESH	../perception/tests/constants.py	/^BINARY_THRESH = 127$/;"	kind:variable	line:5
BagOfFeatures	../perception/perception/features.py	/^class BagOfFeatures:$/;"	kind:class	line:94
BagOfPoints	../autolab_core/autolab_core/points.py	/^class BagOfPoints(object):$/;"	kind:class	line:12
BagOfVectors	../autolab_core/autolab_core/points.py	/^class BagOfVectors(BagOfPoints):$/;"	kind:class	line:191
BernoulliRV	../autolab_core/autolab_core/random_variables.py	/^class BernoulliRV(RandomVariable):$/;"	kind:class	line:83
BestFitPlanaritySuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class BestFitPlanaritySuctionQualityFunction(SuctionQualityFunction):$/;"	kind:class	line:267
BinaryClassificationResult	../autolab_core/autolab_core/learning_analysis.py	/^class BinaryClassificationResult(ClassificationResult):$/;"	kind:class	line:351
BinaryImage	../perception/perception/image.py	/^class BinaryImage(Image):$/;"	kind:class	line:2155
Box	../autolab_core/autolab_core/primitives.py	/^class Box(object):$/;"	kind:class	line:7
Box	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^class Box(object):$/;"	kind:class	line:14
CABLIB_METHODS	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^CABLIB_METHODS = ["chessboard", "aruco_board"]$/;"	kind:variable	line:87
CALIB_TRY_DURATION	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^CALIB_TRY_DURATION = MAIN_CFG["calibration"]["calib_try_duration"]  # [s]$/;"	kind:variable	line:86
CAMERA_INTR_FIELD	../perception/perception/camera_sensor.py	/^    CAMERA_INTR_FIELD = 'camera_intrs'$/;"	kind:variable	line:247
CAMERA_POSE_SAVE	../panda_autograsp/scripts/chessboard_calibration.py	/^    CAMERA_POSE_SAVE = os.path.abspath($/;"	kind:variable	line:124
CENTER_X	../perception/perception/primesense_sensor.py	/^    CENTER_X = float(DEPTH_IM_WIDTH-1) \/ 2.0$/;"	kind:variable	line:32
CENTER_Y	../perception/perception/primesense_sensor.py	/^    CENTER_Y = float(DEPTH_IM_HEIGHT-1) \/ 2.0$/;"	kind:variable	line:33
CHANNELS	../autolab_core/tests/test_dataset.py	/^CHANNELS = 3$/;"	kind:variable	line:43
CLASSIFICATION	../gqcnn/gqcnn/utils/enums.py	/^    CLASSIFICATION = "classification"$/;"	kind:variable	line:66
CLUSTER_TOL	../gqcnn/examples/policy_with_image_proc.py	/^CLUSTER_TOL = 0.0015$/;"	kind:variable	line:52
CNNBatchFeatureExtractor	../perception/perception/feature_extractors.py	/^class CNNBatchFeatureExtractor(FeatureExtractor):$/;"	kind:class	line:32
CNNReusableBatchFeatureExtractor	../perception/perception/feature_extractors.py	/^class CNNReusableBatchFeatureExtractor(CNNBatchFeatureExtractor):$/;"	kind:class	line:98
COLLISION_OBJ_CFG	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^COLLISION_OBJ_CFG = YamlConfig($/;"	kind:variable	line:72
COLLISION_OBJ_TYPES	../panda_autograsp/src/panda_autograsp/functions/moveit.py	/^COLLISION_OBJ_TYPES = ["box", "plane", "cylinder", "sphere", "mesh"]$/;"	kind:variable	line:25
COLOR	../perception/perception/object_render.py	/^    COLOR = 'color'$/;"	kind:variable	line:15
COLOR_DEPTH	../perception/perception/kinect2_sensor.py	/^    COLOR_DEPTH = 0$/;"	kind:variable	line:42
COLOR_DEPTH_IR	../perception/perception/kinect2_sensor.py	/^    COLOR_DEPTH_IR = 1$/;"	kind:variable	line:43
COLOR_IMAGE_EXTS	../perception/perception/constants.py	/^COLOR_IMAGE_EXTS = ['.png', '.jpg']$/;"	kind:variable	line:7
COLOR_IM_FIELD	../perception/perception/camera_sensor.py	/^    COLOR_IM_FIELD = 'color_ims'$/;"	kind:variable	line:248
COLOR_IM_FILEROOT	../perception/tests/constants.py	/^COLOR_IM_FILEROOT = 'data\/test_color'$/;"	kind:variable	line:6
COLOR_IM_HEIGHT	../perception/perception/kinect2_sensor.py	/^    COLOR_IM_HEIGHT = 1080$/;"	kind:variable	line:71
COLOR_IM_HEIGHT	../perception/perception/primesense_sensor.py	/^    COLOR_IM_HEIGHT = 480$/;"	kind:variable	line:28
COLOR_IM_HEIGHT	../perception/perception/realsense_sensor.py	/^    COLOR_IM_HEIGHT = 480$/;"	kind:variable	line:42
COLOR_IM_WIDTH	../perception/perception/kinect2_sensor.py	/^    COLOR_IM_WIDTH = 1920$/;"	kind:variable	line:72
COLOR_IM_WIDTH	../perception/perception/primesense_sensor.py	/^    COLOR_IM_WIDTH = 640$/;"	kind:variable	line:29
COLOR_IM_WIDTH	../perception/perception/realsense_sensor.py	/^    COLOR_IM_WIDTH = 640$/;"	kind:variable	line:43
COLOR_TF	../gqcnn/gqcnn/utils/enums.py	/^    COLOR_TF = "color_tf"$/;"	kind:variable	line:57
COLOR_TO_DEPTH	../perception/perception/kinect2_sensor.py	/^    COLOR_TO_DEPTH = 1$/;"	kind:variable	line:49
COMPRESSED_TENSOR_EXT	../autolab_core/autolab_core/tensor_dataset.py	/^COMPRESSED_TENSOR_EXT = '.npz'$/;"	kind:variable	line:39
CPU	../perception/perception/kinect2_sensor.py	/^    CPU = 1$/;"	kind:variable	line:35
CPU_LOAD_OFFSET	../gqcnn/gqcnn/search/resource_manager.py	/^CPU_LOAD_OFFSET = 50$/;"	kind:variable	line:49
CPU_LOAD_SAMPLE_INTERVAL	../gqcnn/gqcnn/search/resource_manager.py	/^CPU_LOAD_SAMPLE_INTERVAL = 4.0$/;"	kind:variable	line:46
CSVModel	../autolab_core/autolab_core/csv_model.py	/^class CSVModel:$/;"	kind:class	line:7
CalibFrames.cfg	../panda_autograsp/cfg/CalibFrames.cfg	1;"	kind:file	line:1
CameraChessboardRegistration	../perception/perception/chessboard_registration.py	/^class CameraChessboardRegistration:$/;"	kind:class	line:29
CameraIntrinsics	../perception/perception/camera_intrinsics.py	/^class CameraIntrinsics(object):$/;"	kind:class	line:16
CameraSensor	../perception/perception/camera_sensor.py	/^class CameraSensor(object):$/;"	kind:class	line:13
ChessboardRegistrationResult	../perception/perception/chessboard_registration.py	/^class ChessboardRegistrationResult(object):$/;"	kind:class	line:15
ClassificationResult	../autolab_core/autolab_core/learning_analysis.py	/^class ClassificationResult(object):$/;"	kind:class	line:46
ColorImage	../perception/perception/image.py	/^class ColorImage(Image):$/;"	kind:class	line:984
ColorizedPhoXiSensor	../perception/perception/colorized_phoxi_sensor.py	/^class ColorizedPhoXiSensor(CameraSensor):$/;"	kind:class	line:9
ComApproachPlanaritySuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^        ApproachPlanaritySuctionQualityFunction):$/;"	kind:class	line:606
ComDiscApproachPlanaritySuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^        DiscApproachPlanaritySuctionQualityFunction):$/;"	kind:class	line:670
ComDiscCurvatureSuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^        DiscCurvatureSuctionQualityFunction):$/;"	kind:class	line:856
ComForceClosureParallelJawQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class ComForceClosureParallelJawQualityFunction(ParallelJawQualityFunction):$/;"	kind:class	line:143
Completer	../autolab_core/autolab_core/completer.py	/^class Completer(object):$/;"	kind:class	line:11
CompositeGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class CompositeGraspingPolicy(Policy):$/;"	kind:class	line:1527
ConfusionMatrix	../autolab_core/autolab_core/learning_analysis.py	/^class ConfusionMatrix(object):$/;"	kind:class	line:33
Contour	../autolab_core/autolab_core/primitives.py	/^class Contour(object):$/;"	kind:class	line:120
Correspondences	../perception/perception/feature_matcher.py	/^class Correspondences:$/;"	kind:class	line:14
CrossEntropyRobustGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class CrossEntropyRobustGraspingPolicy(GraspingPolicy):$/;"	kind:class	line:678
Cylinder	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^class Cylinder(object):$/;"	kind:class	line:205
DATAPOINTS_PER_FILE	../autolab_core/tests/test_dataset.py	/^DATAPOINTS_PER_FILE = 10$/;"	kind:variable	line:44
DATA_SAVE_FOLDER	../panda_autograsp/scripts/kinect_processing.py	/^DATA_SAVE_FOLDER = os.path.abspath($/;"	kind:variable	line:41
DEFAULT_DOWNLOAD_SCRIPT_PATH	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^DEFAULT_DOWNLOAD_SCRIPT_PATH = os.path.abspath($/;"	kind:variable	line:46
DEFAULT_MODEL	../panda_autograsp/nodes/grasp_planner_server.py	/^    DEFAULT_MODEL = MAIN_CFG["grasp_detection"][DEFAULT_SOLUTION]["defaults"]["model"]$/;"	kind:variable	line:71
DEFAULT_MODEL	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^DEFAULT_MODEL = MAIN_CFG["grasp_detection"][GRASP_SOLUTION]["defaults"]["model"]$/;"	kind:variable	line:81
DEFAULT_MODELS_PATH	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^DEFAULT_MODELS_PATH = os.path.abspath($/;"	kind:variable	line:39
DEFAULT_RESNET50_WEIGHTS	../perception/tools/keras_resnet.py	/^DEFAULT_RESNET50_WEIGHTS = '\/home\/autolab\/Public\/data\/dex-net\/data\/models\/classification\/resnet50\/weights.h5'$/;"	kind:variable	line:15
DEFAULT_SOLUTION	../panda_autograsp/nodes/grasp_planner_server.py	/^    DEFAULT_SOLUTION = MAIN_CFG["main"]["solution"]$/;"	kind:variable	line:70
DEFAULT_VGG16_WEIGHTS	../perception/tools/keras_vgg.py	/^DEFAULT_VGG16_WEIGHTS = '\/home\/autolab\/Public\/data\/dex-net\/data\/models\/classification\/vgg16\/weights.h5'$/;"	kind:variable	line:15
DEPTH	../gqcnn/gqcnn/utils/enums.py	/^    DEPTH = "depth"$/;"	kind:variable	line:55
DEPTH	../perception/perception/object_render.py	/^    DEPTH = 'depth'$/;"	kind:variable	line:13
DEPTH_IM_FIELD	../perception/perception/camera_sensor.py	/^    DEPTH_IM_FIELD = 'depth_ims'$/;"	kind:variable	line:249
DEPTH_IM_HEIGHT	../perception/perception/kinect2_sensor.py	/^    DEPTH_IM_HEIGHT = 424$/;"	kind:variable	line:73
DEPTH_IM_HEIGHT	../perception/perception/primesense_sensor.py	/^    DEPTH_IM_HEIGHT = 480$/;"	kind:variable	line:30
DEPTH_IM_HEIGHT	../perception/perception/realsense_sensor.py	/^    DEPTH_IM_HEIGHT = 480$/;"	kind:variable	line:44
DEPTH_IM_WIDTH	../perception/perception/kinect2_sensor.py	/^    DEPTH_IM_WIDTH = 512$/;"	kind:variable	line:74
DEPTH_IM_WIDTH	../perception/perception/primesense_sensor.py	/^    DEPTH_IM_WIDTH = 640$/;"	kind:variable	line:31
DEPTH_IM_WIDTH	../perception/perception/realsense_sensor.py	/^    DEPTH_IM_WIDTH = 640$/;"	kind:variable	line:45
DEPTH_TF	../gqcnn/gqcnn/utils/enums.py	/^    DEPTH_TF = "depth_tf"$/;"	kind:variable	line:59
DEPTH_TF_TABLE	../gqcnn/gqcnn/utils/enums.py	/^    DEPTH_TF_TABLE = "depth_tf_table"$/;"	kind:variable	line:60
DEPTH_TO_COLOR	../perception/perception/primesense_sensor.py	/^    DEPTH_TO_COLOR = 1$/;"	kind:variable	line:22
DEPTH_TO_COLOR	../perception/perception/realsense_sensor.py	/^    DEPTH_TO_COLOR = 1$/;"	kind:variable	line:18
DOWNLOAD_SCRIPT_PATH	../panda_autograsp/nodes/grasp_planner_server.py	/^    DOWNLOAD_SCRIPT_PATH = os.path.abspath($/;"	kind:variable	line:79
DOWNLOAD_SCRIPT_PATH	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^DOWNLOAD_SCRIPT_PATH = os.path.abspath($/;"	kind:variable	line:89
DataStreamRecorder	../autolab_core/autolab_core/data_stream_recorder.py	/^class DataStreamRecorder(Process):$/;"	kind:class	line:48
DataStreamSyncer	../autolab_core/autolab_core/data_stream_syncer.py	/^class DataStreamSyncer:$/;"	kind:class	line:89
DepthImage	../perception/perception/image.py	/^class DepthImage(Image):$/;"	kind:class	line:1482
DepthImageMultiSuctionPointSampler	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^class DepthImageMultiSuctionPointSampler(ImageGraspSampler):$/;"	kind:class	line:824
DepthImageSuctionPointSampler	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^class DepthImageSuctionPointSampler(ImageGraspSampler):$/;"	kind:class	line:602
DepthSamplingMode	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^class DepthSamplingMode(object):$/;"	kind:class	line:70
DevelopCmd	../gqcnn/setup.py	/^class DevelopCmd(develop):$/;"	kind:class	line:73
DevelopCmd	../panda_autograsp/setup.py	/^class DevelopCmd(develop):$/;"	kind:class	line:134
DevelopCmd	../setup.py	/^class DevelopCmd(develop):$/;"	kind:class	line:264
Direction	../autolab_core/autolab_core/points.py	/^class Direction(BagOfVectors):$/;"	kind:class	line:394
DiscApproachPlanaritySuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class DiscApproachPlanaritySuctionQualityFunction(SuctionQualityFunction):$/;"	kind:class	line:461
DiscCurvatureSuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^        GaussianCurvatureSuctionQualityFunction):$/;"	kind:class	line:824
DiscreteApproachGraspConstraintFn	../gqcnn/gqcnn/grasping/constraint_fn.py	/^class DiscreteApproachGraspConstraintFn(GraspConstraintFn):$/;"	kind:class	line:80
DistMetrics	../autolab_core/autolab_core/dist_metrics.py	/^DistMetrics = {$/;"	kind:variable	line:26
DualQuaternion	../autolab_core/autolab_core/dual_quaternion.py	/^class DualQuaternion(object):$/;"	kind:class	line:12
EEF_STEP	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^EEF_STEP = MAIN_CFG["planning"]["cartesian"]["eef_step"]$/;"	kind:variable	line:68
EXCEPTION	../gqcnn/gqcnn/search/trial.py	/^    EXCEPTION = "exception"$/;"	kind:variable	line:54
EnsensoSensor	../perception/perception/ensenso_sensor.py	/^class EnsensoSensor(CameraSensor):$/;"	kind:class	line:24
EpsilonGreedyQFunctionRobustGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^                                                 ):$/;"	kind:class	line:1402
ExperimentLogger	../autolab_core/autolab_core/experiment_logger.py	/^class ExperimentLogger:$/;"	kind:class	line:20
FACTORY	../panda_autograsp/scripts/chessboard_calibration.py	/^FACTORY = True  # Use libfreenect2 factory camera parameters$/;"	kind:variable	line:42
FCGQCNNTF	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^class FCGQCNNTF(GQCNNTF):$/;"	kind:class	line:45
FCGQCnnQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class FCGQCnnQualityFunction(GraspQualityFunction):$/;"	kind:class	line:1238
FIGSIZE	../gqcnn/gqcnn/utils/enums.py	/^    FIGSIZE = 16  # For visualization.$/;"	kind:variable	line:49
FILE_PATH	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^FILE_PATH = os.path.abspath(os.path.dirname(os.path.realpath(__file__)))$/;"	kind:variable	line:61
FINAL_MODEL	../gqcnn/gqcnn/utils/enums.py	/^    FINAL_MODEL = "model.ckpt"$/;"	kind:variable	line:118
FINISHED	../gqcnn/gqcnn/search/trial.py	/^    FINISHED = "finished"$/;"	kind:variable	line:53
FOCAL_X	../perception/perception/primesense_sensor.py	/^    FOCAL_X = 525.$/;"	kind:variable	line:34
FOCAL_Y	../perception/perception/primesense_sensor.py	/^    FOCAL_Y = 525.$/;"	kind:variable	line:35
FPS	../perception/perception/primesense_sensor.py	/^    FPS = 30$/;"	kind:variable	line:36
FPS	../perception/perception/realsense_sensor.py	/^    FPS = 30$/;"	kind:variable	line:46
FULL_SCREEN	../panda_autograsp/scripts/aruco_pose_estimation.py	/^FULL_SCREEN = False  # Open result on full screen$/;"	kind:variable	line:38
FULL_SCREEN	../panda_autograsp/scripts/chessboard_calibration.py	/^FULL_SCREEN = True  # full screen$/;"	kind:variable	line:41
Feature	../perception/perception/features.py	/^class Feature:$/;"	kind:class	line:9
FeatureExtractor	../perception/perception/feature_extractors.py	/^class FeatureExtractor:$/;"	kind:class	line:15
FeatureMatcher	../perception/perception/feature_matcher.py	/^class FeatureMatcher:$/;"	kind:class	line:101
FullyConvolutionalGraspingPolicy	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^                                                      GraspingPolicy)):$/;"	kind:class	line:54
FullyConvolutionalGraspingPolicyParallelJaw	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^        FullyConvolutionalGraspingPolicy):$/;"	kind:class	line:356
FullyConvolutionalGraspingPolicySuction	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^                                              ):$/;"	kind:class	line:445
GD	../perception/perception/object_render.py	/^    GD = 'gd'$/;"	kind:variable	line:17
GD	../perception/perception/object_render.py	/^    GD = 'gd'$/;"	kind:variable	line:19
GPU_STAT_NUM_SAMPLES	../gqcnn/gqcnn/search/resource_manager.py	/^GPU_STAT_NUM_SAMPLES = 4$/;"	kind:variable	line:50
GPU_STAT_SAMPLE_INTERVAL	../gqcnn/gqcnn/search/resource_manager.py	/^GPU_STAT_SAMPLE_INTERVAL = 1.0$/;"	kind:variable	line:51
GQCNNAnalyzer	../gqcnn/gqcnn/analysis/analyzer.py	/^class GQCNNAnalyzer(object):$/;"	kind:class	line:57
GQCNNFilenames	../gqcnn/gqcnn/utils/enums.py	/^class GQCNNFilenames(object):$/;"	kind:class	line:94
GQCNNFineTuningAndAnalysisTrial	../gqcnn/gqcnn/search/trial.py	/^class GQCNNFineTuningAndAnalysisTrial(GQCNNTrialWithAnalysis):$/;"	kind:class	line:210
GQCNNGrasp	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^class GQCNNGrasp(object):$/;"	kind:class	line:101
GQCNNSearch	../gqcnn/gqcnn/search/search.py	/^class GQCNNSearch(object):$/;"	kind:class	line:56
GQCNNTF	../gqcnn/gqcnn/model/tf/network_tf.py	/^class GQCNNTF(object):$/;"	kind:class	line:60
GQCNNTrainerTF	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^class GQCNNTrainerTF(object):$/;"	kind:class	line:69
GQCNNTrainingAndAnalysisTrial	../gqcnn/gqcnn/search/trial.py	/^class GQCNNTrainingAndAnalysisTrial(GQCNNTrialWithAnalysis):$/;"	kind:class	line:205
GQCNNTrainingStatus	../gqcnn/gqcnn/utils/enums.py	/^class GQCNNTrainingStatus(object):$/;"	kind:class	line:87
GQCNNTrialWithAnalysis	../gqcnn/gqcnn/search/trial.py	/^class GQCNNTrialWithAnalysis(with_metaclass(ABCMeta, object)):$/;"	kind:class	line:57
GQCNNWeights	../gqcnn/gqcnn/model/tf/network_tf.py	/^class GQCNNWeights(object):$/;"	kind:class	line:53
GQCnnQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class GQCnnQualityFunction(GraspQualityFunction):$/;"	kind:class	line:919
GRASP_SOLUTION	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^GRASP_SOLUTION = "gqcnn"$/;"	kind:variable	line:80
GRAY	../perception/perception/object_render.py	/^    GRAY = 'gray'$/;"	kind:variable	line:16
GRAYSCALE	../perception/perception/object_render.py	/^    GRAYSCALE = 'gray'$/;"	kind:variable	line:20
GRAY_TF	../gqcnn/gqcnn/utils/enums.py	/^    GRAY_TF = "gray_tf"$/;"	kind:variable	line:58
GUI_PAUSE	../perception/tools/capture_dataset.py	/^GUI_PAUSE = 0.5$/;"	kind:variable	line:29
GaussianCurvatureSuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class GaussianCurvatureSuctionQualityFunction(SuctionQualityFunction):$/;"	kind:class	line:750
GaussianRV	../autolab_core/autolab_core/random_variables.py	/^class GaussianRV(RandomVariable):$/;"	kind:class	line:117
GaussianRigidTransformRandomVariable	../autolab_core/autolab_core/random_variables.py	/^class GaussianRigidTransformRandomVariable(RandomVariable):$/;"	kind:class	line:200
GdImage	../perception/perception/image.py	/^class GdImage(Image):$/;"	kind:class	line:3078
GeneralConstants	../gqcnn/gqcnn/utils/enums.py	/^class GeneralConstants(object):$/;"	kind:class	line:41
GlobalFeature	../perception/perception/features.py	/^class GlobalFeature(Feature):$/;"	kind:class	line:53
Grasp2D	../gqcnn/gqcnn/grasping/grasp.py	/^class Grasp2D(object):$/;"	kind:class	line:41
GraspAction	../gqcnn/gqcnn/grasping/policy/policy.py	/^class GraspAction(object):$/;"	kind:class	line:156
GraspAction3D	../gqcnn/gqcnn/grasping/actions.py	/^class GraspAction3D(with_metaclass(ABCMeta, Action)):$/;"	kind:class	line:81
GraspConstraintFn	../gqcnn/gqcnn/grasping/constraint_fn.py	/^class GraspConstraintFn(with_metaclass(ABCMeta, object)):$/;"	kind:class	line:41
GraspConstraintFnFactory	../gqcnn/gqcnn/grasping/constraint_fn.py	/^class GraspConstraintFnFactory(object):$/;"	kind:class	line:124
GraspPlanner	../gqcnn/ros_nodes/grasp_planner_node.py	/^class GraspPlanner(object):$/;"	kind:class	line:60
GraspPlanner	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^class GraspPlanner(object):$/;"	kind:class	line:131
GraspPlannerROS	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^class GraspPlannerROS(object):$/;"	kind:class	line:46
GraspQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class GraspQualityFunction(with_metaclass(ABCMeta, object)):$/;"	kind:class	line:53
GraspQualityFunctionFactory	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class GraspQualityFunctionFactory(object):$/;"	kind:class	line:1277
GraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class GraspingPolicy(with_metaclass(ABCMeta, Policy)):$/;"	kind:class	line:236
GrayscaleImage	../perception/perception/image.py	/^class GrayscaleImage(Image):$/;"	kind:class	line:2039
GreedyCompositeGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class GreedyCompositeGraspingPolicy(CompositeGraspingPolicy):$/;"	kind:class	line:1622
GripperMode	../gqcnn/gqcnn/utils/enums.py	/^class GripperMode(object):$/;"	kind:class	line:71
H	../perception/tools/register_camera.py	/^                    H = est_robot_points_world.data[:,ind].dot(true_robot_points_world.data[:,ind].T)$/;"	kind:variable	line:202
H	../perception/tools/register_camera.py	/^                H = est_robot_points_world.data[:,ind].dot(true_robot_points_world.data[:,ind].T)$/;"	kind:variable	line:188
HD	../perception/perception/kinect2_sensor.py	/^    HD = "hd"$/;"	kind:variable	line:60
HEIGHT	../autolab_core/tests/test_dataset.py	/^HEIGHT = 3$/;"	kind:variable	line:41
IMAGE_FIELDS	../perception/perception/camera_sensor.py	/^    IMAGE_FIELDS = [COLOR_IM_FIELD, DEPTH_IM_FIELD]$/;"	kind:variable	line:250
IM_DEPTH_SUB_MEAN	../gqcnn/gqcnn/utils/enums.py	/^    IM_DEPTH_SUB_MEAN = "im_depth_sub_mean.npy"$/;"	kind:variable	line:113
IM_DEPTH_SUB_STD	../gqcnn/gqcnn/utils/enums.py	/^    IM_DEPTH_SUB_STD = "im_depth_sub_std.npy"$/;"	kind:variable	line:114
IM_HEIGHT	../perception/tests/constants.py	/^IM_HEIGHT = 100$/;"	kind:variable	line:1
IM_MEAN	../gqcnn/gqcnn/utils/enums.py	/^    IM_MEAN = "im_mean.npy"$/;"	kind:variable	line:111
IM_ONLY	../gqcnn/gqcnn/utils/enums.py	/^    IM_ONLY = "im_only"$/;"	kind:variable	line:83
IM_OUT_SIZE	../panda_autograsp/scripts/generate_arucoboard.py	/^IM_OUT_SIZE = (1100, 1681)  # Pixel size == Pattern size$/;"	kind:variable	line:45
IM_STD	../gqcnn/gqcnn/utils/enums.py	/^    IM_STD = "im_std.npy"$/;"	kind:variable	line:112
IM_WIDTH	../perception/tests/constants.py	/^IM_WIDTH = 100$/;"	kind:variable	line:2
INTER_MODEL	../gqcnn/gqcnn/utils/enums.py	/^    INTER_MODEL = "model_{}.ckpt"$/;"	kind:variable	line:119
INTR_EXTENSION	../perception/perception/constants.py	/^INTR_EXTENSION = '.intr'$/;"	kind:variable	line:13
Image	../perception/perception/image.py	/^class Image(object):$/;"	kind:class	line:93
ImageBufferResponse	../perception/ros_nodes/image_buffer.py	/^ImageBufferResponse = rospy.numpy_msg.numpy_msg(ImageBufferResponse)$/;"	kind:variable	line:24
ImageCoords	../autolab_core/autolab_core/points.py	/^class ImageCoords(BagOfPoints):$/;"	kind:class	line:969
ImageGraspSampler	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^class ImageGraspSampler(with_metaclass(ABCMeta, object)):$/;"	kind:class	line:77
ImageGraspSamplerFactory	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^class ImageGraspSamplerFactory(object):$/;"	kind:class	line:1064
ImageMode	../gqcnn/gqcnn/utils/enums.py	/^class ImageMode(object):$/;"	kind:class	line:53
InputDepthMode	../gqcnn/gqcnn/utils/enums.py	/^class InputDepthMode(object):$/;"	kind:class	line:80
InstallCmd	../gqcnn/setup.py	/^class InstallCmd(install, object):$/;"	kind:class	line:108
InstallCmd	../panda_autograsp/setup.py	/^class InstallCmd(install, object):$/;"	kind:class	line:174
InstallCmd	../setup.py	/^class InstallCmd(install, object):$/;"	kind:class	line:307
IrImage	../perception/perception/image.py	/^class IrImage(Image):$/;"	kind:class	line:1935
IsotropicGaussianRigidTransformRandomVariable	../autolab_core/autolab_core/random_variables.py	/^class IsotropicGaussianRigidTransformRandomVariable(GaussianRigidTransformRandomVariable):$/;"	kind:class	line:290
IterativeRegistrationSolver	../perception/perception/point_registration.py	/^class IterativeRegistrationSolver:$/;"	kind:class	line:27
JSON_INDENT	../autolab_core/autolab_core/constants.py	/^JSON_INDENT = 2$/;"	kind:variable	line:28
JUMP_THRESHOLD	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^JUMP_THRESHOLD = MAIN_CFG["planning"]["cartesian"]["jump_threshold"]$/;"	kind:variable	line:69
K	../perception/perception/camera_intrinsics.py	/^    def K(self):$/;"	kind:member	line:130
K	../perception/tools/register_camera.py	/^            K = 25$/;"	kind:variable	line:179
KSIZE	../perception/tools/compute_normal_cloud_im.py	/^KSIZE = 9$/;"	kind:variable	line:19
Kinect2BridgedQuality	../perception/perception/kinect2_sensor.py	/^class Kinect2BridgedQuality:$/;"	kind:class	line:57
Kinect2DepthMode	../perception/perception/kinect2_sensor.py	/^class Kinect2DepthMode:$/;"	kind:class	line:51
Kinect2FrameMode	../perception/perception/kinect2_sensor.py	/^class Kinect2FrameMode:$/;"	kind:class	line:39
Kinect2PacketPipelineMode	../perception/perception/kinect2_sensor.py	/^class Kinect2PacketPipelineMode:$/;"	kind:class	line:31
Kinect2RegistrationMode	../perception/perception/kinect2_sensor.py	/^class Kinect2RegistrationMode:$/;"	kind:class	line:45
Kinect2Sensor	../perception/perception/kinect2_sensor.py	/^class Kinect2Sensor(CameraSensor):$/;"	kind:class	line:64
Kinect2SensorFactory	../perception/perception/kinect2_sensor.py	/^class Kinect2SensorFactory:$/;"	kind:class	line:763
KinectSensorBridged	../perception/perception/kinect2_sensor.py	/^class KinectSensorBridged(CameraSensor):$/;"	kind:class	line:372
LEARNING_RATES	../gqcnn/gqcnn/utils/enums.py	/^    LEARNING_RATES = "learning_rates.npy"$/;"	kind:variable	line:97
LEGACY_PARALLEL_JAW	../gqcnn/gqcnn/utils/enums.py	/^    LEGACY_PARALLEL_JAW = "legacy_parallel_jaw"$/;"	kind:variable	line:75
LEGACY_SUCTION	../gqcnn/gqcnn/utils/enums.py	/^    LEGACY_SUCTION = "legacy_suction"$/;"	kind:variable	line:76
LEG_MEAN	../gqcnn/gqcnn/utils/enums.py	/^    LEG_MEAN = "mean.npy"$/;"	kind:variable	line:109
LEG_STD	../gqcnn/gqcnn/utils/enums.py	/^    LEG_STD = "std.npy"$/;"	kind:variable	line:110
LOAD_DIR_PATH	../panda_autograsp/scripts/aruco_pose_estimation.py	/^LOAD_DIR_PATH = os.path.abspath($/;"	kind:variable	line:40
LocalFeature	../perception/perception/features.py	/^class LocalFeature(Feature):$/;"	kind:class	line:15
Logger	../autolab_core/autolab_core/logger.py	/^class Logger(object):$/;"	kind:class	line:59
Logger	../panda_autograsp/src/panda_autograsp/loggers.py	/^class Logger(object):$/;"	kind:class	line:153
MAIN_CFG	../panda_autograsp/nodes/grasp_planner_server.py	/^    MAIN_CFG = YamlConfig($/;"	kind:variable	line:61
MAIN_CFG	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^MAIN_CFG = YamlConfig($/;"	kind:variable	line:30
MAIN_CFG	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^MAIN_CFG = YamlConfig($/;"	kind:variable	line:71
MAIN_CFG	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^MAIN_CFG = YamlConfig($/;"	kind:variable	line:64
MAIN_CFG	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^MAIN_CFG = YamlConfig($/;"	kind:variable	line:72
MARGIN_SIZE	../panda_autograsp/scripts/generate_arucoboard.py	/^MARGIN_SIZE = 0$/;"	kind:variable	line:46
MARKERS_X	../panda_autograsp/scripts/generate_arucoboard.py	/^MARKERS_X = 4$/;"	kind:variable	line:40
MARKERS_Y	../panda_autograsp/scripts/generate_arucoboard.py	/^MARKERS_Y = 6$/;"	kind:variable	line:41
MARKER_LENGTH	../panda_autograsp/scripts/generate_arucoboard.py	/^MARKER_LENGTH = 0.032  # [M]$/;"	kind:variable	line:42
MARKER_SEPARATION	../panda_autograsp/scripts/generate_arucoboard.py	/^MARKER_SEPARATION = 0.009  # [M]$/;"	kind:variable	line:43
MAX	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    MAX = "max"$/;"	kind:variable	line:74
MAX_CLUSTER_SIZE	../gqcnn/examples/policy_with_image_proc.py	/^MAX_CLUSTER_SIZE = 1000000$/;"	kind:variable	line:54
MAX_DEPTH	../perception/perception/constants.py	/^MAX_DEPTH = 1.25$/;"	kind:variable	line:9
MAX_IR	../perception/perception/constants.py	/^MAX_IR = 65535$/;"	kind:variable	line:10
MAX_LOSS	../gqcnn/gqcnn/analysis/analyzer.py	/^MAX_LOSS = 5.0$/;"	kind:variable	line:54
MAX_PREFETCH_Q_SIZE	../gqcnn/gqcnn/utils/enums.py	/^    MAX_PREFETCH_Q_SIZE = 250$/;"	kind:variable	line:45
METERS	../perception/perception/kinect2_sensor.py	/^    METERS = 0$/;"	kind:variable	line:54
METERS_TO_MM	../perception/perception/constants.py	/^METERS_TO_MM = 1000.0$/;"	kind:variable	line:4
MILLIMETERS	../perception/perception/kinect2_sensor.py	/^    MILLIMETERS = 1$/;"	kind:variable	line:55
MIN	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    MIN = "min"$/;"	kind:variable	line:73
MIN_CLUSTER_SIZE	../gqcnn/examples/policy_with_image_proc.py	/^MIN_CLUSTER_SIZE = 100$/;"	kind:variable	line:53
MIN_DEPTH	../perception/perception/constants.py	/^MIN_DEPTH = 0.25$/;"	kind:variable	line:8
MIN_TIME_BETWEEN_SCHEDULE_ATTEMPTS	../gqcnn/gqcnn/search/enums.py	/^    MIN_TIME_BETWEEN_SCHEDULE_ATTEMPTS = 20$/;"	kind:variable	line:49
MM_TO_METERS	../perception/perception/constants.py	/^MM_TO_METERS = 1.0 \/ METERS_TO_MM$/;"	kind:variable	line:5
MODELS_PATH	../panda_autograsp/nodes/grasp_planner_server.py	/^    MODELS_PATH = os.path.abspath($/;"	kind:variable	line:72
MODELS_PATH	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^MODELS_PATH = os.path.abspath($/;"	kind:variable	line:82
MODEL_NAME	../panda_autograsp/scripts/plan_grasp.py	/^MODEL_NAME = "GQCNN-4.0-PJ"$/;"	kind:variable	line:32
MODEL_RENAME_DICT	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^MODEL_RENAME_DICT = {$/;"	kind:variable	line:52
MULTI_SUCTION	../gqcnn/gqcnn/utils/enums.py	/^    MULTI_SUCTION = "multi_suction"$/;"	kind:variable	line:74
MVCNNFeature	../perception/perception/features.py	/^class MVCNNFeature(GlobalFeature):$/;"	kind:class	line:89
Mesh	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^class Mesh(object):$/;"	kind:class	line:377
MoveitPlannerServer	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^class MoveitPlannerServer:$/;"	kind:class	line:80
MultiSuctionGrasp3D	../gqcnn/gqcnn/grasping/actions.py	/^class MultiSuctionGrasp3D(GraspAction3D):$/;"	kind:class	line:161
MultiSuctionPoint2D	../gqcnn/gqcnn/grasping/grasp.py	/^class MultiSuctionPoint2D(object):$/;"	kind:class	line:465
NEED_BIGDEPTH	../panda_autograsp/scripts/kinect_processing.py	/^NEED_BIGDEPTH = False  # Use Full size depth image$/;"	kind:variable	line:39
NEED_COLOR_DEPTH_MAP	../panda_autograsp/scripts/kinect_processing.py	/^NEED_COLOR_DEPTH_MAP = False  # Overlay depth and colour$/;"	kind:variable	line:40
NONE	../perception/perception/kinect2_sensor.py	/^    NONE = 0$/;"	kind:variable	line:48
NONE	../perception/perception/primesense_sensor.py	/^    NONE = 0$/;"	kind:variable	line:21
NONE	../perception/perception/realsense_sensor.py	/^    NONE = 0$/;"	kind:variable	line:17
NOT_STARTED	../gqcnn/gqcnn/utils/enums.py	/^    NOT_STARTED = "not_started"$/;"	kind:variable	line:88
NUMPY_SAVE	../panda_autograsp/scripts/chessboard_calibration.py	/^    NUMPY_SAVE = os.path.abspath($/;"	kind:variable	line:118
NUM_ITERS	../perception/tests/constants.py	/^NUM_ITERS = 500$/;"	kind:variable	line:4
NUM_POINTS	../perception/tests/constants.py	/^NUM_POINTS = 100$/;"	kind:variable	line:3
NUM_PREFETCH_Q_WORKERS	../gqcnn/gqcnn/utils/enums.py	/^    NUM_PREFETCH_Q_WORKERS = 3$/;"	kind:variable	line:46
N_COLMNS	../panda_autograsp/scripts/chessboard_calibration.py	/^N_COLMNS = 7  # Inner chessboard columns$/;"	kind:variable	line:52
N_COLMNS	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^N_COLMNS = calib_config["chessboard_settings"]["N_COLUMNS"]$/;"	kind:variable	line:97
N_FRAMES	../panda_autograsp/scripts/chessboard_calibration.py	/^N_FRAMES = 10  # Take the mean over N_frames$/;"	kind:variable	line:50
N_FRAMES	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^N_FRAMES = calib_config["chessboard_settings"]["N_FRAMES"]$/;"	kind:variable	line:95
N_ROWS	../panda_autograsp/scripts/chessboard_calibration.py	/^N_ROWS = 5  # Inner chessboard rows$/;"	kind:variable	line:51
N_ROWS	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^N_ROWS = calib_config["chessboard_settings"]["N_ROWS"]$/;"	kind:variable	line:96
NoAction	../gqcnn/gqcnn/grasping/actions.py	/^class NoAction(Action):$/;"	kind:class	line:76
NoAntipodalPairsFoundException	../gqcnn/gqcnn/utils/policy_exceptions.py	/^class NoAntipodalPairsFoundException(Exception):$/;"	kind:class	line:47
NoMagicQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class NoMagicQualityFunction(GraspQualityFunction):$/;"	kind:class	line:1075
NoValidGraspsException	../gqcnn/gqcnn/utils/policy_exceptions.py	/^class NoValidGraspsException(Exception):$/;"	kind:class	line:36
NormalCloud	../autolab_core/autolab_core/points.py	/^class NormalCloud(BagOfVectors):$/;"	kind:class	line:844
NormalCloudImage	../perception/perception/image.py	/^class NormalCloudImage(Image):$/;"	kind:class	line:3609
NormalCorrespondences	../perception/perception/feature_matcher.py	/^class NormalCorrespondences(Correspondences):$/;"	kind:class	line:60
NumpyEncoder	../autolab_core/autolab_core/json_serialization.py	/^class NumpyEncoder(_json.JSONEncoder):$/;"	kind:class	line:11
OPENCL	../perception/perception/kinect2_sensor.py	/^    OPENCL = 2$/;"	kind:variable	line:36
OPENGL	../perception/perception/kinect2_sensor.py	/^    OPENGL = 0$/;"	kind:variable	line:34
OPENNI2_PATH	../perception/perception/primesense_sensor.py	/^    OPENNI2_PATH = '\/home\/autolab\/Libraries\/OpenNI-Linux-x64-2.2\/Redist'$/;"	kind:variable	line:37
ObjectRender	../perception/perception/object_render.py	/^class ObjectRender(object):$/;"	kind:class	line:22
OpenCVCameraSensor	../perception/perception/opencv_camera_sensor.py	/^class OpenCVCameraSensor(CameraSensor):$/;"	kind:class	line:12
OrderedLoader	../autolab_core/autolab_core/yaml_config.py	/^        class OrderedLoader(Loader):$/;"	kind:class	line:144
OrthographicIntrinsics	../perception/perception/orthographic_intrinsics.py	/^class OrthographicIntrinsics(object):$/;"	kind:class	line:16
P	../perception/perception/orthographic_intrinsics.py	/^    def P(self):$/;"	kind:member	line:97
PACKAGE	../franka_ros/franka_example_controllers/cfg/compliance_param.cfg	/^PACKAGE = "franka_example_controllers"$/;"	kind:variable	line:2
PACKAGE	../franka_ros/franka_example_controllers/cfg/desired_mass_param.cfg	/^PACKAGE = "franka_example_controllers"$/;"	kind:variable	line:2
PACKAGE	../panda_autograsp/cfg/CalibFrames.cfg	/^PACKAGE = "panda_autograsp"$/;"	kind:variable	line:6
PARALLEL_JAW	../gqcnn/gqcnn/utils/enums.py	/^    PARALLEL_JAW = "parallel_jaw"$/;"	kind:variable	line:72
PARALLEL_JAW	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def PARALLEL_JAW(self):$/;"	kind:member	line:116
PCT_POS_TRAIN	../gqcnn/gqcnn/utils/enums.py	/^    PCT_POS_TRAIN = "pct_pos_train.npy"$/;"	kind:variable	line:96
PCT_POS_VAL	../gqcnn/gqcnn/utils/enums.py	/^    PCT_POS_VAL = "pct_pos_val.npy"$/;"	kind:variable	line:95
PENDING	../gqcnn/gqcnn/search/trial.py	/^    PENDING = "pending"$/;"	kind:variable	line:51
PI	../gqcnn/gqcnn/utils/enums.py	/^    PI = math.pi$/;"	kind:variable	line:48
POINT_N_STEP	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^POINT_N_STEP = MAIN_CFG["planning"]["point"]["point_n_step"]$/;"	kind:variable	line:67
POSE_ARROW_SIZE	../panda_autograsp/scripts/aruco_pose_estimation.py	/^POSE_ARROW_SIZE = 0.1  # [M]$/;"	kind:variable	line:39
POSE_CALIB_METHOD	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^POSE_CALIB_METHOD = MAIN_CFG["calibration"]["pose_estimation_calib_board"]$/;"	kind:variable	line:81
POSE_MEAN	../gqcnn/gqcnn/utils/enums.py	/^    POSE_MEAN = "pose_mean.npy"$/;"	kind:variable	line:115
POSE_STD	../gqcnn/gqcnn/utils/enums.py	/^    POSE_STD = "pose_std.npy"$/;"	kind:variable	line:116
POSE_STREAM	../gqcnn/gqcnn/utils/enums.py	/^    POSE_STREAM = "pose_stream"$/;"	kind:variable	line:81
PandaAutograspCLI	../panda_autograsp/nodes/panda_autograsp_cli.py	/^class PandaAutograspCLI:$/;"	kind:class	line:40
PandaAutograspServer	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^class PandaAutograspServer:$/;"	kind:class	line:129
ParallelJawGrasp3D	../gqcnn/gqcnn/grasping/actions.py	/^class ParallelJawGrasp3D(GraspAction3D):$/;"	kind:class	line:99
ParallelJawQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class ParallelJawQualityFunction(GraspQualityFunction):$/;"	kind:class	line:110
PhoXiSensor	../perception/perception/phoxi_sensor.py	/^class PhoXiSensor(CameraSensor):$/;"	kind:class	line:17
Plane	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^class Plane(object):$/;"	kind:class	line:100
Plane3D	../autolab_core/autolab_core/points.py	/^class Plane3D(object):$/;"	kind:class	line:475
Point	../autolab_core/autolab_core/points.py	/^class Point(BagOfPoints):$/;"	kind:class	line:196
PointCloud	../autolab_core/autolab_core/points.py	/^class PointCloud(BagOfPoints):$/;"	kind:class	line:534
PointCloudBoxDetector	../perception/perception/detector.py	/^class PointCloudBoxDetector(RgbdDetector):$/;"	kind:class	line:429
PointCloudImage	../perception/perception/image.py	/^class PointCloudImage(Image):$/;"	kind:class	line:3379
PointNormalCloud	../autolab_core/autolab_core/points.py	/^class PointNormalCloud(object):$/;"	kind:class	line:1149
PointToPlaneFeatureMatcher	../perception/perception/feature_matcher.py	/^class PointToPlaneFeatureMatcher(FeatureMatcher):$/;"	kind:class	line:175
PointToPlaneICPSolver	../perception/perception/point_registration.py	/^class PointToPlaneICPSolver(IterativeRegistrationSolver):$/;"	kind:class	line:64
PointsTest	../autolab_core/tests/test_points.py	/^class PointsTest(unittest.TestCase):$/;"	kind:class	line:14
Policy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class Policy(with_metaclass(ABCMeta, object)):$/;"	kind:class	line:223
PrimesenseRegistrationMode	../perception/perception/primesense_sensor.py	/^class PrimesenseRegistrationMode:$/;"	kind:class	line:18
PrimesenseSensor	../perception/perception/primesense_sensor.py	/^class PrimesenseSensor(CameraSensor):$/;"	kind:class	line:24
PrimesenseSensor_ROS	../perception/perception/primesense_sensor.py	/^class PrimesenseSensor_ROS(PrimesenseSensor):$/;"	kind:class	line:262
PriorityCompositeGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class PriorityCompositeGraspingPolicy(CompositeGraspingPolicy):$/;"	kind:class	line:1554
QFunctionRobustGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class QFunctionRobustGraspingPolicy(CrossEntropyRobustGraspingPolicy):$/;"	kind:class	line:1331
QUARTER_HD	../perception/perception/kinect2_sensor.py	/^    QUARTER_HD = "qhd"$/;"	kind:variable	line:61
QUEUE_SLEEP	../gqcnn/gqcnn/utils/enums.py	/^    QUEUE_SLEEP = 0.001$/;"	kind:variable	line:47
QueryImageBundle	../perception/perception/object_render.py	/^class QueryImageBundle:$/;"	kind:class	line:71
READ_ONLY_ACCESS	../autolab_core/autolab_core/constants.py	/^READ_ONLY_ACCESS = 'READ_ONLY'$/;"	kind:variable	line:23
READ_WRITE_ACCESS	../autolab_core/autolab_core/constants.py	/^READ_WRITE_ACCESS = 'READ_WRITE'$/;"	kind:variable	line:24
REGRESSION	../gqcnn/gqcnn/utils/enums.py	/^    REGRESSION = "regression"  # Has not been tested, for experimentation only!$/;"	kind:variable	line:67
RE_SPACE	../autolab_core/autolab_core/completer.py	/^RE_SPACE = re.compile('.*\\s+$', re.M)$/;"	kind:variable	line:9
RGBD	../perception/perception/object_render.py	/^    RGBD = 'rgbd'$/;"	kind:variable	line:18
ROOT_CONFIGURED	../autolab_core/autolab_core/logger.py	/^    ROOT_CONFIGURED = False$/;"	kind:variable	line:60
ROOT_CONFIGURED	../panda_autograsp/src/panda_autograsp/loggers.py	/^    ROOT_CONFIGURED = False$/;"	kind:variable	line:157
ROOT_LOG_LEVEL	../autolab_core/autolab_core/logger.py	/^ROOT_LOG_LEVEL = logging.INFO$/;"	kind:variable	line:11
ROOT_LOG_LEVEL	../panda_autograsp/src/panda_autograsp/loggers.py	/^ROOT_LOG_LEVEL = logging.INFO$/;"	kind:variable	line:27
ROOT_LOG_STREAM	../autolab_core/autolab_core/logger.py	/^ROOT_LOG_STREAM = sys.stdout$/;"	kind:variable	line:12
ROOT_LOG_STREAM	../panda_autograsp/src/panda_autograsp/loggers.py	/^ROOT_LOG_STREAM = sys.stdout$/;"	kind:variable	line:28
RUNNING	../gqcnn/gqcnn/search/trial.py	/^    RUNNING = "running"$/;"	kind:variable	line:52
R_cb_world	../perception/tools/register_camera.py	/^                    R_cb_world = V.T.dot(U.T)$/;"	kind:variable	line:204
R_cb_world	../perception/tools/register_camera.py	/^                R_cb_world = V.T.dot(U.T)$/;"	kind:variable	line:190
R_cb_world	../perception/tools/register_camera.py	/^            R_cb_world = R_cb_world.dot(T_cb_world.rotation)$/;"	kind:variable	line:220
R_cb_world	../perception/tools/register_camera.py	/^            R_cb_world = best_R_cb_world$/;"	kind:variable	line:216
R_gripper_world	../perception/tools/register_camera.py	/^                R_gripper_world = np.array([[-1.0, 0, 0],$/;"	kind:variable	line:292
R_gripper_world	../perception/tools/register_camera.py	/^                R_gripper_world = np.array([[1.0, 0, 0],$/;"	kind:variable	line:296
R_robot_world	../perception/tools/register_camera.py	/^                    R_robot_world = np.array([[1, 0, 0],$/;"	kind:variable	line:109
RandomVariable	../autolab_core/autolab_core/random_variables.py	/^class RandomVariable(object):$/;"	kind:class	line:13
RawDistanceFeatureMatcher	../perception/perception/feature_matcher.py	/^class RawDistanceFeatureMatcher(FeatureMatcher):$/;"	kind:class	line:125
RealSenseRegistrationMode	../perception/perception/realsense_sensor.py	/^class RealSenseRegistrationMode:$/;"	kind:class	line:14
RealSenseSensor	../perception/perception/realsense_sensor.py	/^class RealSenseSensor(CameraSensor):$/;"	kind:class	line:21
RegistrationResult	../perception/perception/point_registration.py	/^class RegistrationResult(object):$/;"	kind:class	line:13
RegressionResult	../autolab_core/autolab_core/learning_analysis.py	/^class RegressionResult(object):$/;"	kind:class	line:306
RenderMode	../perception/perception/object_render.py	/^class RenderMode(object):$/;"	kind:class	line:9
ResourceManager	../gqcnn/gqcnn/search/resource_manager.py	/^class ResourceManager(object):$/;"	kind:class	line:54
RgbCloud	../autolab_core/autolab_core/points.py	/^class RgbCloud(BagOfPoints):$/;"	kind:class	line:1042
RgbPointCloud	../autolab_core/autolab_core/points.py	/^class RgbPointCloud(object):$/;"	kind:class	line:1120
RgbdDetection	../perception/perception/detector.py	/^class RgbdDetection(object):$/;"	kind:class	line:19
RgbdDetector	../perception/perception/detector.py	/^class RgbdDetector(object):$/;"	kind:class	line:112
RgbdDetectorFactory	../perception/perception/detector.py	/^class RgbdDetectorFactory:$/;"	kind:class	line:601
RgbdForegroundMaskDetector	../perception/perception/detector.py	/^class RgbdForegroundMaskDetector(RgbdDetector):$/;"	kind:class	line:145
RgbdForegroundMaskQueryImageDetector	../perception/perception/detector.py	/^class RgbdForegroundMaskQueryImageDetector(RgbdDetector):$/;"	kind:class	line:219
RgbdImage	../perception/perception/image.py	/^class RgbdImage(Image):$/;"	kind:class	line:2808
RgbdImageState	../gqcnn/gqcnn/grasping/policy/policy.py	/^class RgbdImageState(object):$/;"	kind:class	line:63
RgbdSensorFactory	../perception/perception/rgbd_sensors.py	/^class RgbdSensorFactory:$/;"	kind:class	line:7
RigidTransform	../autolab_core/autolab_core/rigid_transformations.py	/^class RigidTransform(object):$/;"	kind:class	line:37
RigidTransformTest	../autolab_core/tests/test_rigid_transform.py	/^class RigidTransformTest(unittest.TestCase):$/;"	kind:class	line:15
RobustGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class RobustGraspingPolicy(GraspingPolicy):$/;"	kind:class	line:505
S	../perception/perception/orthographic_intrinsics.py	/^    def S(self):$/;"	kind:member	line:73
SAVED_ARCH	../gqcnn/gqcnn/utils/enums.py	/^    SAVED_ARCH = "architecture.json"$/;"	kind:variable	line:121
SAVED_CFG	../gqcnn/gqcnn/utils/enums.py	/^    SAVED_CFG = "config.json"$/;"	kind:variable	line:122
SAVE_CALIB_POSE_PATH	../panda_autograsp/scripts/aruco_pose_estimation.py	/^SAVE_CALIB_POSE_PATH = os.path.abspath($/;"	kind:variable	line:47
SAVE_DIR_PATH	../panda_autograsp/scripts/generate_arucoboard.py	/^SAVE_DIR_PATH = os.path.abspath(os.path.dirname(os.path.realpath(__file__)))$/;"	kind:variable	line:31
SAVE_PATH	../panda_autograsp/scripts/chessboard_calibration.py	/^SAVE_PATH = os.path.abspath($/;"	kind:variable	line:56
SCALED_DEPTH	../perception/perception/object_render.py	/^    SCALED_DEPTH = 'scaled_depth'$/;"	kind:variable	line:14
SD	../perception/perception/kinect2_sensor.py	/^    SD = "sd"$/;"	kind:variable	line:62
SEARCH_THREAD_SLEEP	../gqcnn/gqcnn/search/enums.py	/^    SEARCH_THREAD_SLEEP = 2$/;"	kind:variable	line:48
SEED	../autolab_core/tests/test_dataset.py	/^SEED = 4134298$/;"	kind:variable	line:40
SEED	../autolab_core/tools/compute_dataset_statistics.py	/^SEED = 2345$/;"	kind:variable	line:44
SEED	../gqcnn/gqcnn/utils/enums.py	/^    SEED = 3472134$/;"	kind:variable	line:42
SEED_SAMPLE_MAX	../gqcnn/gqcnn/utils/enums.py	/^    SEED_SAMPLE_MAX = 2**32 - 1  # Max range for `np.random.seed`.$/;"	kind:variable	line:43
SEGMASK	../perception/perception/object_render.py	/^    SEGMASK = 'segmask'$/;"	kind:variable	line:12
SETTING_UP	../gqcnn/gqcnn/utils/enums.py	/^    SETTING_UP = "setting_up"$/;"	kind:variable	line:89
SHOTFeature	../perception/perception/features.py	/^class SHOTFeature(LocalFeature):$/;"	kind:class	line:84
SQUARE_SIZE	../panda_autograsp/scripts/chessboard_calibration.py	/^SQUARE_SIZE = 30  # [mm] The square size of a chessboard square$/;"	kind:variable	line:53
SQUARE_SIZE	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^SQUARE_SIZE = calib_config["chessboard_settings"]["SQUARE_SIZE"]$/;"	kind:variable	line:98
STF_EXTENSION	../autolab_core/autolab_core/rigid_transformations.py	/^STF_EXTENSION = '.stf'$/;"	kind:variable	line:35
SUB	../gqcnn/gqcnn/utils/enums.py	/^    SUB = "im_depth_sub"$/;"	kind:variable	line:82
SUB_MOD_REQ_INSTALL_METHOD	../setup.py	/^SUB_MOD_REQ_INSTALL_METHOD = 1$/;"	kind:variable	line:37
SUCTION	../gqcnn/gqcnn/utils/enums.py	/^    SUCTION = "suction"$/;"	kind:variable	line:73
SUCTION	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def SUCTION(self):$/;"	kind:member	line:122
SUPPORTED_FILE_EXTS	../perception/perception/camera_sensor.py	/^    SUPPORTED_FILE_EXTS = ['.png', '.npy']$/;"	kind:variable	line:45
SamplingMethod	../gqcnn/gqcnn/grasping/policy/enums.py	/^class SamplingMethod(object):$/;"	kind:class	line:36
SearchConstants	../gqcnn/gqcnn/search/enums.py	/^class SearchConstants(object):$/;"	kind:class	line:47
SegmentationImage	../perception/perception/image.py	/^class SegmentationImage(Image):$/;"	kind:class	line:3232
SensorUnresponsiveException	../perception/perception/exceptions.py	/^class SensorUnresponsiveException(Exception):$/;"	kind:class	line:2
SimilarityTransform	../autolab_core/autolab_core/rigid_transformations.py	/^class SimilarityTransform(RigidTransform):$/;"	kind:class	line:1081
Sphere	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^class Sphere(object):$/;"	kind:class	line:294
SuctionGrasp3D	../gqcnn/gqcnn/grasping/actions.py	/^class SuctionGrasp3D(GraspAction3D):$/;"	kind:class	line:136
SuctionPoint2D	../gqcnn/gqcnn/grasping/grasp.py	/^class SuctionPoint2D(object):$/;"	kind:class	line:269
SuctionQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class SuctionQualityFunction(GraspQualityFunction):$/;"	kind:class	line:215
TENSOR_CONFIG	../autolab_core/tests/test_dataset.py	/^TENSOR_CONFIG = {$/;"	kind:variable	line:46
TENSOR_EXT	../autolab_core/autolab_core/tensor_dataset.py	/^TENSOR_EXT = '.npy'$/;"	kind:variable	line:38
TEST_ID	../autolab_core/autolab_core/constants.py	/^TEST_ID = 1$/;"	kind:variable	line:32
TEST_TENSOR_DATASET_NAME	../autolab_core/tests/test_dataset.py	/^TEST_TENSOR_DATASET_NAME = 'test_dataset'$/;"	kind:variable	line:45
TF_DEPTH_IMS	../gqcnn/gqcnn/utils/enums.py	/^    TF_DEPTH_IMS = "tf_depth_ims"$/;"	kind:variable	line:61
TF_EXTENSION	../autolab_core/autolab_core/rigid_transformations.py	/^TF_EXTENSION = '.tf'$/;"	kind:variable	line:34
TF_EXTENSION	../perception/perception/constants.py	/^TF_EXTENSION = '.tf'$/;"	kind:variable	line:12
TF_MAX_VERSION	../gqcnn/setup.py	/^TF_MAX_VERSION = "1.13.1"$/;"	kind:variable	line:43
TF_MAX_VERSION	../panda_autograsp/setup.py	/^TF_MAX_VERSION = "1.13.1"$/;"	kind:variable	line:32
TF_MAX_VERSION	../setup.py	/^TF_MAX_VERSION = "1.13.1"$/;"	kind:variable	line:40
TOP_K	../gqcnn/gqcnn/grasping/policy/enums.py	/^    TOP_K = "top_k"$/;"	kind:variable	line:37
TOTAL_TRAIN_ERRORS	../gqcnn/gqcnn/utils/enums.py	/^    TOTAL_TRAIN_ERRORS = "total_train_errors.npy"$/;"	kind:variable	line:103
TOTAL_TRAIN_LOSSES	../gqcnn/gqcnn/utils/enums.py	/^    TOTAL_TRAIN_LOSSES = "total_train_losses.npy"$/;"	kind:variable	line:102
TRAINING	../gqcnn/gqcnn/utils/enums.py	/^    TRAINING = "training"$/;"	kind:variable	line:90
TRAIN_ERRORS	../gqcnn/gqcnn/utils/enums.py	/^    TRAIN_ERRORS = "train_errors.npy"$/;"	kind:variable	line:101
TRAIN_ID	../autolab_core/autolab_core/constants.py	/^TRAIN_ID = 0$/;"	kind:variable	line:31
TRAIN_ITERS	../gqcnn/gqcnn/utils/enums.py	/^    TRAIN_ITERS = "train_eval_iters.npy"$/;"	kind:variable	line:99
TRAIN_LOSSES	../gqcnn/gqcnn/utils/enums.py	/^    TRAIN_LOSSES = "train_losses.npy"$/;"	kind:variable	line:100
TRIAL_CPU_LOAD	../gqcnn/gqcnn/search/enums.py	/^    TRIAL_CPU_LOAD = 300  # Decrease to get more aggressize CPU utilization.$/;"	kind:variable	line:37
TRIAL_GPU_LOAD	../gqcnn/gqcnn/search/enums.py	/^    TRIAL_GPU_LOAD = 33  # Decrease to get more aggressize GPU utilization.$/;"	kind:variable	line:38
TRIAL_GPU_MEM	../gqcnn/gqcnn/search/enums.py	/^    TRIAL_GPU_MEM = 2000$/;"	kind:variable	line:44
T_cam_cb	../perception/tools/register_webcam.py	/^            T_cam_cb = T_cb_cam.inverse()$/;"	kind:variable	line:74
T_camera_world	../gqcnn/examples/antipodal_grasp_sampling.py	/^    T_camera_world = RigidTransform.load($/;"	kind:variable	line:72
T_camera_world	../gqcnn/examples/policy_with_image_proc.py	/^    T_camera_world = RigidTransform.load(camera_pose_filename)$/;"	kind:variable	line:129
T_camera_world	../perception/tools/capture_dataset.py	/^            T_camera_world = sensor_pose$/;"	kind:variable	line:311
T_camera_world	../perception/tools/capture_dataset.py	/^        T_camera_world = RigidTransform.load(os.path.join(sensor_config['calib_dir'], sensor_frame, tf_filename))$/;"	kind:variable	line:228
T_camera_world	../perception/tools/capture_test_images.py	/^        T_camera_world = RigidTransform.load(os.path.join(config['calib_dir'], sensor_frame, tf_filename))$/;"	kind:variable	line:65
T_camera_world	../perception/tools/filter_images.py	/^    T_camera_world = RigidTransform.load(os.path.join(image_dir, '%s_to_world.tf' %(frame)))$/;"	kind:variable	line:48
T_camera_world	../perception/tools/register_camera.py	/^            T_camera_world = T_cb_world * reg_result.T_camera_cb$/;"	kind:variable	line:225
T_camera_world	../perception/tools/register_camera.py	/^            T_camera_world = T_cb_world * reg_result.T_camera_cb$/;"	kind:variable	line:75
T_camera_world	../perception/tools/register_webcam.py	/^            T_camera_world = T_cb_world.dot(T_cam_cb)$/;"	kind:variable	line:75
T_cb_cam	../perception/tools/register_object.py	/^    T_cb_cam = reg_result.T_camera_cb$/;"	kind:variable	line:57
T_cb_cam	../perception/tools/register_webcam.py	/^            T_cb_cam = RigidTransform(mat, tvec, from_frame='cb', to_frame=sensor_frame)$/;"	kind:variable	line:73
T_cb_obj	../perception/tools/register_object.py	/^    T_cb_obj = RigidTransform.load(obj_cb_transform_file_path)$/;"	kind:variable	line:39
T_cb_world	../perception/tools/register_camera.py	/^            T_cb_world = RigidTransform(rotation=R_cb_world,$/;"	kind:variable	line:221
T_cb_world	../perception/tools/register_camera.py	/^    T_cb_world = RigidTransform.load(config['chessboard_tf'])$/;"	kind:variable	line:49
T_cb_world	../perception/tools/register_webcam.py	/^    T_cb_world = RigidTransform.load(config['chessboard_tf'])$/;"	kind:variable	line:28
T_corrected_cb_world	../perception/tools/register_camera.py	/^            T_corrected_cb_world = RigidTransform(rotation=R_cb_world,$/;"	kind:variable	line:217
T_grasp_camera	../gqcnn/examples/policy_with_image_proc.py	/^    T_grasp_camera = action.grasp.pose($/;"	kind:variable	line:242
T_gripper_world	../perception/tools/register_camera.py	/^            T_gripper_world = RigidTransform(rotation=R_gripper_world,$/;"	kind:variable	line:302
T_gripper_world	../perception/tools/register_camera.py	/^            T_gripper_world = RigidTransform(rotation=R_gripper_world,$/;"	kind:variable	line:345
T_gripper_world	../perception/tools/register_camera.py	/^            T_gripper_world = RigidTransform(rotation=R_gripper_world,$/;"	kind:variable	line:372
T_gripper_world_lift	../perception/tools/register_camera.py	/^            T_gripper_world_lift = T_lift * T_gripper_world$/;"	kind:variable	line:309
T_gripper_world_lift	../perception/tools/register_camera.py	/^            T_gripper_world_lift = T_lift * T_gripper_world$/;"	kind:variable	line:352
T_gripper_world_lift	../perception/tools/register_camera.py	/^            T_gripper_world_lift = T_lift * T_gripper_world$/;"	kind:variable	line:379
T_lift	../perception/tools/register_camera.py	/^            T_lift = RigidTransform(translation=(0,0,0.05), from_frame='cb', to_frame='cb')$/;"	kind:variable	line:308
T_lift	../perception/tools/register_camera.py	/^            T_lift = RigidTransform(translation=(0,0,0.05), from_frame='cb', to_frame='cb')$/;"	kind:variable	line:351
T_lift	../perception/tools/register_camera.py	/^            T_lift = RigidTransform(translation=(0,0,0.05), from_frame='cb', to_frame='cb')$/;"	kind:variable	line:378
T_obj_camera	../perception/perception/object_render.py	/^    def T_obj_camera(self):$/;"	kind:member	line:56
T_orig_gripper_world_lift	../perception/tools/register_camera.py	/^            T_orig_gripper_world_lift = T_gripper_world_lift.copy()$/;"	kind:variable	line:310
T_robot_world	../perception/tools/register_camera.py	/^                    T_robot_world = RigidTransform(rotation=R_robot_world,$/;"	kind:variable	line:113
T_world_cam	../perception/tools/register_object.py	/^    T_world_cam = RigidTransform.load(T_world_cam_path)$/;"	kind:variable	line:43
T_world_cam_path	../perception/tools/register_object.py	/^    T_world_cam_path = os.path.join(config['calib_dir'], sensor_frame, '{0}_to_world.tf'.format(sensor_frame))$/;"	kind:variable	line:42
T_world_obj	../perception/tools/register_object.py	/^    T_world_obj = T_world_cam * T_cb_cam.inverse() * T_cb_obj$/;"	kind:variable	line:58
Tensor	../autolab_core/autolab_core/tensor_dataset.py	/^class Tensor(object):$/;"	kind:class	line:41
TensorDatapoint	../autolab_core/autolab_core/tensor_dataset.py	/^class TensorDatapoint(dict):$/;"	kind:class	line:202
TensorDataset	../autolab_core/autolab_core/tensor_dataset.py	/^class TensorDataset(object):$/;"	kind:class	line:215
TensorDatasetTest	../autolab_core/tests/test_dataset.py	/^class TensorDatasetTest(TestCase):$/;"	kind:class	line:76
TensorDatasetVirtualSensor	../perception/perception/camera_sensor.py	/^class TensorDatasetVirtualSensor(VirtualSensor):$/;"	kind:class	line:246
TerminateException	../autolab_core/autolab_core/exceptions.py	/^class TerminateException(Exception):$/;"	kind:class	line:5
TestImage	../perception/tests/test_image.py	/^class TestImage(unittest.TestCase):$/;"	kind:class	line:12
TestRegistration	../perception/tests/test_registration.py	/^class TestRegistration(TestCase):$/;"	kind:class	line:16
Tf2Broadcaster	../panda_autograsp/src/panda_autograsp/tf2_broadcaster_ros.py	/^class Tf2Broadcaster:$/;"	kind:class	line:24
TrainStatsLogger	../gqcnn/gqcnn/utils/train_stats_logger.py	/^class TrainStatsLogger(object):$/;"	kind:class	line:42
TrainingMode	../gqcnn/gqcnn/utils/enums.py	/^class TrainingMode(object):$/;"	kind:class	line:65
TrialConstants	../gqcnn/gqcnn/search/enums.py	/^class TrialConstants(object):$/;"	kind:class	line:36
TrialStatus	../gqcnn/gqcnn/search/trial.py	/^class TrialStatus:$/;"	kind:class	line:50
TutorialFormatterDirective	../moveit_tutorials/_scripts/tutorialformatter.py	/^class TutorialFormatterDirective(rst.Directive):$/;"	kind:class	line:81
UNIFORM	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    UNIFORM = "uniform"$/;"	kind:variable	line:72
UNIFORM	../gqcnn/gqcnn/grasping/policy/enums.py	/^    UNIFORM = "uniform"$/;"	kind:variable	line:38
UniformRandomGraspingPolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^class UniformRandomGraspingPolicy(GraspingPolicy):$/;"	kind:class	line:436
VAL_ERRORS	../gqcnn/gqcnn/utils/enums.py	/^    VAL_ERRORS = "val_errors.npy"$/;"	kind:variable	line:107
VAL_ITERS	../gqcnn/gqcnn/utils/enums.py	/^    VAL_ITERS = "val_eval_iters.npy"$/;"	kind:variable	line:105
VAL_LOSSES	../gqcnn/gqcnn/utils/enums.py	/^    VAL_LOSSES = "val_losses.npy"$/;"	kind:variable	line:106
VERSION	../moveit_tutorials/_themes/sphinx_rtd_theme/__init__.py	/^VERSION = (0, 1, 8)$/;"	kind:variable	line:8
VIS_SUPPORTED	../perception/tools/register_object.py	/^    VIS_SUPPORTED = FALSE$/;"	kind:variable	line:19
VIS_SUPPORTED	../perception/tools/register_object.py	/^VIS_SUPPORTED = True$/;"	kind:variable	line:13
VideoRecorder	../perception/perception/video_recorder.py	/^class VideoRecorder:$/;"	kind:class	line:8
VirtualKinect2Sensor	../perception/perception/kinect2_sensor.py	/^class VirtualKinect2Sensor(CameraSensor):$/;"	kind:class	line:570
VirtualSensor	../perception/perception/camera_sensor.py	/^class VirtualSensor(CameraSensor):$/;"	kind:class	line:44
WIDTH	../autolab_core/tests/test_dataset.py	/^WIDTH = 3$/;"	kind:variable	line:42
WINDOW	../gqcnn/gqcnn/analysis/analyzer.py	/^WINDOW = 100  # For loss.$/;"	kind:variable	line:53
WRITE_ACCESS	../autolab_core/autolab_core/constants.py	/^WRITE_ACCESS = 'WRITE'$/;"	kind:variable	line:25
WebcamSensor	../perception/perception/webcam_sensor.py	/^class WebcamSensor(CameraSensor):$/;"	kind:class	line:10
WeightPublisher	../perception/ros_nodes/weight_publisher.py	/^class WeightPublisher(object):$/;"	kind:class	line:13
WeightSensor	../perception/perception/weight_sensor.py	/^class WeightSensor(object):$/;"	kind:class	line:11
YamlConfig	../autolab_core/autolab_core/yaml_config.py	/^class YamlConfig(object):$/;"	kind:class	line:10
ZeroGraspQualityFunction	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^class ZeroGraspQualityFunction(object):$/;"	kind:class	line:86
_AXES2TUPLE	../autolab_core/autolab_core/transformations.py	/^_AXES2TUPLE = {$/;"	kind:variable	line:1521
_DataStreamSyncer	../autolab_core/autolab_core/data_stream_syncer.py	/^class _DataStreamSyncer(Process):$/;"	kind:class	line:14
_EPS	../autolab_core/autolab_core/transformations.py	/^_EPS = numpy.finfo(float).eps * 4.0$/;"	kind:variable	line:1515
_KNOWN_TYPES_MAP	../autolab_core/autolab_core/csv_model.py	/^    _KNOWN_TYPES_MAP = {$/;"	kind:variable	line:11
_MASTER_RECORD_FILENAME	../autolab_core/autolab_core/experiment_logger.py	/^    _MASTER_RECORD_FILENAME = 'experiment_record.csv'$/;"	kind:variable	line:28
_NEXT_AXIS	../autolab_core/autolab_core/transformations.py	/^_NEXT_AXIS = [1, 2, 0, 1]$/;"	kind:variable	line:1518
_NULL	../autolab_core/autolab_core/data_stream_recorder.py	/^_NULL = lambda : None$/;"	kind:variable	line:11
_TUPLE2AXES	../autolab_core/autolab_core/transformations.py	/^_TUPLE2AXES = dict((v, k) for k, v in _AXES2TUPLE.items())$/;"	kind:variable	line:1531
__add__	../autolab_core/autolab_core/dual_quaternion.py	/^    def __add__(self, val):$/;"	kind:member	line:199
__add__	../autolab_core/autolab_core/points.py	/^    def __add__(self, other_pc):$/;"	kind:member	line:711
__add__	../autolab_core/autolab_core/points.py	/^    def __add__(self, other_pt):$/;"	kind:member	line:258
__all__	../gqcnn/gqcnn/__init__.py	/^__all__ = [$/;"	kind:variable	line:39
__all__	../gqcnn/gqcnn/analysis/__init__.py	/^__all__ = ["GQCNNAnalyzer"]$/;"	kind:variable	line:31
__all__	../gqcnn/gqcnn/grasping/__init__.py	/^__all__ = [$/;"	kind:variable	line:42
__all__	../gqcnn/gqcnn/grasping/policy/__init__.py	/^__all__ = [$/;"	kind:variable	line:34
__all__	../gqcnn/gqcnn/model/tf/__init__.py	/^__all__ = ["GQCNNTF", "FCGQCNNTF"]$/;"	kind:variable	line:32
__all__	../gqcnn/gqcnn/search/__init__.py	/^__all__ = ["GQCNNSearch"]$/;"	kind:variable	line:31
__all__	../gqcnn/gqcnn/training/tf/__init__.py	/^__all__ = ["GQCNNTrainerTF"]$/;"	kind:variable	line:31
__all__	../gqcnn/gqcnn/utils/__init__.py	/^__all__ = [$/;"	kind:variable	line:37
__all__	../perception/perception/__init__.py	/^__all__ = [$/;"	kind:variable	line:69
__call__	../gqcnn/gqcnn/grasping/constraint_fn.py	/^    def __call__(self, grasp):$/;"	kind:member	line:48
__call__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __call__(self, state, actions, params=None):$/;"	kind:member	line:60
__call__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __call__(self, state):$/;"	kind:member	line:226
__contains__	../autolab_core/autolab_core/yaml_config.py	/^    def __contains__(self, key):$/;"	kind:member	line:51
__convert_key	../autolab_core/autolab_core/yaml_config.py	/^    def __convert_key(expression):$/;"	kind:member	line:129
__del__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __del__(self):$/;"	kind:member	line:1256
__del__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __del__(self):$/;"	kind:member	line:936
__del__	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def __del__(self):$/;"	kind:member	line:581
__del__	../perception/perception/colorized_phoxi_sensor.py	/^    def __del__(self):$/;"	kind:member	line:39
__del__	../perception/perception/ensenso_sensor.py	/^    def __del__(self):$/;"	kind:member	line:36
__del__	../perception/perception/kinect2_sensor.py	/^    def __del__(self):$/;"	kind:member	line:119
__del__	../perception/perception/kinect2_sensor.py	/^    def __del__(self):$/;"	kind:member	line:401
__del__	../perception/perception/phoxi_sensor.py	/^    def __del__(self):$/;"	kind:member	line:66
__del__	../perception/perception/primesense_sensor.py	/^    def __del__(self):$/;"	kind:member	line:60
__del__	../perception/perception/realsense_sensor.py	/^    def __del__(self):$/;"	kind:member	line:132
__del__	../perception/perception/webcam_sensor.py	/^    def __del__(self):$/;"	kind:member	line:39
__del__	../perception/perception/weight_sensor.py	/^    def __del__(self):$/;"	kind:member	line:124
__div__	../autolab_core/autolab_core/points.py	/^    def __div__(self, div):$/;"	kind:member	line:348
__div__	../autolab_core/autolab_core/points.py	/^    def __div__(self, div):$/;"	kind:member	line:798
__docformat__	../autolab_core/autolab_core/transformations.py	/^__docformat__ = "restructuredtext en"$/;"	kind:variable	line:177
__eq__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __eq__(self, other):$/;"	kind:member	line:1068
__getitem__	../autolab_core/autolab_core/points.py	/^    def __getitem__(self, dim):$/;"	kind:member	line:253
__getitem__	../autolab_core/autolab_core/points.py	/^    def __getitem__(self, i):$/;"	kind:member	line:1139
__getitem__	../autolab_core/autolab_core/points.py	/^    def __getitem__(self, i):$/;"	kind:member	line:1199
__getitem__	../autolab_core/autolab_core/points.py	/^    def __getitem__(self, i):$/;"	kind:member	line:161
__getitem__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __getitem__(self, i):$/;"	kind:member	line:96
__getitem__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __getitem__(self, ind):$/;"	kind:member	line:529
__getitem__	../autolab_core/autolab_core/yaml_config.py	/^    def __getitem__(self, key):$/;"	kind:member	line:56
__getitem__	../perception/perception/image.py	/^    def __getitem__(self, indices):$/;"	kind:member	line:597
__hash__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __hash__(self):$/;"	kind:member	line:1078
__init__	../autolab_core/autolab_core/completer.py	/^    def __init__(self, commands=[]):$/;"	kind:member	line:16
__init__	../autolab_core/autolab_core/csv_model.py	/^    def __init__(self, full_filename, headers_types_list, default_entry=''):$/;"	kind:member	line:18
__init__	../autolab_core/autolab_core/data_stream_recorder.py	/^    def __init__(self, name, data_sampler_method, cache_path=None, save_every=50):$/;"	kind:member	line:50
__init__	../autolab_core/autolab_core/data_stream_syncer.py	/^    def __init__(self, data_stream_recorders, frequency=0):$/;"	kind:member	line:91
__init__	../autolab_core/autolab_core/data_stream_syncer.py	/^    def __init__(self, frequency, ok_qs, cmds_q, tokens_q):$/;"	kind:member	line:16
__init__	../autolab_core/autolab_core/dual_quaternion.py	/^    def __init__(self, qr=[1,0,0,0], qd=[0,0,0,0], enforce_unit_norm=True):$/;"	kind:member	line:33
__init__	../autolab_core/autolab_core/exceptions.py	/^    def __init__(self, *args, **kwargs):$/;"	kind:member	line:8
__init__	../autolab_core/autolab_core/experiment_logger.py	/^    def __init__(self, experiment_root_path, experiment_tag='experiment', log_to_file=True, sub_experiment_dirs=True):$/;"	kind:member	line:30
__init__	../autolab_core/autolab_core/learning_analysis.py	/^    def __init__(self, num_categories):$/;"	kind:member	line:35
__init__	../autolab_core/autolab_core/learning_analysis.py	/^    def __init__(self, pred_probs, labels):$/;"	kind:member	line:47
__init__	../autolab_core/autolab_core/learning_analysis.py	/^    def __init__(self, pred_probs, labels, threshold=0.5):$/;"	kind:member	line:352
__init__	../autolab_core/autolab_core/learning_analysis.py	/^    def __init__(self, predictions, labels):$/;"	kind:member	line:307
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(point_data, rgb_data, frame):$/;"	kind:member	line:1124
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, data, frame):$/;"	kind:member	line:1046
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, data, frame):$/;"	kind:member	line:17
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, data, frame):$/;"	kind:member	line:397
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, data, frame):$/;"	kind:member	line:973
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:200
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:538
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:847
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, n, x0):$/;"	kind:member	line:479
__init__	../autolab_core/autolab_core/points.py	/^    def __init__(self, point_data, normal_data, frame):$/;"	kind:member	line:1153
__init__	../autolab_core/autolab_core/primitives.py	/^    def __init__(self, boundary_pixels, area=0.0, frame='unspecified'):$/;"	kind:member	line:134
__init__	../autolab_core/autolab_core/primitives.py	/^    def __init__(self, min_pt, max_pt, frame='unspecified'):$/;"	kind:member	line:37
__init__	../autolab_core/autolab_core/random_variables.py	/^    def __init__(self, mu, sigma, *args, **kwargs):$/;"	kind:member	line:121
__init__	../autolab_core/autolab_core/random_variables.py	/^    def __init__(self, mu_tra=np.zeros(3), mu_rot=np.eye(3), $/;"	kind:member	line:229
__init__	../autolab_core/autolab_core/random_variables.py	/^    def __init__(self, num_prealloc_samples=0):$/;"	kind:member	line:18
__init__	../autolab_core/autolab_core/random_variables.py	/^    def __init__(self, obj, *args, **kwargs):$/;"	kind:member	line:157
__init__	../autolab_core/autolab_core/random_variables.py	/^    def __init__(self, p, *args, **kwargs):$/;"	kind:member	line:87
__init__	../autolab_core/autolab_core/random_variables.py	/^    def __init__(self, sigma_trans, sigma_rot,$/;"	kind:member	line:304
__init__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __init__(self, rotation=np.eye(3), translation=np.zeros(3), scale=1.0,$/;"	kind:member	line:1084
__init__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __init__(self, rotation=np.eye(3), translation=np.zeros(3),$/;"	kind:member	line:41
__init__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __init__(self, field_names, *args, **kwargs):$/;"	kind:member	line:206
__init__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __init__(self, filename, config, access_mode=WRITE_ACCESS, force_overwrite=False):$/;"	kind:member	line:225
__init__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __init__(self, shape, dtype=np.float32, data=None):$/;"	kind:member	line:46
__init__	../autolab_core/autolab_core/transformations.py	/^    def __init__(self, initial=None):$/;"	kind:member	line:1380
__init__	../autolab_core/autolab_core/yaml_config.py	/^    def __init__(self, filename=None):$/;"	kind:member	line:19
__init__	../gqcnn/gqcnn/analysis/analyzer.py	/^    def __init__(self, config, verbose=True, plot_backend="pdf"):$/;"	kind:member	line:60
__init__	../gqcnn/gqcnn/grasping/actions.py	/^    def __init__(self, T_grasp_world, q_value=0.0, id=-1, metadata={}):$/;"	kind:member	line:90
__init__	../gqcnn/gqcnn/grasping/actions.py	/^    def __init__(self, q_value=0.0, id=-1, metadata={}):$/;"	kind:member	line:58
__init__	../gqcnn/gqcnn/grasping/constraint_fn.py	/^    def __init__(self, config):$/;"	kind:member	line:44
__init__	../gqcnn/gqcnn/grasping/constraint_fn.py	/^    def __init__(self, config):$/;"	kind:member	line:84
__init__	../gqcnn/gqcnn/grasping/grasp.py	/^    def __init__(self, center, axis=None, depth=1.0, camera_intr=None):$/;"	kind:member	line:284
__init__	../gqcnn/gqcnn/grasping/grasp.py	/^    def __init__(self, pose, camera_intr=None):$/;"	kind:member	line:478
__init__	../gqcnn/gqcnn/grasping/grasp.py	/^    def __init__(self,$/;"	kind:member	line:62
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self):$/;"	kind:member	line:56
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:1076
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:114
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:1239
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:147
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:219
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:270
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:358
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:464
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:610
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:676
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:753
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:825
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:857
__init__	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def __init__(self, config):$/;"	kind:member	line:920
__init__	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def __init__(self, config):$/;"	kind:member	line:633
__init__	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def __init__(self, config):$/;"	kind:member	line:855
__init__	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def __init__(self, config):$/;"	kind:member	line:87
__init__	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def __init__(self, config, gripper_width=np.inf):$/;"	kind:member	line:227
__init__	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def __init__(self, cfg, filters=None):$/;"	kind:member	line:359
__init__	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def __init__(self, cfg, filters=None):$/;"	kind:member	line:58
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, config):$/;"	kind:member	line:1370
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, config):$/;"	kind:member	line:1417
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, config):$/;"	kind:member	line:439
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, config, filters=None):$/;"	kind:member	line:510
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, config, filters=None):$/;"	kind:member	line:691
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, config, init_sampler=True):$/;"	kind:member	line:240
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, grasp, q_value, image=None, policy_name=None):$/;"	kind:member	line:160
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, policies):$/;"	kind:member	line:1536
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, policies):$/;"	kind:member	line:1623
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self, policies, priority_list):$/;"	kind:member	line:1555
__init__	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def __init__(self,$/;"	kind:member	line:66
__init__	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def __init__(self, gqcnn_config, fc_config, verbose=True, log_file=None):$/;"	kind:member	line:54
__init__	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def __init__(self):$/;"	kind:member	line:56
__init__	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def __init__(self, gqcnn_config, verbose=True, log_file=None):$/;"	kind:member	line:63
__init__	../gqcnn/gqcnn/search/resource_manager.py	/^    def __init__(self,$/;"	kind:member	line:55
__init__	../gqcnn/gqcnn/search/search.py	/^    def __init__(self,$/;"	kind:member	line:57
__init__	../gqcnn/gqcnn/search/trial.py	/^    def __init__(self, analysis_cfg, train_cfg, dataset_dir, base_model_dir,$/;"	kind:member	line:211
__init__	../gqcnn/gqcnn/search/trial.py	/^    def __init__(self, analysis_cfg, train_cfg, dataset_dir, split_name,$/;"	kind:member	line:58
__init__	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def __init__(self,$/;"	kind:member	line:72
__init__	../gqcnn/gqcnn/utils/policy_exceptions.py	/^    def __init__(self, in_collision=True, not_confident=False, *args,$/;"	kind:member	line:40
__init__	../gqcnn/gqcnn/utils/train_stats_logger.py	/^    def __init__(self, experiment_dir):$/;"	kind:member	line:45
__init__	../gqcnn/ros_nodes/grasp_planner_node.py	/^    def __init__(self, cfg, cv_bridge, grasping_policy, grasp_pose_publisher):$/;"	kind:member	line:61
__init__	../panda_autograsp/nodes/panda_autograsp_cli.py	/^    def __init__(self):$/;"	kind:member	line:43
__init__	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def __init__(self):$/;"	kind:member	line:106
__init__	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def __init__(self, model=DEFAULT_MODEL, sensor_type="kinectv2"):$/;"	kind:member	line:155
__init__	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    def __init__(self, cfg, cv_bridge, grasping_policy, grasp_pose_publisher):$/;"	kind:member	line:62
__init__	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def __init__($/;"	kind:member	line:123
__init__	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def __init__($/;"	kind:member	line:236
__init__	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def __init__($/;"	kind:member	line:29
__init__	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def __init__($/;"	kind:member	line:323
__init__	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def __init__($/;"	kind:member	line:406
__init__	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def __init__($/;"	kind:member	line:105
__init__	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def __init__(self, pose_calib_method=POSE_CALIB_METHOD, gazebo=False):$/;"	kind:member	line:140
__init__	../panda_autograsp/src/panda_autograsp/tf2_broadcaster_ros.py	/^    def __init__(self):$/;"	kind:member	line:69
__init__	../perception/perception/camera_intrinsics.py	/^    def __init__(self, frame, fx, fy=None, cx=0.0, cy=0.0, skew=0.0, height=None, width=None):$/;"	kind:member	line:21
__init__	../perception/perception/camera_sensor.py	/^    def __init__(self, dataset_path, frame=None, loop=True):$/;"	kind:member	line:255
__init__	../perception/perception/camera_sensor.py	/^    def __init__(self, path_to_images, frame=None, loop=True):$/;"	kind:member	line:51
__init__	../perception/perception/chessboard_registration.py	/^    def __init__(self, T_camera_cb, cb_points_camera):$/;"	kind:member	line:25
__init__	../perception/perception/cnn.py	/^    def __init__(self):$/;"	kind:member	line:11
__init__	../perception/perception/cnn.py	/^    def __init__(self, config, model_dir=None, use_default_weights=False,$/;"	kind:member	line:60
__init__	../perception/perception/colorized_phoxi_sensor.py	/^    def __init__(self, phoxi_config, webcam_config, calib_dir, frame='phoxi'):$/;"	kind:member	line:13
__init__	../perception/perception/detector.py	/^    def __init__(self, color_thumbnail, depth_thumbnail, bounding_box, binary_thumbnail=None, camera_intr=None, contour=None):$/;"	kind:member	line:45
__init__	../perception/perception/ensenso_sensor.py	/^    def __init__(self, frame='ensenso'):$/;"	kind:member	line:27
__init__	../perception/perception/exceptions.py	/^    def __init__(self, *args, **kwargs):$/;"	kind:member	line:4
__init__	../perception/perception/feature_extractors.py	/^    def __init__(self):$/;"	kind:member	line:18
__init__	../perception/perception/feature_extractors.py	/^    def __init__(self, cnn):$/;"	kind:member	line:100
__init__	../perception/perception/feature_extractors.py	/^    def __init__(self, config):$/;"	kind:member	line:40
__init__	../perception/perception/feature_matcher.py	/^    def __init__(self):$/;"	kind:member	line:107
__init__	../perception/perception/feature_matcher.py	/^    def __init__(self, dist_thresh=0.05, norm_thresh=0.75):$/;"	kind:member	line:185
__init__	../perception/perception/feature_matcher.py	/^    def __init__(self, index_map, source_points, target_points):$/;"	kind:member	line:28
__init__	../perception/perception/feature_matcher.py	/^    def __init__(self, index_map, source_points, target_points, source_normals, target_normals):$/;"	kind:member	line:78
__init__	../perception/perception/features.py	/^    def __init__(self):$/;"	kind:member	line:12
__init__	../perception/perception/features.py	/^    def __init__(self, descriptor, rf, point, normal):$/;"	kind:member	line:31
__init__	../perception/perception/features.py	/^    def __init__(self, descriptor, rf, point, normal):$/;"	kind:member	line:86
__init__	../perception/perception/features.py	/^    def __init__(self, features = None):$/;"	kind:member	line:102
__init__	../perception/perception/features.py	/^    def __init__(self, key, descriptor, pose=None):$/;"	kind:member	line:67
__init__	../perception/perception/features.py	/^    def __init__(self, key, descriptor, pose=None):$/;"	kind:member	line:91
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:1487
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:1939
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:2043
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:2811
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:3081
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:3236
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:3383
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:3613
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified'):$/;"	kind:member	line:98
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified', encoding='rgb8'):$/;"	kind:member	line:988
__init__	../perception/perception/image.py	/^    def __init__(self, data, frame='unspecified',$/;"	kind:member	line:2159
__init__	../perception/perception/kinect2_sensor.py	/^    def __init__(self, packet_pipeline_mode = Kinect2PacketPipelineMode.AUTO,$/;"	kind:member	line:76
__init__	../perception/perception/kinect2_sensor.py	/^    def __init__(self, path_to_images, frame=None):$/;"	kind:member	line:576
__init__	../perception/perception/kinect2_sensor.py	/^    def __init__(self, quality=Kinect2BridgedQuality.HD, frame='kinect2_rgb_optical_frame'):$/;"	kind:member	line:378
__init__	../perception/perception/object_render.py	/^    def __init__(self, binary_image_render, color_image_render, depth_image_render):$/;"	kind:member	line:74
__init__	../perception/perception/object_render.py	/^    def __init__(self, image, T_camera_world=RigidTransform(from_frame='camera', to_frame='table'),$/;"	kind:member	line:31
__init__	../perception/perception/opencv_camera_sensor.py	/^    def __init__(self, device_id, upside_down=False):$/;"	kind:member	line:14
__init__	../perception/perception/orthographic_intrinsics.py	/^    def __init__(self, frame,$/;"	kind:member	line:20
__init__	../perception/perception/phoxi_sensor.py	/^    def __init__(self, frame='phoxi', device_name='2018-02-020-LC3', size='small'):$/;"	kind:member	line:21
__init__	../perception/perception/point_registration.py	/^    def __init__(self, T_source_target, cost):$/;"	kind:member	line:23
__init__	../perception/perception/point_registration.py	/^    def __init__(self, sample_size=100, cost_sample_size=100, gamma=100.0, mu=1e-2):$/;"	kind:member	line:78
__init__	../perception/perception/primesense_sensor.py	/^    def __init__(self, depth_image_buffer= None, depth_absolute=False, color_image_buffer=None, color_absolute=False,$/;"	kind:member	line:274
__init__	../perception/perception/primesense_sensor.py	/^    def __init__(self, registration_mode=PrimesenseRegistrationMode.DEPTH_TO_COLOR,$/;"	kind:member	line:39
__init__	../perception/perception/realsense_sensor.py	/^    def __init__(self,$/;"	kind:member	line:48
__init__	../perception/perception/video_recorder.py	/^    def __init__(self, device_id=0, res=(640, 480), video_format='v4l2', fps=30):$/;"	kind:member	line:22
__init__	../perception/perception/webcam_sensor.py	/^    def __init__(self, frame='webcam', device_id=0):$/;"	kind:member	line:14
__init__	../perception/perception/weight_sensor.py	/^    def __init__(self, id_mask='F1804', ntaps=4, debug=False):$/;"	kind:member	line:15
__init__	../perception/ros_nodes/weight_publisher.py	/^    def __init__(self, rate=20.0, id_mask='F1804'):$/;"	kind:member	line:28
__init__.py	../autolab_core/autolab_core/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/analysis/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/grasping/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/grasping/policy/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/model/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/model/tf/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/search/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/training/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/training/tf/__init__.py	1;"	kind:file	line:1
__init__.py	../gqcnn/gqcnn/utils/__init__.py	1;"	kind:file	line:1
__init__.py	../moveit_tutorials/_themes/sphinx_rtd_theme/__init__.py	1;"	kind:file	line:1
__init__.py	../panda_autograsp/src/panda_autograsp/__init__.py	1;"	kind:file	line:1
__init__.py	../panda_autograsp/src/panda_autograsp/functions/__init__.py	1;"	kind:file	line:1
__init__.py	../panda_autograsp/src/panda_autograsp/grasp_planners/__init__.py	1;"	kind:file	line:1
__init__.py	../perception/perception/__init__.py	1;"	kind:file	line:1
__init__.py	../perception/tests/__init__.py	1;"	kind:file	line:1
__iter__	../autolab_core/autolab_core/csv_model.py	/^    def __iter__(self):$/;"	kind:member	line:353
__iter__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __iter__(self):$/;"	kind:member	line:104
__iter__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __iter__(self):$/;"	kind:member	line:592
__iter__	../autolab_core/autolab_core/yaml_config.py	/^    def __iter__(self):$/;"	kind:member	line:151
__iter__	../perception/perception/feature_matcher.py	/^    def __iter__(self):$/;"	kind:member	line:51
__iter__	../perception/perception/feature_matcher.py	/^    def __iter__(self):$/;"	kind:member	line:92
__metaclass__	../autolab_core/autolab_core/experiment_logger.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:26
__metaclass__	../autolab_core/autolab_core/points.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:15
__metaclass__	../autolab_core/autolab_core/random_variables.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:16
__metaclass__	../perception/perception/camera_sensor.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:17
__metaclass__	../perception/perception/detector.py	/^    __metaclass__ = ABCMeta    $/;"	kind:variable	line:115
__metaclass__	../perception/perception/feature_extractors.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:16
__metaclass__	../perception/perception/feature_matcher.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:105
__metaclass__	../perception/perception/features.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:11
__metaclass__	../perception/perception/features.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:29
__metaclass__	../perception/perception/features.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:65
__metaclass__	../perception/perception/image.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:96
__metaclass__	../perception/perception/point_registration.py	/^    __metaclass__ = ABCMeta$/;"	kind:variable	line:29
__mul__	../autolab_core/autolab_core/dual_quaternion.py	/^    def __mul__(self, val):$/;"	kind:member	line:164
__mul__	../autolab_core/autolab_core/points.py	/^    def __mul__(self, mult):$/;"	kind:member	line:306
__mul__	../autolab_core/autolab_core/points.py	/^    def __mul__(self, mult):$/;"	kind:member	line:755
__mul__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __mul__(self, rigid_object):$/;"	kind:member	line:429
__ne__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __ne__(self, other):$/;"	kind:member	line:1073
__next__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __next__(self):$/;"	kind:member	line:108
__next__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __next__(self):$/;"	kind:member	line:597
__next__	../autolab_core/autolab_core/yaml_config.py	/^    def __next__(self):$/;"	kind:member	line:157
__ordered_load	../autolab_core/autolab_core/yaml_config.py	/^    def __ordered_load(self, stream, Loader=yaml.Loader, object_pairs_hook=OrderedDict):$/;"	kind:member	line:136
__repr__	../autolab_core/autolab_core/dual_quaternion.py	/^    def __repr__(self):$/;"	kind:member	line:229
__repr__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __repr__(self):$/;"	kind:member	line:1348
__repr__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __repr__(self):$/;"	kind:member	line:597
__rmul__	../autolab_core/autolab_core/points.py	/^    def __rmul__(self, mult):$/;"	kind:member	line:328
__rmul__	../autolab_core/autolab_core/points.py	/^    def __rmul__(self, mult):$/;"	kind:member	line:777
__setitem__	../autolab_core/autolab_core/tensor_dataset.py	/^    def __setitem__(self, i, data):$/;"	kind:member	line:99
__setitem__	../autolab_core/autolab_core/yaml_config.py	/^    def __setitem__(self, key, val):$/;"	kind:member	line:61
__str__	../autolab_core/autolab_core/dual_quaternion.py	/^    def __str__(self):$/;"	kind:member	line:226
__str__	../autolab_core/autolab_core/points.py	/^    def __str__(self):$/;"	kind:member	line:188
__str__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __str__(self):$/;"	kind:member	line:1343
__str__	../autolab_core/autolab_core/rigid_transformations.py	/^    def __str__(self):$/;"	kind:member	line:592
__str__	../gqcnn/gqcnn/search/trial.py	/^    def __str__(self):$/;"	kind:member	line:179
__sub__	../autolab_core/autolab_core/points.py	/^    def __sub__(self, other_pc):$/;"	kind:member	line:735
__sub__	../autolab_core/autolab_core/points.py	/^    def __sub__(self, other_pt):$/;"	kind:member	line:286
__truediv__	../autolab_core/autolab_core/points.py	/^    def __truediv__(self, div):$/;"	kind:member	line:352
__truediv__	../autolab_core/autolab_core/points.py	/^    def __truediv__(self, div):$/;"	kind:member	line:802
__version__	../autolab_core/autolab_core/version.py	/^__version__ = '0.0.12'$/;"	kind:variable	line:1
__version__	../gqcnn/gqcnn/version.py	/^__version__ = "1.1.0"$/;"	kind:variable	line:1
__version__	../moveit_tutorials/_scripts/tutorialformatter.py	/^__version__ = '0.1.2'$/;"	kind:variable	line:73
__version__	../moveit_tutorials/_themes/sphinx_rtd_theme/__init__.py	/^__version__ = ".".join(str(v) for v in VERSION)$/;"	kind:variable	line:10
__version__	../panda_autograsp/setup.py	/^__version__ = re.sub($/;"	kind:variable	line:225
__version__	../panda_autograsp/version.py	/^__version__ = "0.0.6"$/;"	kind:variable	line:1
__version__	../perception/perception/version.py	/^__version__ = '0.0.9'$/;"	kind:variable	line:1
__version__	../setup.py	/^__version__ = re.sub($/;"	kind:variable	line:356
__version_full__	../moveit_tutorials/_themes/sphinx_rtd_theme/__init__.py	/^__version_full__ = __version__$/;"	kind:variable	line:11
_action	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _action(self, state, num_actions=1):$/;"	kind:member	line:249
_action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _action(self, state):$/;"	kind:member	line:1274
_action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _action(self, state):$/;"	kind:member	line:1449
_action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _action(self, state):$/;"	kind:member	line:414
_action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _action(self, state):$/;"	kind:member	line:455
_action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _action(self, state):$/;"	kind:member	line:595
_action_to_plane	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _action_to_plane(self, point_cloud_image, action):$/;"	kind:member	line:362
_action_to_plane	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _action_to_plane(self, point_cloud_image, action):$/;"	kind:member	line:469
_allocate_tensors	../autolab_core/autolab_core/tensor_dataset.py	/^    def _allocate_tensors(self):$/;"	kind:member	line:459
_best_fit_plane	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _best_fit_plane(self, A, b):$/;"	kind:member	line:253
_build_conv_layer	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_conv_layer(self,$/;"	kind:member	line:1025
_build_fc_layer	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_fc_layer(self,$/;"	kind:member	line:1099
_build_fc_merge	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_fc_merge(self, input_fc_node_1, input_fc_node_2, fan_in_1,$/;"	kind:member	line:1185
_build_fully_conv_layer	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def _build_fully_conv_layer(self,$/;"	kind:member	line:148
_build_fully_conv_merge_layer	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def _build_fully_conv_merge_layer(self, input_node_im, input_node_pose,$/;"	kind:member	line:197
_build_gpu_list	../gqcnn/gqcnn/search/resource_manager.py	/^    def _build_gpu_list(self, max_possible_trials_per_device):$/;"	kind:member	line:133
_build_im_stream	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def _build_im_stream(self,$/;"	kind:member	line:253
_build_im_stream	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_im_stream(self,$/;"	kind:member	line:1226
_build_merge_stream	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def _build_merge_stream(self, input_stream_1, input_stream_2, fan_in_1,$/;"	kind:member	line:330
_build_merge_stream	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_merge_stream(self, input_stream_1, input_stream_2, fan_in_1,$/;"	kind:member	line:1327
_build_network	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_network(self, input_im_node, input_pose_node,$/;"	kind:member	line:1376
_build_pc_layer	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_pc_layer(self, input_node, fan_in, out_size, name):$/;"	kind:member	line:1152
_build_pose_stream	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _build_pose_stream(self, input_node, fan_in, layers):$/;"	kind:member	line:1304
_build_train_progress_dict	../gqcnn/gqcnn/search/trial.py	/^    def _build_train_progress_dict(self):$/;"	kind:member	line:74
_build_trial_progress_dict	../gqcnn/gqcnn/search/trial.py	/^    def _build_trial_progress_dict(self):$/;"	kind:member	line:81
_caches_to_file	../autolab_core/autolab_core/data_stream_recorder.py	/^def _caches_to_file(cache_path, start, end, name, cb, concat):$/;"	kind:function	line:13
_camera_info_callback	../perception/perception/ensenso_sensor.py	/^    def _camera_info_callback(self, msg):$/;"	kind:member	line:90
_camera_info_callback	../perception/perception/kinect2_sensor.py	/^    def _camera_info_callback(self, msg):$/;"	kind:member	line:457
_camera_world_calibration	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def _camera_world_calibration(self, calib_type=POSE_CALIB_METHOD):$/;"	kind:member	line:856
_check_valid_data	../autolab_core/autolab_core/points.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:1059
_check_valid_data	../autolab_core/autolab_core/points.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:212
_check_valid_data	../autolab_core/autolab_core/points.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:409
_check_valid_data	../autolab_core/autolab_core/points.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:44
_check_valid_data	../autolab_core/autolab_core/points.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:550
_check_valid_data	../autolab_core/autolab_core/points.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:860
_check_valid_data	../autolab_core/autolab_core/points.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:985
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:1028
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:1512
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:1961
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:2066
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:2192
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:252
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:2836
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:3106
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:3260
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:3405
_check_valid_data	../perception/perception/image.py	/^    def _check_valid_data(self, data):$/;"	kind:member	line:3635
_check_valid_rotation	../autolab_core/autolab_core/rigid_transformations.py	/^    def _check_valid_rotation(self, rotation):$/;"	kind:member	line:91
_check_valid_translation	../autolab_core/autolab_core/rigid_transformations.py	/^    def _check_valid_translation(self, translation):$/;"	kind:member	line:103
_cleanup	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _cleanup(self):$/;"	kind:member	line:1318
_close_tensorboard	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _close_tensorboard(self):$/;"	kind:member	line:228
_color_im_callback	../perception/perception/phoxi_sensor.py	/^    def _color_im_callback(self, msg):$/;"	kind:member	line:225
_color_image_callback	../perception/perception/kinect2_sensor.py	/^    def _color_image_callback(self, image_msg):$/;"	kind:member	line:438
_colorize	../perception/perception/colorized_phoxi_sensor.py	/^    def _colorize(self, depth_im, color_im):$/;"	kind:member	line:145
_complete_path	../autolab_core/autolab_core/completer.py	/^    def _complete_path(self, path=None):$/;"	kind:member	line:34
_compute_data_metrics	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _compute_data_metrics(self):$/;"	kind:member	line:623
_compute_data_params	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _compute_data_params(self):$/;"	kind:member	line:1199
_compute_split_indices	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _compute_split_indices(self):$/;"	kind:member	line:973
_config_pipe	../perception/perception/realsense_sensor.py	/^    def _config_pipe(self):$/;"	kind:member	line:79
_connect	../perception/ros_nodes/weight_publisher.py	/^    def _connect(self, id_mask):$/;"	kind:member	line:69
_connect_to_sensor	../perception/perception/phoxi_sensor.py	/^    def _connect_to_sensor(self):$/;"	kind:member	line:201
_create_loss	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _create_loss(self):$/;"	kind:member	line:131
_create_optimizer	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _create_optimizer(self, loss, batch, var_list, learning_rate):$/;"	kind:member	line:169
_depth_im_callback	../perception/perception/phoxi_sensor.py	/^    def _depth_im_callback(self, msg):$/;"	kind:member	line:238
_depth_im_from_pointcloud	../perception/perception/ensenso_sensor.py	/^    def _depth_im_from_pointcloud(self, msg):$/;"	kind:member	line:60
_depth_image_callback	../perception/perception/kinect2_sensor.py	/^    def _depth_image_callback(self, image_msg):$/;"	kind:member	line:444
_distort	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _distort(self, image_arr, pose_arr):$/;"	kind:member	line:1562
_dump_cache	../autolab_core/autolab_core/data_stream_recorder.py	/^def _dump_cache(data, filename, name, i):$/;"	kind:function	line:39
_dump_cb	../autolab_core/autolab_core/data_stream_recorder.py	/^def _dump_cb(data, filename, cb):$/;"	kind:function	line:43
_error_rate_in_batches	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _error_rate_in_batches(self, num_files_eval=None, validation_set=True):$/;"	kind:member	line:1625
_extract_q	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _extract_q(self, i):$/;"	kind:member	line:130
_filter	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _filter(self, actions):$/;"	kind:member	line:229
_filter_depth_frame	../perception/perception/realsense_sensor.py	/^    def _filter_depth_frame(self, depth):$/;"	kind:member	line:195
_finetune	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _finetune(self, base_model_dir):$/;"	kind:member	line:266
_flush	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _flush(self):$/;"	kind:member	line:193
_flush	../perception/ros_nodes/weight_publisher.py	/^    def _flush(self):$/;"	kind:member	line:102
_flush_prefetch_queue	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _flush_prefetch_queue(self):$/;"	kind:member	line:1340
_forward_pass	../perception/perception/feature_extractors.py	/^    def _forward_pass(self, images):$/;"	kind:member	line:51
_frames_and_index_map	../perception/perception/kinect2_sensor.py	/^    def _frames_and_index_map(self, skip_registration=False):$/;"	kind:member	line:310
_gen_grasp_affordance_map	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _gen_grasp_affordance_map(self, state, stride=1):$/;"	kind:member	line:838
_gen_images_and_depths	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _gen_images_and_depths(self, depth, segmask):$/;"	kind:member	line:245
_gen_images_and_depths	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _gen_images_and_depths(self, depth, segmask):$/;"	kind:member	line:427
_gen_images_and_depths	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _gen_images_and_depths(self, depth, segmask):$/;"	kind:member	line:517
_get_actions	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _get_actions(self, preds, ind, images, depths, camera_intr,$/;"	kind:member	line:182
_get_actions	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _get_actions(self, preds, ind, images, depths, camera_intr,$/;"	kind:member	line:397
_get_actions	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _get_actions(self, preds, ind, images, depths, camera_intr,$/;"	kind:member	line:448
_get_cfg	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def _get_cfg(self, model):$/;"	kind:member	line:230
_get_cpu_load	../gqcnn/gqcnn/search/resource_manager.py	/^    def _get_cpu_load(self):$/;"	kind:member	line:99
_get_dynamic_param	../panda_autograsp/src/panda_autograsp/tf2_broadcaster_ros.py	/^    def _get_dynamic_param(self, parameter_name):$/;"	kind:member	line:378
_get_gpu_stats	../gqcnn/gqcnn/search/resource_manager.py	/^    def _get_gpu_stats(self):$/;"	kind:member	line:108
_get_new_uid	../autolab_core/autolab_core/csv_model.py	/^    def _get_new_uid(self):$/;"	kind:member	line:75
_handle_tare	../perception/ros_nodes/weight_publisher.py	/^    def _handle_tare(self, request):$/;"	kind:member	line:62
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:1050
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:1982
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:2087
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:2213
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:263
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:3274
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:3426
_image_data	../perception/perception/image.py	/^    def _image_data(self):$/;"	kind:member	line:3660
_image_data	../perception/perception/image.py	/^    def _image_data(self, normalize=False):$/;"	kind:member	line:2891
_image_data	../perception/perception/image.py	/^    def _image_data(self, normalize=False):$/;"	kind:member	line:3163
_image_data	../perception/perception/image.py	/^    def _image_data(self, normalize=False,$/;"	kind:member	line:1534
_import_module	../autolab_core/autolab_core/transformations.py	/^def _import_module(module_name, warn=True, prefix='_py_', ignore='_'):$/;"	kind:function	line:1681
_initialize	../perception/perception/cnn.py	/^    def _initialize(self):$/;"	kind:member	line:131
_launch_tensorboard	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _launch_tensorboard(self):$/;"	kind:member	line:215
_leaky_relu	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _leaky_relu(self, x, alpha=.1):$/;"	kind:member	line:1022
_listdir	../autolab_core/autolab_core/completer.py	/^    def _listdir(self, root):$/;"	kind:member	line:24
_load	../perception/perception/cnn.py	/^    def _load(self):$/;"	kind:member	line:95
_load_and_enqueue	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _load_and_enqueue(self, seed):$/;"	kind:member	line:1379
_load_config	../autolab_core/autolab_core/yaml_config.py	/^    def _load_config(self, filename):$/;"	kind:member	line:75
_mask_predictions	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _mask_predictions(self, preds, raw_segmask):$/;"	kind:member	line:109
_mask_predictions	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _mask_predictions(self, pred_map, segmask):$/;"	kind:member	line:827
_normal_map_callback	../perception/perception/phoxi_sensor.py	/^    def _normal_map_callback(self, msg):$/;"	kind:member	line:246
_open_dataset	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _open_dataset(self):$/;"	kind:member	line:1179
_optimize_weights	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _optimize_weights(self, finetune=False):$/;"	kind:member	line:291
_pack	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def _pack(self, dim_h, dim_w, data, vector=False):$/;"	kind:member	line:128
_parse_config	../gqcnn/gqcnn/analysis/analyzer.py	/^    def _parse_config(self):$/;"	kind:member	line:82
_parse_config	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _parse_config(self):$/;"	kind:member	line:1375
_parse_config	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _parse_config(self):$/;"	kind:member	line:1421
_parse_config	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _parse_config(self):$/;"	kind:member	line:537
_parse_config	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _parse_config(self):$/;"	kind:member	line:732
_parse_config	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def _parse_config(self, cfg):$/;"	kind:member	line:123
_parse_config	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _parse_config(self, gqcnn_config):$/;"	kind:member	line:387
_parse_config	../perception/perception/cnn.py	/^    def _parse_config(self, config):$/;"	kind:member	line:72
_pause	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _pause(self):$/;"	kind:member	line:219
_plan_grasp	../gqcnn/ros_nodes/grasp_planner_node.py	/^    def _plan_grasp(self,$/;"	kind:member	line:203
_plan_grasp	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def _plan_grasp($/;"	kind:member	line:474
_plan_grasp	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    def _plan_grasp($/;"	kind:member	line:224
_plot	../gqcnn/gqcnn/analysis/analyzer.py	/^    def _plot(self, model_dir, model_output_dir, train_result, val_result):$/;"	kind:member	line:580
_plot_grasp	../gqcnn/gqcnn/analysis/analyzer.py	/^    def _plot_grasp(self,$/;"	kind:member	line:146
_plot_grasp_affordance_map	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _plot_grasp_affordance_map(self,$/;"	kind:member	line:893
_pointcloud_callback	../perception/perception/ensenso_sensor.py	/^    def _pointcloud_callback(self, msg):$/;"	kind:member	line:86
_points_in_window	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _points_in_window(self, point_cloud_image, action, segmask=None):$/;"	kind:member	line:226
_points_in_window	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _points_in_window(self, point_cloud_image, action, segmask=None):$/;"	kind:member	line:479
_points_in_window	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _points_in_window(self, point_cloud_image, action, segmask=None):$/;"	kind:member	line:830
_points_to_matrices	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _points_to_matrices(self, points):$/;"	kind:member	line:245
_points_to_matrices	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _points_to_matrices(self, points):$/;"	kind:member	line:757
_preallocate_samples	../autolab_core/autolab_core/random_variables.py	/^    def _preallocate_samples(self):$/;"	kind:member	line:30
_predict	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def _predict(self, image_arr, pose_arr, verbose=False):$/;"	kind:member	line:835
_preprocess_data	../autolab_core/autolab_core/points.py	/^    def _preprocess_data(self, data):$/;"	kind:member	line:49
_preprocess_data	../perception/perception/image.py	/^    def _preprocess_data(self, data):$/;"	kind:member	line:132
_process_image_msg	../perception/perception/kinect2_sensor.py	/^    def _process_image_msg(self, msg):$/;"	kind:member	line:420
_raw_weights	../perception/perception/weight_sensor.py	/^    def _raw_weights(self):$/;"	kind:member	line:92
_read_color_and_depth_image	../perception/perception/realsense_sensor.py	/^    def _read_color_and_depth_image(self):$/;"	kind:member	line:200
_read_color_image	../perception/perception/primesense_sensor.py	/^    def _read_color_image(self):$/;"	kind:member	line:177
_read_color_image	../perception/perception/primesense_sensor.py	/^    def _read_color_image(self):$/;"	kind:member	line:383
_read_color_images	../perception/perception/primesense_sensor.py	/^    def _read_color_images(self, num_images):$/;"	kind:member	line:370
_read_depth_image	../perception/perception/primesense_sensor.py	/^    def _read_depth_image(self):$/;"	kind:member	line:160
_read_depth_image	../perception/perception/primesense_sensor.py	/^    def _read_depth_image(self):$/;"	kind:member	line:380
_read_depth_images	../perception/perception/primesense_sensor.py	/^    def _read_depth_images(self, num_images):$/;"	kind:member	line:360
_read_training_params	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _read_training_params(self):$/;"	kind:member	line:1059
_read_weights	../perception/ros_nodes/weight_publisher.py	/^    def _read_weights(self):$/;"	kind:member	line:123
_realize_dirs	../autolab_core/autolab_core/experiment_logger.py	/^    def _realize_dirs(self, dirs):$/;"	kind:member	line:166
_resume	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _resume(self):$/;"	kind:member	line:224
_ros_read_images	../perception/perception/primesense_sensor.py	/^    def _ros_read_images(self, stream_buffer, number, staleness_limit = 10.):$/;"	kind:member	line:312
_run	../gqcnn/gqcnn/search/trial.py	/^    def _run(self, trainer):$/;"	kind:member	line:206
_run	../gqcnn/gqcnn/search/trial.py	/^    def _run(self, trainer):$/;"	kind:member	line:219
_run	../gqcnn/gqcnn/search/trial.py	/^    def _run(self, trainer):$/;"	kind:member	line:86
_run_prediction_single_model	../gqcnn/gqcnn/analysis/analyzer.py	/^    def _run_prediction_single_model(self, model_dir, model_output_dir,$/;"	kind:member	line:193
_run_trial	../gqcnn/gqcnn/search/trial.py	/^    def _run_trial(self,$/;"	kind:member	line:89
_sample	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample(self,$/;"	kind:member	line:147
_sample	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample(self,$/;"	kind:member	line:297
_sample	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample(self,$/;"	kind:member	line:664
_sample	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample(self,$/;"	kind:member	line:886
_sample_antipodal_grasps	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample_antipodal_grasps(self,$/;"	kind:member	line:343
_sample_depth	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample_depth(self, min_depth, max_depth):$/;"	kind:member	line:287
_sample_depths	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _sample_depths(self, raw_depth_im, raw_seg):$/;"	kind:member	line:378
_sample_predictions	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _sample_predictions(self, preds, num_actions):$/;"	kind:member	line:133
_sample_predictions_flat	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _sample_predictions_flat(self, preds_flat, num_samples):$/;"	kind:member	line:154
_sample_suction_points	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample_suction_points(self,$/;"	kind:member	line:708
_sample_suction_points	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _sample_suction_points(self,$/;"	kind:member	line:932
_save	../autolab_core/autolab_core/csv_model.py	/^    def _save(self):$/;"	kind:member	line:103
_save_cache	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _save_cache(self, i):$/;"	kind:member	line:156
_save_configs	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _save_configs(self):$/;"	kind:member	line:1032
_save_data	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _save_data(self, path, cb, concat):$/;"	kind:member	line:139
_segment_color	../perception/perception/detector.py	/^    def _segment_color(self, color_im, bounding_box, bgmodel, cfg, vis_segmentation=False):$/;"	kind:member	line:225
_send_oks	../autolab_core/autolab_core/data_stream_syncer.py	/^    def _send_oks(self):$/;"	kind:member	line:60
_set_camera_properties	../perception/perception/ensenso_sensor.py	/^    def _set_camera_properties(self, msg):$/;"	kind:member	line:47
_set_camera_properties	../perception/perception/kinect2_sensor.py	/^    def _set_camera_properties(self, msg):$/;"	kind:member	line:407
_set_depth_scale	../perception/perception/realsense_sensor.py	/^    def _set_depth_scale(self):$/;"	kind:member	line:102
_set_format	../perception/perception/ensenso_sensor.py	/^    def _set_format(self, msg):$/;"	kind:member	line:42
_set_intrinsics	../perception/perception/realsense_sensor.py	/^    def _set_intrinsics(self):$/;"	kind:member	line:108
_set_qs	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _set_qs(self, ok_q, tokens_q):$/;"	kind:member	line:189
_setup	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _setup(self):$/;"	kind:member	line:1346
_setup_denoising_and_synthetic	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _setup_denoising_and_synthetic(self):$/;"	kind:member	line:1162
_setup_gqcnn	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def _setup_gqcnn(self):$/;"	kind:member	line:1382
_setup_output_dirs	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _setup_output_dirs(self):$/;"	kind:member	line:1010
_setup_summaries	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _setup_summaries(self):$/;"	kind:member	line:1284
_setup_tensorflow	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _setup_tensorflow(self):$/;"	kind:member	line:1241
_start_recording	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _start_recording(self, *args, **kwargs):$/;"	kind:member	line:165
_start_sensor	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def _start_sensor(self):$/;"	kind:member	line:351
_stop	../autolab_core/autolab_core/data_stream_recorder.py	/^    def _stop(self):$/;"	kind:member	line:209
_str_to_bool	../autolab_core/autolab_core/csv_model.py	/^    def _str_to_bool(s):$/;"	kind:member	line:367
_sum_of_squared_residuals	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def _sum_of_squared_residuals(self, w, A, z):$/;"	kind:member	line:262
_surface_normals	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def _surface_normals(self, depth_im, edge_pixels):$/;"	kind:member	line:269
_take_oks	../autolab_core/autolab_core/data_stream_syncer.py	/^    def _take_oks(self):$/;"	kind:member	line:66
_tare	../perception/ros_nodes/weight_publisher.py	/^    def _tare(self):$/;"	kind:member	line:112
_to_numpy	../perception/perception/realsense_sensor.py	/^    def _to_numpy(self, frame, dtype):$/;"	kind:member	line:191
_train	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def _train(self):$/;"	kind:member	line:238
_try_ok	../autolab_core/autolab_core/data_stream_syncer.py	/^    def _try_ok(self):$/;"	kind:member	line:74
_unpack_state	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _unpack_state(self, state):$/;"	kind:member	line:103
_visualize_2d	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _visualize_2d(self,$/;"	kind:member	line:204
_visualize_3d	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _visualize_3d(self, actions, wrapped_depth_im, camera_intr,$/;"	kind:member	line:188
_visualize_3d	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _visualize_3d(self, actions, wrapped_depth_im, camera_intr,$/;"	kind:member	line:433
_visualize_3d	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _visualize_3d(self, actions, wrapped_depth_im, camera_intr,$/;"	kind:member	line:522
_visualize_affordance_map	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _visualize_affordance_map(self, preds, depth_im):$/;"	kind:member	line:438
_visualize_affordance_map	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _visualize_affordance_map(self,$/;"	kind:member	line:194
_visualize_affordance_map	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def _visualize_affordance_map(self,$/;"	kind:member	line:480
_weights_callback	../perception/perception/weight_sensor.py	/^    def _weights_callback(self, msg):$/;"	kind:member	line:107
abs_angle_diff	../autolab_core/autolab_core/dist_metrics.py	/^def abs_angle_diff(v_i, v_j):$/;"	kind:function	line:9
absolute	../perception/ros_nodes/image_buffer.py	/^    absolute       = rospy.get_param('~absolute', False)$/;"	kind:variable	line:37
accuracy	../autolab_core/autolab_core/learning_analysis.py	/^    def accuracy(self):$/;"	kind:member	line:72
accuracy_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def accuracy_curve(self, delta_tau=0.01):$/;"	kind:member	line:515
action	../gqcnn/examples/policy.py	/^        action="store_true",$/;"	kind:variable	line:90
action	../gqcnn/examples/policy.py	/^    action = policy(state)$/;"	kind:variable	line:260
action	../gqcnn/examples/policy_ros.py	/^    action = GraspAction(grasp_2d, grasp.q_value, thumbnail)$/;"	kind:variable	line:163
action	../gqcnn/examples/policy_with_image_proc.py	/^    action = policy(state)$/;"	kind:variable	line:228
action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def action(self, state):$/;"	kind:member	line:231
action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def action(self, state):$/;"	kind:member	line:377
action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def action(self, state, policy_subset=None, min_q_value=-1.0):$/;"	kind:member	line:1569
action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def action(self, state, policy_subset=None, min_q_value=-1.0):$/;"	kind:member	line:1626
action	../gqcnn/tools/run_policy.py	/^    action = policy(state)$/;"	kind:variable	line:131
action_path	../gqcnn/tools/run_policy.py	/^    action_path = os.path.join(test_case_path, "action")$/;"	kind:variable	line:94
action_set	../gqcnn/gqcnn/grasping/policy/fc_policy.py	/^    def action_set(self, state, num_actions):$/;"	kind:member	line:334
action_set	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def action_set(self, state):$/;"	kind:member	line:941
action_set	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def action_set(self, state, policy_subset=None, min_q_value=-1.0):$/;"	kind:member	line:1594
action_set	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def action_set(self, state, policy_subset=None, min_q_value=-1.0):$/;"	kind:member	line:1647
actions.py	../gqcnn/gqcnn/grasping/actions.py	1;"	kind:file	line:1
add	../autolab_core/autolab_core/tensor_dataset.py	/^    def add(self, datapoint):$/;"	kind:member	line:121
add	../autolab_core/autolab_core/tensor_dataset.py	/^    def add(self, datapoint):$/;"	kind:member	line:481
add	../perception/perception/features.py	/^    def add(self, feature):$/;"	kind:member	line:109
add_batch	../autolab_core/autolab_core/tensor_dataset.py	/^    def add_batch(self, datapoints):$/;"	kind:member	line:127
add_collision_objects	../panda_autograsp/src/panda_autograsp/functions/moveit.py	/^def add_collision_objects(scene_commander, collision_cfg):$/;"	kind:function	line:135
add_frame	../perception/perception/image.py	/^    def add_frame($/;"	kind:member	line:2629
add_log_file	../autolab_core/autolab_core/logger.py	/^    def add_log_file(logger, log_file, global_log_file=False):$/;"	kind:member	line:128
add_log_file	../panda_autograsp/src/panda_autograsp/loggers.py	/^    def add_log_file(log_file=None, logger=None, mode="a", encoding=None, delay=False):$/;"	kind:member	line:265
add_metadata	../autolab_core/autolab_core/tensor_dataset.py	/^    def add_metadata(self, key, value):$/;"	kind:member	line:679
add_root_log_file	../autolab_core/autolab_core/logger.py	/^def add_root_log_file(log_file):$/;"	kind:function	line:41
add_root_log_file	../panda_autograsp/src/panda_autograsp/loggers.py	/^def add_root_log_file(log_file, mode="a", encoding=None, delay=False):$/;"	kind:function	line:109
add_scene_collision_objects	../panda_autograsp/nodes/moveit_planner_server.py	/^        add_scene_collision_objects=moveit_add_scene_collision_objects,$/;"	kind:variable	line:70
add_sigmoid_to_output	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def add_sigmoid_to_output(self):$/;"	kind:member	line:819
add_softmax_to_output	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def add_softmax_to_output(self):$/;"	kind:member	line:803
add_submods_requirements	../setup.py	/^def add_submods_requirements(requirements):$/;"	kind:function	line:105
adjoint_tf	../autolab_core/autolab_core/rigid_transformations.py	/^    def adjoint_tf(self):$/;"	kind:member	line:163
aggregate_tensor_datasets.py	../autolab_core/tools/aggregate_tensor_datasets.py	1;"	kind:file	line:1
align	../perception/perception/image.py	/^    def align(self, scale, center, angle, height, width):$/;"	kind:member	line:387
all_image_indices	../perception/tools/capture_dataset.py	/^    all_image_indices = np.arange(num_images)$/;"	kind:variable	line:174
all_indices	../perception/tools/capture_dataset.py	/^    all_indices = np.arange(num_objects)$/;"	kind:variable	line:168
all_input_dataset_names	../autolab_core/tools/aggregate_tensor_datasets.py	/^    all_input_dataset_names = []$/;"	kind:variable	line:55
all_points	../perception/tools/filter_images.py	/^    all_points = np.c_[filtered_points[:,:cur_i], point_cloud_filtered.data[:,invalid_indices]]$/;"	kind:variable	line:143
alpha	../perception/tools/compute_normal_cloud_im.py	/^    alpha = 0.025$/;"	kind:variable	line:36
analysis_config	../gqcnn/tools/hyperparam_search.py	/^    analysis_config = YamlConfig(analysis_config)$/;"	kind:variable	line:116
analysis_config	../gqcnn/tools/hyperparam_search.py	/^    analysis_config = args.analysis_config$/;"	kind:variable	line:87
analyze	../gqcnn/gqcnn/analysis/analyzer.py	/^    def analyze(self, model_dir, output_dir, dataset_config=None):$/;"	kind:member	line:92
analyze_classification_performance	../perception/tools/analyze_cnn_classification.py	/^def analyze_classification_performance(model_dir, config, dataset_path=None):$/;"	kind:function	line:20
analyze_cnn_classification.py	../perception/tools/analyze_cnn_classification.py	1;"	kind:file	line:1
analyze_gqcnn_performance.py	../gqcnn/tools/analyze_gqcnn_performance.py	1;"	kind:file	line:1
analyzer	../gqcnn/tools/analyze_gqcnn_performance.py	/^    analyzer = GQCNNAnalyzer(config, plot_backend="pdf")$/;"	kind:variable	line:121
analyzer.py	../gqcnn/gqcnn/analysis/analyzer.py	1;"	kind:file	line:1
angle	../gqcnn/gqcnn/grasping/grasp.py	/^    def angle(self):$/;"	kind:member	line:322
angle	../gqcnn/gqcnn/grasping/grasp.py	/^    def angle(self):$/;"	kind:member	line:531
angular_bins	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def angular_bins(self):$/;"	kind:member	line:644
antipodal_grasp_sampling.py	../gqcnn/examples/antipodal_grasp_sampling.py	1;"	kind:file	line:1
ap_score	../autolab_core/autolab_core/learning_analysis.py	/^    def ap_score(self):$/;"	kind:member	line:175
app_score	../autolab_core/autolab_core/learning_analysis.py	/^    def app_score(self):$/;"	kind:member	line:467
apply	../autolab_core/autolab_core/rigid_transformations.py	/^    def apply(self, points):$/;"	kind:member	line:1137
apply	../autolab_core/autolab_core/rigid_transformations.py	/^    def apply(self, points):$/;"	kind:member	line:344
apply	../perception/perception/image.py	/^    def apply(self, method, *args, **kwargs):$/;"	kind:member	line:655
approach_angle	../gqcnn/gqcnn/grasping/grasp.py	/^    def approach_angle(self):$/;"	kind:member	line:104
approach_angle	../gqcnn/gqcnn/grasping/grasp.py	/^    def approach_angle(self):$/;"	kind:member	line:336
approach_angle	../gqcnn/gqcnn/grasping/grasp.py	/^    def approach_angle(self):$/;"	kind:member	line:524
approach_axis	../gqcnn/gqcnn/grasping/grasp.py	/^    def approach_axis(self):$/;"	kind:member	line:100
approach_axis	../gqcnn/gqcnn/grasping/grasp.py	/^    def approach_axis(self):$/;"	kind:member	line:343
approach_axis	../gqcnn/gqcnn/grasping/grasp.py	/^    def approach_axis(self):$/;"	kind:member	line:520
arcball_constrain_to_axis	../autolab_core/autolab_core/transformations.py	/^def arcball_constrain_to_axis(point, axis):$/;"	kind:function	line:1485
arcball_map_to_sphere	../autolab_core/autolab_core/transformations.py	/^def arcball_map_to_sphere(point, center, radius):$/;"	kind:function	line:1472
arcball_nearest_axis	../autolab_core/autolab_core/transformations.py	/^def arcball_nearest_axis(point, axes):$/;"	kind:function	line:1501
area	../autolab_core/autolab_core/primitives.py	/^    def area(self):$/;"	kind:member	line:81
args	../autolab_core/tools/aggregate_tensor_datasets.py	/^    args = parser.parse_args()$/;"	kind:variable	line:45
args	../autolab_core/tools/compute_dataset_statistics.py	/^    args = parser.parse_args()$/;"	kind:variable	line:163
args	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    args = parser.parse_args()$/;"	kind:variable	line:22
args	../autolab_core/tools/shuffle_tensor_dataset.py	/^    args = parser.parse_args()$/;"	kind:variable	line:43
args	../autolab_core/tools/split_dataset.py	/^    args = parser.parse_args()$/;"	kind:variable	line:52
args	../autolab_core/tools/subsample_tensor_dataset.py	/^    args = parser.parse_args()$/;"	kind:variable	line:44
args	../gqcnn/examples/antipodal_grasp_sampling.py	/^    args = parser.parse_args()$/;"	kind:variable	line:57
args	../gqcnn/examples/policy.py	/^    args = parser.parse_args()$/;"	kind:variable	line:93
args	../gqcnn/examples/policy_ros.py	/^    args = parser.parse_args()$/;"	kind:variable	line:86
args	../gqcnn/examples/policy_with_image_proc.py	/^    args = parser.parse_args()$/;"	kind:variable	line:88
args	../gqcnn/tools/analyze_gqcnn_performance.py	/^    args = parser.parse_args()$/;"	kind:variable	line:70
args	../gqcnn/tools/finetune.py	/^    args = parser.parse_args()$/;"	kind:variable	line:99
args	../gqcnn/tools/hyperparam_search.py	/^    args = parser.parse_args()$/;"	kind:variable	line:83
args	../gqcnn/tools/run_policy.py	/^    args = parser.parse_args()$/;"	kind:variable	line:68
args	../gqcnn/tools/train.py	/^    args = parser.parse_args()$/;"	kind:variable	line:90
args	../panda_autograsp/nodes/moveit_planner_server.py	/^        args=sys.argv,$/;"	kind:variable	line:69
args	../perception/tools/analyze_cnn_classification.py	/^    args = parser.parse_args()$/;"	kind:variable	line:224
args	../perception/tools/capture_dataset.py	/^    args = parser.parse_args()$/;"	kind:variable	line:135
args	../perception/tools/capture_test_images.py	/^    args = parser.parse_args()$/;"	kind:variable	line:25
args	../perception/tools/filter_images.py	/^    args = parser.parse_args()$/;"	kind:variable	line:38
args	../perception/tools/finetune_classification_cnn.py	/^    args = parser.parse_args()$/;"	kind:variable	line:211
args	../perception/tools/register_camera.py	/^    args = parser.parse_args()$/;"	kind:variable	line:44
args	../perception/tools/register_ensenso.py	/^    args = parser.parse_args()$/;"	kind:variable	line:156
args	../perception/tools/register_object.py	/^    args = parser.parse_args()$/;"	kind:variable	line:26
args	../perception/tools/register_webcam.py	/^    args = parser.parse_args()$/;"	kind:variable	line:24
arr	../autolab_core/autolab_core/tensor_dataset.py	/^    def arr(self):$/;"	kind:member	line:55
aruco_board	../panda_autograsp/scripts/aruco_pose_estimation.py	/^aruco_board = aruco.GridBoard_create($/;"	kind:variable	line:69
aruco_board	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^aruco_board = aruco.GridBoard_create($/;"	kind:variable	line:117
aruco_board_pose_estimation	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def aruco_board_pose_estimation(self):$/;"	kind:member	line:886
aruco_pose_estimation.py	../panda_autograsp/scripts/aruco_pose_estimation.py	1;"	kind:file	line:1
as_frames	../autolab_core/autolab_core/rigid_transformations.py	/^    def as_frames(self, from_frame, to_frame='world'):$/;"	kind:member	line:1275
as_frames	../autolab_core/autolab_core/rigid_transformations.py	/^    def as_frames(self, from_frame, to_frame='world'):$/;"	kind:member	line:504
at_joint_target	../panda_autograsp/src/panda_autograsp/functions/moveit.py	/^def at_joint_target(current, desired, goal_tolerance):$/;"	kind:function	line:104
auc_score	../autolab_core/autolab_core/learning_analysis.py	/^    def auc_score(self):$/;"	kind:member	line:185
author	../autolab_core/docs/source/conf.py	/^author = u'Jeff Mahler'$/;"	kind:variable	line:59
author	../autolab_core/setup.py	/^    author = 'Jeff Mahler',$/;"	kind:variable	line:27
author	../docs/source/conf.py	/^author = "Rick Staa"$/;"	kind:variable	line:27
author	../gqcnn/docs/source/conf.py	/^author = u"Vishal Satish, Jeff Mahler"$/;"	kind:variable	line:62
author	../gqcnn/setup.py	/^    author="Vishal Satish",$/;"	kind:variable	line:171
author	../panda_autograsp/setup.py	/^    author="Rick Staa",$/;"	kind:variable	line:244
author	../perception/docs/source/conf.py	/^author = u'Jeff Mahler'$/;"	kind:variable	line:59
author	../perception/setup.py	/^      author='Jeff Mahler',$/;"	kind:variable	line:30
author	../setup.py	/^    author="Rick Staa",$/;"	kind:variable	line:391
author_email	../autolab_core/setup.py	/^    author_email = 'jmahler@berkeley.edu',$/;"	kind:variable	line:28
author_email	../gqcnn/setup.py	/^    author_email="vsatish@berkeley.edu",$/;"	kind:variable	line:172
author_email	../panda_autograsp/setup.py	/^    author_email="rick.staa@outlook.com",$/;"	kind:variable	line:245
author_email	../perception/setup.py	/^      author_email='jmahler@berkeley.edu',$/;"	kind:variable	line:31
author_email	../setup.py	/^    author_email="rick.staa@outlook.com",$/;"	kind:variable	line:392
autoclass_content	../autolab_core/docs/source/conf.py	/^autoclass_content = 'class'$/;"	kind:variable	line:36
autoclass_content	../docs/source/conf.py	/^autoclass_content = "class"$/;"	kind:variable	line:47
autoclass_content	../gqcnn/docs/source/conf.py	/^autoclass_content = "class"$/;"	kind:variable	line:39
autoclass_content	../perception/docs/source/conf.py	/^autoclass_content = 'class'$/;"	kind:variable	line:36
autodoc_default_flags	../autolab_core/docs/source/conf.py	/^autodoc_default_flags = ['members', 'show-inheritance']$/;"	kind:variable	line:38
autodoc_default_flags	../docs/source/conf.py	/^autodoc_default_flags = ["members"]  # , "show-inheritance"]$/;"	kind:variable	line:49
autodoc_default_flags	../gqcnn/docs/source/conf.py	/^autodoc_default_flags = ["members", "show-inheritance"]$/;"	kind:variable	line:41
autodoc_default_flags	../perception/docs/source/conf.py	/^autodoc_default_flags = ['members', 'show-inheritance']$/;"	kind:variable	line:38
autodoc_member_order	../autolab_core/docs/source/conf.py	/^autodoc_member_order = 'bysource'$/;"	kind:variable	line:37
autodoc_member_order	../docs/source/conf.py	/^autodoc_member_order = "bysource"$/;"	kind:variable	line:48
autodoc_member_order	../gqcnn/docs/source/conf.py	/^autodoc_member_order = "bysource"$/;"	kind:variable	line:40
autodoc_member_order	../perception/docs/source/conf.py	/^autodoc_member_order = 'bysource'$/;"	kind:variable	line:37
autosummary_generate	../docs/source/conf.py	/^autosummary_generate = True$/;"	kind:variable	line:50
axis	../gqcnn/gqcnn/grasping/grasp.py	/^    def axis(self):$/;"	kind:member	line:516
axis	../gqcnn/gqcnn/grasping/grasp.py	/^    def axis(self):$/;"	kind:member	line:95
axis	../panda_autograsp/scripts/chessboard_calibration.py	/^    axis = ($/;"	kind:variable	line:138
axis	../perception/tools/filter_images.py	/^                          axis=1)$/;"	kind:variable	line:87
axis_angle	../autolab_core/autolab_core/rigid_transformations.py	/^    def axis_angle(self):$/;"	kind:member	line:216
b_data	../perception/perception/image.py	/^    def b_data(self):$/;"	kind:member	line:1074
backend	../gqcnn/tools/finetune.py	/^    backend = args.backend$/;"	kind:variable	line:110
backend	../gqcnn/tools/train.py	/^    backend = args.backend$/;"	kind:variable	line:99
background_model	../perception/perception/image.py	/^    def background_model(self, ignore_black=True, use_hsv=False, scale=8):$/;"	kind:member	line:1262
base_model_dirs	../gqcnn/tools/hyperparam_search.py	/^    base_model_dirs = args.base_model_dirs$/;"	kind:variable	line:85
base_model_name	../gqcnn/tools/finetune.py	/^    base_model_name = args.base_model_name$/;"	kind:variable	line:101
base_models	../gqcnn/tools/hyperparam_search.py	/^                         base_models=base_model_dirs)$/;"	kind:variable	line:128
batch_size	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def batch_size(self):$/;"	kind:member	line:592
begin	../gqcnn/gqcnn/search/trial.py	/^    def begin(self, gpu_avail="", cpu_cores_avail=[]):$/;"	kind:member	line:169
best_R_cb_world	../perception/tools/register_camera.py	/^                        best_R_cb_world = R_cb_world$/;"	kind:variable	line:213
best_R_cb_world	../perception/tools/register_camera.py	/^            best_R_cb_world = None$/;"	kind:variable	line:176
best_dist	../perception/tools/register_camera.py	/^                        best_dist = mean_dist$/;"	kind:variable	line:212
best_dist	../perception/tools/register_camera.py	/^            best_dist = np.inf$/;"	kind:variable	line:177
best_fit_plane	../autolab_core/autolab_core/points.py	/^    def best_fit_plane(self):$/;"	kind:member	line:661
bgr2rgb	../perception/perception/image.py	/^    def bgr2rgb(self):$/;"	kind:member	line:1079
bigdepth	../panda_autograsp/scripts/kinect_processing.py	/^            bigdepth=bigdepth,$/;"	kind:variable	line:135
bigdepth	../panda_autograsp/scripts/kinect_processing.py	/^    bigdepth = Frame(1920, 1082, 4) if NEED_BIGDEPTH else None$/;"	kind:variable	line:113
binary_im	../perception/perception/detector.py	/^    def binary_im(self):$/;"	kind:member	line:78
binary_im	../perception/perception/object_render.py	/^    def binary_im(self):$/;"	kind:member	line:93
blue	../autolab_core/autolab_core/points.py	/^    def blue(self):$/;"	kind:member	line:1094
board	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            board=aruco_board,$/;"	kind:variable	line:154
border_pixels	../perception/perception/image.py	/^    def border_pixels($/;"	kind:member	line:3277
boundary_map	../perception/perception/image.py	/^    def boundary_map(self):$/;"	kind:member	line:2431
box	../perception/tools/filter_images.py	/^    box = Box(np.array([0.2, -0.24, min_height]), np.array([0.56, 0.21, max_height]), frame='world')$/;"	kind:variable	line:107
box_coords	../panda_autograsp/scripts/chessboard_calibration.py	/^                    box_coords = ($/;"	kind:variable	line:190
box_coords	../panda_autograsp/scripts/chessboard_calibration.py	/^                    box_coords = ($/;"	kind:variable	line:264
box_coords	../panda_autograsp/scripts/chessboard_calibration.py	/^        box_coords = ($/;"	kind:variable	line:466
box_mask	../autolab_core/autolab_core/points.py	/^    def box_mask(self, box):$/;"	kind:member	line:629
breathe_default_project	../docs/source/conf.py	/^breathe_default_project = "panda_autograsp"$/;"	kind:variable	line:56
breathe_projects	../docs/source/conf.py	/^breathe_projects = {"panda_autograsp": "..\/build\/doxyxml"}$/;"	kind:variable	line:55
bridge	../perception/ros_nodes/image_buffer.py	/^    bridge = CvBridge()$/;"	kind:variable	line:46
broadcast_camera_frame	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def broadcast_camera_frame(self, calib_type="aruco_board"):$/;"	kind:member	line:1083
broadcaster	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    broadcaster = tf2_ros.TransformBroadcaster()$/;"	kind:variable	line:52
buffer	../perception/ros_nodes/image_buffer.py	/^    buffer = []$/;"	kind:variable	line:47
bufsize	../perception/ros_nodes/image_buffer.py	/^    bufsize        = rospy.get_param('~bufsize', 100)$/;"	kind:variable	line:38
build_alexnet	../perception/perception/cnn.py	/^    def build_alexnet(self, weights, output_layer=None):$/;"	kind:member	line:295
build_alexnet_weights	../perception/perception/cnn.py	/^    def build_alexnet_weights(self):$/;"	kind:member	line:219
c	../gqcnn/examples/policy_with_image_proc.py	/^    c = np.array([165, 460, 500, 135])$/;"	kind:variable	line:141
c_x	../panda_autograsp/scripts/chessboard_calibration.py	/^        c_x = color_mtx[0, 2]  # x optical center$/;"	kind:variable	line:369
c_y	../panda_autograsp/scripts/chessboard_calibration.py	/^        c_y = color_mtx[1, 2]  # y optical center$/;"	kind:variable	line:370
calc_xyz_rpy	../iai_kinect2/kinect2_calibration/scripts/convert_calib_pose_to_urdf_format.py	/^def calc_xyz_rpy(data):$/;"	kind:function	line:28
calib_config	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^calib_config = MAIN_CFG["calibration"]$/;"	kind:variable	line:94
calib_frame_group	../panda_autograsp/cfg/CalibFrames.cfg	/^calib_frame_group = gen.add_group("calib_frame", type="tab")$/;"	kind:variable	line:16
calibrate_sensor_service	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def calibrate_sensor_service(self, req):$/;"	kind:member	line:811
callback	../perception/ros_nodes/image_buffer.py	/^    def callback(data):$/;"	kind:function	line:50
camera	../perception/tools/capture_dataset.py	/^        camera = VirtualCamera(camera_intr, T_camera_world)$/;"	kind:variable	line:243
cameraMatrix	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            cameraMatrix=camera_matrix,$/;"	kind:variable	line:158
camera_intr	../gqcnn/examples/antipodal_grasp_sampling.py	/^    camera_intr = sensor.ir_intrinsics$/;"	kind:variable	line:78
camera_intr	../gqcnn/examples/policy.py	/^    camera_intr = CameraIntrinsics.load(camera_intr_filename)$/;"	kind:variable	line:190
camera_intr	../gqcnn/examples/policy_ros.py	/^                                  camera_intr=camera_intr)$/;"	kind:variable	line:152
camera_intr	../gqcnn/examples/policy_ros.py	/^                           camera_intr=camera_intr)$/;"	kind:variable	line:145
camera_intr	../gqcnn/examples/policy_ros.py	/^    camera_intr = CameraIntrinsics.load(camera_intr_filename)$/;"	kind:variable	line:118
camera_intr	../gqcnn/examples/policy_with_image_proc.py	/^    camera_intr = CameraIntrinsics.load(camera_intr_filename)$/;"	kind:variable	line:128
camera_intr	../perception/tools/capture_dataset.py	/^            camera_intr = camera_intrs[sensor_name]$/;"	kind:variable	line:308
camera_intr	../perception/tools/capture_dataset.py	/^        camera_intr = camera_intr.resize(im_rescale_factor)$/;"	kind:variable	line:238
camera_intr	../perception/tools/capture_dataset.py	/^        camera_intr = sensor.ir_intrinsics$/;"	kind:variable	line:237
camera_intr	../perception/tools/capture_test_images.py	/^        camera_intr = sensor.ir_intrinsics$/;"	kind:variable	line:73
camera_intr	../perception/tools/compute_normal_cloud_im.py	/^    camera_intr = CameraIntrinsics.load(camera_intr_filename)$/;"	kind:variable	line:25
camera_intr	../perception/tools/filter_images.py	/^    camera_intr = sensor.ir_intrinsics$/;"	kind:variable	line:45
camera_intr	../perception/tools/primesense_viewer.py	/^    camera_intr = sensor.ir_intrinsics$/;"	kind:variable	line:22
camera_intr_filename	../gqcnn/examples/policy.py	/^        camera_intr_filename = os.path.join($/;"	kind:variable	line:120
camera_intr_filename	../gqcnn/examples/policy.py	/^    camera_intr_filename = args.camera_intr$/;"	kind:variable	line:97
camera_intr_filename	../gqcnn/examples/policy_ros.py	/^        camera_intr_filename = os.path.join($/;"	kind:variable	line:104
camera_intr_filename	../gqcnn/examples/policy_ros.py	/^    camera_intr_filename = args.camera_intr$/;"	kind:variable	line:89
camera_intr_filename	../gqcnn/examples/policy_with_image_proc.py	/^        camera_intr_filename = os.path.join($/;"	kind:variable	line:101
camera_intr_filename	../gqcnn/examples/policy_with_image_proc.py	/^    camera_intr_filename = args.camera_intrinsics$/;"	kind:variable	line:91
camera_intr_filename	../perception/tools/capture_dataset.py	/^            camera_intr_filename = os.path.join(raw_dir, 'camera_intr.intr')$/;"	kind:variable	line:273
camera_intr_filename	../perception/tools/compute_normal_cloud_im.py	/^    camera_intr_filename = sys.argv[2]$/;"	kind:variable	line:23
camera_intr_obj	../panda_autograsp/scripts/chessboard_calibration.py	/^        camera_intr_obj = CameraIntrinsics("none", f_x, f_y, c_x, c_y, s)$/;"	kind:variable	line:409
camera_intrinsics.py	../perception/perception/camera_intrinsics.py	1;"	kind:file	line:1
camera_intrs	../perception/tools/capture_dataset.py	/^    camera_intrs = {}$/;"	kind:variable	line:219
camera_matrix	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        camera_matrix = sensor.color_intrinsics.K$/;"	kind:variable	line:128
camera_pose_filename	../gqcnn/examples/policy_with_image_proc.py	/^        camera_pose_filename = os.path.join($/;"	kind:variable	line:105
camera_pose_filename	../gqcnn/examples/policy_with_image_proc.py	/^    camera_pose_filename = args.camera_pose$/;"	kind:variable	line:92
camera_pose_filename	../perception/tools/capture_dataset.py	/^            camera_pose_filename = os.path.join(raw_dir, 'T_camera_world.tf')$/;"	kind:variable	line:275
camera_sensor.py	../perception/perception/camera_sensor.py	1;"	kind:file	line:1
can_convert	../perception/perception/image.py	/^    def can_convert(x):$/;"	kind:member	line:292
capture_dataset.py	../perception/tools/capture_dataset.py	1;"	kind:file	line:1
capture_test_images.py	../perception/tools/capture_test_images.py	1;"	kind:file	line:1
cart2sph	../autolab_core/autolab_core/utils.py	/^def cart2sph(x, y, z):$/;"	kind:function	line:231
category	../perception/tools/keras_resnet.py	/^    category = label_to_category[label]$/;"	kind:variable	line:27
category	../perception/tools/keras_vgg.py	/^    category = label_to_category[label]$/;"	kind:variable	line:27
cb_point_data_world	../perception/tools/register_camera.py	/^            cb_point_data_world = cb_points_world.data$/;"	kind:variable	line:269
cb_points_world	../perception/tools/register_camera.py	/^            cb_points_world = T_camera_world * reg_result.cb_points_cam$/;"	kind:variable	line:268
center	../autolab_core/autolab_core/primitives.py	/^    def center(self):$/;"	kind:member	line:99
center	../gqcnn/examples/policy_ros.py	/^        center = Point(np.array([grasp.center_px[0], grasp.center_px[1]]),$/;"	kind:variable	line:139
center	../gqcnn/examples/policy_ros.py	/^        center = Point(np.array([grasp.center_px[0], grasp.center_px[1]]),$/;"	kind:variable	line:147
center	../gqcnn/gqcnn/grasping/grasp.py	/^    def center(self):$/;"	kind:member	line:509
center	../perception/perception/image.py	/^    def center(self):$/;"	kind:member	line:179
center_nonzero	../perception/perception/image.py	/^    def center_nonzero(self):$/;"	kind:member	line:780
cfg	../autolab_core/tools/aggregate_tensor_datasets.py	/^    cfg = YamlConfig(config_filename)$/;"	kind:variable	line:49
cfg	../gqcnn/ros_nodes/grasp_planner_node.py	/^    cfg = YamlConfig(config_filename)$/;"	kind:variable	line:399
cfg	../panda_autograsp/nodes/grasp_planner_server.py	/^    cfg = YamlConfig(config_filename)$/;"	kind:variable	line:242
change_data_sampler_params	../autolab_core/autolab_core/data_stream_recorder.py	/^    def change_data_sampler_params(self, *args, **kwargs):$/;"	kind:member	line:229
channels	../autolab_core/autolab_core/tensor_dataset.py	/^    def channels(self):$/;"	kind:member	line:83
channels	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^                channels = data.shape[3]$/;"	kind:variable	line:54
channels	../perception/perception/image.py	/^    def channels(self):$/;"	kind:member	line:186
chessboard_calibration.py	../panda_autograsp/scripts/chessboard_calibration.py	1;"	kind:file	line:1
chessboard_pose_estimation	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def chessboard_pose_estimation(self):$/;"	kind:member	line:989
chessboard_registration.py	../perception/perception/chessboard_registration.py	1;"	kind:file	line:1
ci	../autolab_core/autolab_core/primitives.py	/^    def ci(self):$/;"	kind:member	line:105
cj	../autolab_core/autolab_core/primitives.py	/^    def cj(self):$/;"	kind:member	line:110
classifiers	../autolab_core/setup.py	/^    classifiers = [$/;"	kind:variable	line:32
classifiers	../gqcnn/setup.py	/^    classifiers=[$/;"	kind:variable	line:176
classifiers	../panda_autograsp/setup.py	/^    classifiers=[$/;"	kind:variable	line:249
classifiers	../perception/setup.py	/^      classifiers = [$/;"	kind:variable	line:35
classifiers	../setup.py	/^    classifiers=[$/;"	kind:variable	line:396
clear_root	../panda_autograsp/src/panda_autograsp/loggers.py	/^    def clear_root():$/;"	kind:member	line:160
clear_root	../panda_autograsp/src/panda_autograsp/loggers.py	/^def clear_root():$/;"	kind:function	line:34
click_gripper	../perception/tools/register_camera.py	/^def click_gripper(event, x, y, flags, param):$/;"	kind:function	line:32
clicked_pt	../perception/tools/register_camera.py	/^                clicked_pt = None$/;"	kind:variable	line:129
clicked_pt	../perception/tools/register_camera.py	/^clicked_pt = None$/;"	kind:variable	line:29
clip_matrix	../autolab_core/autolab_core/transformations.py	/^def clip_matrix(left, right, bottom, top, near, far, perspective=False):$/;"	kind:function	line:572
clip_start	../perception/tools/filter_images.py	/^    clip_start = time.time()$/;"	kind:variable	line:73
close	../perception/perception/feature_extractors.py	/^    def close(self):$/;"	kind:member	line:47
close_gripper_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def close_gripper_service(self, req):$/;"	kind:member	line:745
close_session	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def close_session(self):$/;"	kind:member	line:571
close_session	../perception/perception/cnn.py	/^    def close_session(self):$/;"	kind:member	line:148
closest_allzero_pixel	../perception/perception/image.py	/^    def closest_allzero_pixel(self, pixel, direction, w=13, t=0.5):$/;"	kind:member	line:2569
closest_nonzero_pixel	../perception/perception/image.py	/^    def closest_nonzero_pixel(self, pixel, direction, w=13, t=0.5):$/;"	kind:member	line:2513
closest_pixel_to_set	../perception/perception/image.py	/^    def closest_pixel_to_set(self, start, pixel_set, direction, w=13, t=0.5):$/;"	kind:member	line:2449
cluster_indices	../gqcnn/examples/policy_with_image_proc.py	/^    cluster_indices = ec.Extract()$/;"	kind:variable	line:166
cluster_indices	../perception/tools/filter_images.py	/^    cluster_indices = ec.Extract()$/;"	kind:variable	line:122
cmap	../perception/tools/capture_dataset.py	/^               cmap=plt.cm.gray_r)$/;"	kind:variable	line:193
cmdclass	../gqcnn/setup.py	/^    cmdclass={$/;"	kind:variable	line:190
cmdclass	../panda_autograsp/setup.py	/^    cmdclass={"install": InstallCmd, "develop": DevelopCmd},$/;"	kind:variable	line:287
cmdclass	../setup.py	/^    cmdclass={"install": InstallCmd, "develop": DevelopCmd},$/;"	kind:variable	line:419
cnn	../perception/tools/predict_class_label.py	/^    cnn = ClassificationCNN.open(model_dir, model_typename=model_type)$/;"	kind:variable	line:24
cnn.py	../perception/perception/cnn.py	1;"	kind:file	line:1
color	../gqcnn/examples/policy_with_image_proc.py	/^                     color=(0, 0, 1),$/;"	kind:variable	line:209
color	../gqcnn/tools/run_policy.py	/^                    color="r")$/;"	kind:variable	line:145
color	../gqcnn/tools/run_policy.py	/^                    color="r")$/;"	kind:variable	line:156
color	../panda_autograsp/scripts/kinect_processing.py	/^        color = frames["color"]$/;"	kind:variable	line:125
color	../perception/perception/image.py	/^    def color(self):$/;"	kind:member	line:2881
color	../perception/tools/capture_test_images.py	/^                color = color.resize(rescale_factor)$/;"	kind:variable	line:109
color	../perception/tools/filter_images.py	/^                         color=color,$/;"	kind:variable	line:156
color	../perception/tools/filter_images.py	/^                     color=(0,0,1),$/;"	kind:variable	line:170
color	../perception/tools/filter_images.py	/^                     color=(0,0,1),$/;"	kind:variable	line:98
color	../perception/tools/filter_images.py	/^                     color=(1,0,0),$/;"	kind:variable	line:94
color	../perception/tools/filter_images.py	/^            color = plt.get_cmap('hsv')(float(i)\/num_clusters)[:-1]$/;"	kind:variable	line:153
color_depth_map	../panda_autograsp/scripts/kinect_processing.py	/^            color_depth_map=color_depth_map,$/;"	kind:variable	line:136
color_depth_map	../panda_autograsp/scripts/kinect_processing.py	/^    color_depth_map = ($/;"	kind:variable	line:114
color_frame	../perception/perception/camera_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:143
color_frame	../perception/perception/colorized_phoxi_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:70
color_frame	../perception/perception/kinect2_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:160
color_frame	../perception/perception/kinect2_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:657
color_frame	../perception/perception/phoxi_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:97
color_frame	../perception/perception/primesense_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:97
color_frame	../perception/perception/realsense_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:151
color_frame	../perception/perception/webcam_sensor.py	/^    def color_frame(self):$/;"	kind:member	line:64
color_im	../gqcnn/examples/antipodal_grasp_sampling.py	/^    color_im = color_im.inpaint(rescale_factor=inpaint_rescale_factor)$/;"	kind:variable	line:82
color_im	../gqcnn/examples/policy.py	/^    color_im = ColorImage(np.zeros([depth_im.height, depth_im.width,$/;"	kind:variable	line:195
color_im	../gqcnn/examples/policy_ros.py	/^    color_im = ColorImage(np.zeros([depth_im.height, depth_im.width,$/;"	kind:variable	line:122
color_im	../gqcnn/examples/policy_with_image_proc.py	/^    color_im = ColorImage(np.zeros([depth_im.height, depth_im.width,$/;"	kind:variable	line:135
color_im	../perception/perception/detector.py	/^    def color_im(self):$/;"	kind:member	line:66
color_im	../perception/perception/object_render.py	/^    def color_im(self):$/;"	kind:member	line:99
color_im	../perception/tools/primesense_viewer.py	/^    color_im = color_im.inpaint(rescale_factor=0.5)$/;"	kind:variable	line:35
color_im_filename	../perception/tools/capture_dataset.py	/^                color_im_filename = os.path.join(raw_dir, 'color_%d.png' %(k))$/;"	kind:variable	line:371
color_img	../panda_autograsp/scripts/kinect_processing.py	/^        color_img = cv2.imshow($/;"	kind:variable	line:146
color_intr	../panda_autograsp/scripts/chessboard_calibration.py	/^        color_intr = sensor.color_intrinsics$/;"	kind:variable	line:420
color_intrinsics	../perception/perception/camera_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:155
color_intrinsics	../perception/perception/colorized_phoxi_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:46
color_intrinsics	../perception/perception/kinect2_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:126
color_intrinsics	../perception/perception/kinect2_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:669
color_intrinsics	../perception/perception/phoxi_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:73
color_intrinsics	../perception/perception/primesense_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:67
color_intrinsics	../perception/perception/realsense_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:119
color_intrinsics	../perception/perception/webcam_sensor.py	/^    def color_intrinsics(self):$/;"	kind:member	line:46
color_mtx	../panda_autograsp/scripts/chessboard_calibration.py	/^        color_mtx = color_intr.K$/;"	kind:variable	line:422
colorize_phoxi.py	../perception/tools/colorize_phoxi.py	1;"	kind:file	line:1
colorized_phoxi_sensor.py	../perception/perception/colorized_phoxi_sensor.py	1;"	kind:file	line:1
combine_with	../perception/perception/image.py	/^    def combine_with(self, depth_im):$/;"	kind:member	line:1820
combine_with	../perception/perception/image.py	/^    def combine_with(self, rgbd_im):$/;"	kind:member	line:3016
commander	../franka_ros/franka_example_controllers/scripts/move_to_start.py	/^    commander = MoveGroupCommander('panda_arm')$/;"	kind:variable	line:10
complete	../autolab_core/autolab_core/completer.py	/^    def complete(self, text, state):$/;"	kind:member	line:58
complete_extra	../autolab_core/autolab_core/completer.py	/^    def complete_extra(self, args):$/;"	kind:member	line:51
completer.py	../autolab_core/autolab_core/completer.py	1;"	kind:file	line:1
compliance_param.cfg	../franka_ros/franka_example_controllers/cfg/compliance_param.cfg	1;"	kind:file	line:1
compose_matrix	../autolab_core/autolab_core/transformations.py	/^def compose_matrix(scale=None, shear=None, angles=None, translate=None,$/;"	kind:function	line:785
compute_dataset_statistics	../autolab_core/tools/compute_dataset_statistics.py	/^def compute_dataset_statistics(dataset_path,$/;"	kind:function	line:46
compute_dataset_statistics.py	../autolab_core/tools/compute_dataset_statistics.py	1;"	kind:file	line:1
compute_grasp_service	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def compute_grasp_service(self, req):$/;"	kind:member	line:563
compute_normal_cloud_im.py	../perception/tools/compute_normal_cloud_im.py	1;"	kind:file	line:1
concatenate_matrices	../autolab_core/autolab_core/transformations.py	/^def concatenate_matrices(*matrices):$/;"	kind:function	line:1649
conf.py	../autolab_core/docs/source/conf.py	1;"	kind:file	line:1
conf.py	../docs/source/conf.py	1;"	kind:file	line:1
conf.py	../gqcnn/docs/source/conf.py	1;"	kind:file	line:1
conf.py	../moveit_tutorials/conf.py	1;"	kind:file	line:1
conf.py	../perception/docs/source/conf.py	1;"	kind:file	line:1
config	../autolab_core/autolab_core/tensor_dataset.py	/^    def config(self):$/;"	kind:member	line:348
config	../autolab_core/tools/compute_dataset_statistics.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:193
config	../gqcnn/examples/antipodal_grasp_sampling.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:61
config	../gqcnn/examples/policy.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:177
config	../gqcnn/examples/policy_with_image_proc.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:114
config	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def config(self):$/;"	kind:member	line:1112
config	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def config(self):$/;"	kind:member	line:1269
config	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def config(self):$/;"	kind:member	line:961
config	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def config(self):$/;"	kind:member	line:313
config	../gqcnn/tools/analyze_gqcnn_performance.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:114
config	../gqcnn/tools/run_policy.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:89
config	../perception/tools/analyze_cnn_classification.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:236
config	../perception/tools/capture_dataset.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:156
config	../perception/tools/capture_test_images.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:30
config	../perception/tools/finetune_classification_cnn.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:215
config	../perception/tools/register_camera.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:46
config	../perception/tools/register_ensenso.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:158
config	../perception/tools/register_object.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:29
config	../perception/tools/register_webcam.py	/^    config = YamlConfig(config_filename)$/;"	kind:variable	line:26
config_dict	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    config_dict = pickle.load(config_dict_file)  # Load the aruco board settings$/;"	kind:variable	line:63
config_dict	../panda_autograsp/scripts/generate_arucoboard.py	/^    config_dict = {$/;"	kind:variable	line:73
config_filename	../autolab_core/tools/aggregate_tensor_datasets.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:46
config_filename	../autolab_core/tools/compute_dataset_statistics.py	/^        config_filename = os.path.join(os.getcwd(), config_filename)$/;"	kind:variable	line:190
config_filename	../autolab_core/tools/compute_dataset_statistics.py	/^        config_filename = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:184
config_filename	../autolab_core/tools/compute_dataset_statistics.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:167
config_filename	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    config_filename = os.path.join(dataset_dir, 'config.json')$/;"	kind:variable	line:63
config_filename	../gqcnn/examples/antipodal_grasp_sampling.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:58
config_filename	../gqcnn/examples/policy.py	/^                config_filename = os.path.join($/;"	kind:variable	line:158
config_filename	../gqcnn/examples/policy.py	/^                config_filename = os.path.join($/;"	kind:variable	line:162
config_filename	../gqcnn/examples/policy.py	/^                config_filename = os.path.join($/;"	kind:variable	line:168
config_filename	../gqcnn/examples/policy.py	/^                config_filename = os.path.join($/;"	kind:variable	line:172
config_filename	../gqcnn/examples/policy.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:99
config_filename	../gqcnn/examples/policy_with_image_proc.py	/^        config_filename = os.path.join($/;"	kind:variable	line:109
config_filename	../gqcnn/examples/policy_with_image_proc.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:94
config_filename	../gqcnn/ros_nodes/grasp_planner_node.py	/^    config_filename = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:390
config_filename	../gqcnn/tools/analyze_gqcnn_performance.py	/^        config_filename = os.path.join($/;"	kind:variable	line:96
config_filename	../gqcnn/tools/analyze_gqcnn_performance.py	/^        config_filename = os.path.join(os.getcwd(), config_filename)$/;"	kind:variable	line:104
config_filename	../gqcnn/tools/analyze_gqcnn_performance.py	/^        config_filename = os.path.join(os.getcwd(), dataset_config_filename)$/;"	kind:variable	line:107
config_filename	../gqcnn/tools/analyze_gqcnn_performance.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:74
config_filename	../gqcnn/tools/finetune.py	/^        config_filename = os.path.join($/;"	kind:variable	line:119
config_filename	../gqcnn/tools/finetune.py	/^        config_filename = os.path.join(os.getcwd(), config_filename)$/;"	kind:variable	line:136
config_filename	../gqcnn/tools/finetune.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:106
config_filename	../gqcnn/tools/run_policy.py	/^        config_filename = os.path.join($/;"	kind:variable	line:80
config_filename	../gqcnn/tools/run_policy.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:70
config_filename	../gqcnn/tools/train.py	/^        config_filename = os.path.join($/;"	kind:variable	line:108
config_filename	../gqcnn/tools/train.py	/^        config_filename = os.path.join(os.getcwd(), config_filename)$/;"	kind:variable	line:118
config_filename	../gqcnn/tools/train.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:96
config_filename	../panda_autograsp/nodes/grasp_planner_server.py	/^            config_filename = os.path.abspath($/;"	kind:variable	line:192
config_filename	../panda_autograsp/nodes/grasp_planner_server.py	/^            config_filename = os.path.abspath($/;"	kind:variable	line:202
config_filename	../panda_autograsp/nodes/grasp_planner_server.py	/^            config_filename = os.path.abspath($/;"	kind:variable	line:217
config_filename	../panda_autograsp/nodes/grasp_planner_server.py	/^            config_filename = os.path.abspath($/;"	kind:variable	line:227
config_filename	../perception/tools/analyze_cnn_classification.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:227
config_filename	../perception/tools/capture_dataset.py	/^        config_filename = os.path.join(os.getcwd(), config_filename)$/;"	kind:variable	line:152
config_filename	../perception/tools/capture_dataset.py	/^        config_filename = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:146
config_filename	../perception/tools/capture_dataset.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:138
config_filename	../perception/tools/capture_test_images.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:26
config_filename	../perception/tools/finetune_classification_cnn.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:212
config_filename	../perception/tools/register_camera.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:45
config_filename	../perception/tools/register_ensenso.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:157
config_filename	../perception/tools/register_object.py	/^    config_filename = 'cfg\/tools\/register_object.yaml'$/;"	kind:variable	line:28
config_filename	../perception/tools/register_webcam.py	/^    config_filename = args.config_filename$/;"	kind:variable	line:25
config_save_str	../panda_autograsp/scripts/generate_arucoboard.py	/^    config_save_str = os.path.abspath($/;"	kind:variable	line:82
configure_root	../autolab_core/autolab_core/logger.py	/^def configure_root():$/;"	kind:function	line:14
configure_root	../panda_autograsp/src/panda_autograsp/loggers.py	/^def configure_root(log_level=ROOT_LOG_LEVEL):$/;"	kind:function	line:57
confusion_matrix	../autolab_core/autolab_core/learning_analysis.py	/^    def confusion_matrix(self):$/;"	kind:member	line:120
conjugate	../autolab_core/autolab_core/dual_quaternion.py	/^    def conjugate(self):$/;"	kind:member	line:89
constants.py	../autolab_core/autolab_core/constants.py	1;"	kind:file	line:1
constants.py	../perception/perception/constants.py	1;"	kind:file	line:1
constants.py	../perception/tests/constants.py	1;"	kind:file	line:1
constraint_fn	../gqcnn/gqcnn/grasping/constraint_fn.py	/^    def constraint_fn(fn_type, config):$/;"	kind:member	line:126
constraint_fn.py	../gqcnn/gqcnn/grasping/constraint_fn.py	1;"	kind:file	line:1
construct_internal_dirs	../autolab_core/autolab_core/experiment_logger.py	/^    def construct_internal_dirs(self, dirs, realize=False):$/;"	kind:member	line:140
construct_internal_dirs_group	../autolab_core/autolab_core/experiment_logger.py	/^    def construct_internal_dirs_group(self, group_dirs):$/;"	kind:member	line:149
contour_mask	../perception/perception/image.py	/^    def contour_mask(self, contour):$/;"	kind:member	line:2414
conv	../perception/perception/cnn.py	/^def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding="VALID", group=1):$/;"	kind:function	line:14
conversions.py	../panda_autograsp/src/panda_autograsp/functions/conversions.py	1;"	kind:file	line:1
convert_calib_pose_to_urdf_format.py	../iai_kinect2/kinect2_calibration/scripts/convert_calib_pose_to_urdf_format.py	1;"	kind:file	line:1
convert_labels	../autolab_core/autolab_core/learning_analysis.py	/^    def convert_labels(self, mapping):$/;"	kind:member	line:131
convert_legacy_dataset_to_tensor_dataset.py	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	1;"	kind:file	line:1
copy	../autolab_core/autolab_core/dual_quaternion.py	/^    def copy(self):$/;"	kind:member	line:118
copy	../autolab_core/autolab_core/points.py	/^    def copy(self):$/;"	kind:member	line:101
copy	../autolab_core/autolab_core/rigid_transformations.py	/^    def copy(self):$/;"	kind:member	line:81
copy	../perception/perception/image.py	/^    def copy(self):$/;"	kind:member	line:680
copy_dirs	../autolab_core/autolab_core/experiment_logger.py	/^    def copy_dirs(self, src_dirs_path, target_dirs):$/;"	kind:member	line:208
copy_to_dir	../autolab_core/autolab_core/experiment_logger.py	/^    def copy_to_dir(self, src_file_path, target_dirs):$/;"	kind:member	line:200
copyright	../autolab_core/docs/source/conf.py	/^copyright = u'2016, Jeff Mahler'$/;"	kind:variable	line:58
copyright	../docs/source/conf.py	/^copyright = "2019, Rick Staa"$/;"	kind:variable	line:26
copyright	../gqcnn/docs/source/conf.py	/^copyright = u"2019, The Regents of the University of California"$/;"	kind:variable	line:61
copyright	../perception/docs/source/conf.py	/^copyright = u'2016, Jeff Mahler'$/;"	kind:variable	line:58
core_q_to_ros_q	../autolab_core/autolab_core/rigid_transformations.py	/^    def core_q_to_ros_q(q_core):$/;"	kind:member	line:609
corner_px	../perception/tools/register_webcam.py	/^            corner_px = resized_color_im.find_chessboard(sx=nx, sy=ny)$/;"	kind:variable	line:55
corners2	../panda_autograsp/scripts/chessboard_calibration.py	/^                    corners2 = cv2.cornerSubPix($/;"	kind:variable	line:171
corners2	../panda_autograsp/scripts/chessboard_calibration.py	/^            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)$/;"	kind:variable	line:505
correct_indices	../autolab_core/autolab_core/learning_analysis.py	/^    def correct_indices(self):$/;"	kind:member	line:128
cpu_cores	../gqcnn/gqcnn/search/resource_manager.py	/^    def cpu_cores(self):$/;"	kind:member	line:96
cpu_cores	../gqcnn/tools/hyperparam_search.py	/^                         cpu_cores=cpu_cores,$/;"	kind:variable	line:126
cpu_cores	../gqcnn/tools/hyperparam_search.py	/^    cpu_cores = [int(core) for core in args.cpu_cores]$/;"	kind:variable	line:91
criteria	../panda_autograsp/scripts/chessboard_calibration.py	/^criteria = ($/;"	kind:variable	line:45
crop	../perception/perception/camera_intrinsics.py	/^    def crop(self, height, width, crop_ci, crop_cj):$/;"	kind:member	line:184
crop	../perception/perception/image.py	/^    def crop(self, height, width, center_i=None, center_j=None):$/;"	kind:member	line:2951
crop	../perception/perception/image.py	/^    def crop(self, height, width, center_i=None, center_j=None):$/;"	kind:member	line:3049
crop	../perception/perception/image.py	/^    def crop(self, height, width, center_i=None, center_j=None):$/;"	kind:member	line:3203
crop	../perception/perception/image.py	/^    def crop(self, height, width, center_i=None, center_j=None):$/;"	kind:member	line:690
cropped_ir_intrinsics	../perception/perception/detector.py	/^    def cropped_ir_intrinsics(self):$/;"	kind:member	line:86
cross_entropy_loss	../autolab_core/autolab_core/learning_analysis.py	/^    def cross_entropy_loss(self):$/;"	kind:member	line:451
csv_model.py	../autolab_core/autolab_core/csv_model.py	1;"	kind:file	line:1
cur_i	../gqcnn/examples/policy_with_image_proc.py	/^    cur_i = 0$/;"	kind:variable	line:172
cur_i	../perception/tools/filter_images.py	/^        cur_i = cur_i + num_points$/;"	kind:variable	line:138
cur_i	../perception/tools/filter_images.py	/^    cur_i = 0$/;"	kind:variable	line:127
cv_bridge	../gqcnn/examples/policy_ros.py	/^    cv_bridge = CvBridge()$/;"	kind:variable	line:115
cv_bridge	../gqcnn/ros_nodes/grasp_planner_node.py	/^    cv_bridge = CvBridge()$/;"	kind:variable	line:359
cv_bridge	../panda_autograsp/nodes/grasp_planner_server.py	/^    cv_bridge = CvBridge()$/;"	kind:variable	line:91
cx	../perception/perception/camera_intrinsics.py	/^    def cx(self):$/;"	kind:member	line:80
cx	../perception/perception/camera_intrinsics.py	/^    def cx(self, z):$/;"	kind:member	line:86
cy	../perception/perception/camera_intrinsics.py	/^    def cy(self):$/;"	kind:member	line:93
cy	../perception/perception/camera_intrinsics.py	/^    def cy(self, z):$/;"	kind:member	line:99
data	../autolab_core/autolab_core/points.py	/^    def data(self):$/;"	kind:member	line:80
data	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^            data = np.load(filename)['arr_0']$/;"	kind:variable	line:42
data	../perception/perception/image.py	/^    def data(self):$/;"	kind:member	line:206
data_dir	../autolab_core/tools/list_watertight_meshes.py	/^    data_dir = sys.argv[1]$/;"	kind:variable	line:34
data_files	../panda_autograsp/setup.py	/^    data_files=[$/;"	kind:variable	line:272
data_slice	../autolab_core/autolab_core/tensor_dataset.py	/^    def data_slice(self, slice_ind):$/;"	kind:member	line:153
data_stream_recorder.py	../autolab_core/autolab_core/data_stream_recorder.py	1;"	kind:file	line:1
data_stream_syncer.py	../autolab_core/autolab_core/data_stream_syncer.py	1;"	kind:file	line:1
datapoint	../autolab_core/autolab_core/tensor_dataset.py	/^    def datapoint(self, ind):$/;"	kind:member	line:141
datapoint	../autolab_core/autolab_core/tensor_dataset.py	/^    def datapoint(self, ind, field_names=None):$/;"	kind:member	line:533
datapoint	../autolab_core/tools/aggregate_tensor_datasets.py	/^                datapoint = dataset.datapoint(i, field_names=alt_field_names)$/;"	kind:variable	line:93
datapoint	../autolab_core/tools/aggregate_tensor_datasets.py	/^                datapoint = dataset.datapoint(i, field_names=field_names)$/;"	kind:variable	line:91
datapoint	../autolab_core/tools/shuffle_tensor_dataset.py	/^        datapoint = dataset[j]$/;"	kind:variable	line:55
datapoint	../autolab_core/tools/subsample_tensor_dataset.py	/^        datapoint = dataset[i]$/;"	kind:variable	line:61
datapoint	../perception/tools/capture_dataset.py	/^            datapoint = dataset.datapoint_template$/;"	kind:variable	line:312
datapoint_indices	../autolab_core/autolab_core/tensor_dataset.py	/^    def datapoint_indices(self):$/;"	kind:member	line:384
datapoint_indices_for_tensor	../autolab_core/autolab_core/tensor_dataset.py	/^    def datapoint_indices_for_tensor(self, tensor_index):$/;"	kind:member	line:415
datapoint_template	../autolab_core/autolab_core/tensor_dataset.py	/^    def datapoint_template(self):$/;"	kind:member	line:380
datapoints_per_file	../autolab_core/autolab_core/tensor_dataset.py	/^    def datapoints_per_file(self):$/;"	kind:member	line:368
datapoints_per_file	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^                datapoints_per_file = data.shape[0]$/;"	kind:variable	line:44
datapoints_per_file	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    datapoints_per_file = None$/;"	kind:variable	line:29
datapoints_per_tensor	../autolab_core/autolab_core/tensor_dataset.py	/^    def datapoints_per_tensor(self):$/;"	kind:member	line:372
dataset	../autolab_core/tools/aggregate_tensor_datasets.py	/^        dataset = TensorDataset.open(dataset_name)$/;"	kind:variable	line:85
dataset	../autolab_core/tools/aggregate_tensor_datasets.py	/^    dataset = TensorDataset.open(all_input_dataset_names[0])$/;"	kind:variable	line:66
dataset	../autolab_core/tools/print_dataset_size.py	/^    dataset = TensorDataset.open(sys.argv[1])$/;"	kind:variable	line:32
dataset	../autolab_core/tools/shuffle_tensor_dataset.py	/^    dataset = TensorDataset.open(dataset_path)$/;"	kind:variable	line:47
dataset	../autolab_core/tools/split_dataset.py	/^    dataset = TensorDataset.open(dataset_dir)$/;"	kind:variable	line:59
dataset	../autolab_core/tools/subsample_tensor_dataset.py	/^    dataset = TensorDataset.open(dataset_path)$/;"	kind:variable	line:49
dataset	../perception/tools/capture_dataset.py	/^            dataset = datasets[sensor_name]$/;"	kind:variable	line:310
dataset_config	../gqcnn/tools/analyze_gqcnn_performance.py	/^        dataset_config = YamlConfig(dataset_config_filename)$/;"	kind:variable	line:118
dataset_config	../gqcnn/tools/analyze_gqcnn_performance.py	/^    dataset_config = None$/;"	kind:variable	line:116
dataset_config	../perception/tools/capture_dataset.py	/^    dataset_config = config['dataset']$/;"	kind:variable	line:157
dataset_config_filename	../gqcnn/tools/analyze_gqcnn_performance.py	/^    dataset_config_filename = args.dataset_config_filename$/;"	kind:variable	line:73
dataset_dir	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    dataset_dir = args.dataset_dir$/;"	kind:variable	line:23
dataset_dir	../autolab_core/tools/split_dataset.py	/^    dataset_dir = args.dataset_dir$/;"	kind:variable	line:53
dataset_dir	../gqcnn/tools/finetune.py	/^        dataset_dir = os.path.join(os.getcwd(), dataset_dir)$/;"	kind:variable	line:130
dataset_dir	../gqcnn/tools/finetune.py	/^    dataset_dir = args.dataset_dir$/;"	kind:variable	line:100
dataset_dir	../gqcnn/tools/train.py	/^        dataset_dir = os.path.join(os.getcwd(), dataset_dir)$/;"	kind:variable	line:114
dataset_dir	../gqcnn/tools/train.py	/^    dataset_dir = args.dataset_dir$/;"	kind:variable	line:91
dataset_grasped_obj_id	../autolab_core/tools/aggregate_tensor_datasets.py	/^                dataset_grasped_obj_id = datapoint['grasped_obj_ids']$/;"	kind:variable	line:113
dataset_obj_id	../autolab_core/tools/aggregate_tensor_datasets.py	/^                    dataset_obj_id = datapoint['obj_ids'][k]$/;"	kind:variable	line:104
dataset_obj_ids	../autolab_core/tools/aggregate_tensor_datasets.py	/^                dataset_obj_ids = dataset.metadata['obj_ids']$/;"	kind:variable	line:102
dataset_obj_ids	../autolab_core/tools/aggregate_tensor_datasets.py	/^            dataset_obj_ids = dataset.metadata['obj_ids']$/;"	kind:variable	line:87
dataset_obj_key	../autolab_core/tools/aggregate_tensor_datasets.py	/^                        dataset_obj_key = dataset_obj_ids[str(dataset_obj_id)]$/;"	kind:variable	line:106
dataset_path	../autolab_core/tools/compute_dataset_statistics.py	/^    dataset_path = args.dataset_path$/;"	kind:variable	line:164
dataset_path	../autolab_core/tools/shuffle_tensor_dataset.py	/^    dataset_path = args.dataset_path$/;"	kind:variable	line:44
dataset_path	../autolab_core/tools/subsample_tensor_dataset.py	/^    dataset_path = args.dataset_path$/;"	kind:variable	line:45
dataset_path	../perception/tools/analyze_cnn_classification.py	/^    dataset_path = args.dataset_path$/;"	kind:variable	line:226
dataset_subdirs	../autolab_core/tools/aggregate_tensor_datasets.py	/^            dataset_subdirs = utils.filenames(dataset_name,$/;"	kind:variable	line:61
datasets	../gqcnn/tools/hyperparam_search.py	/^    datasets = args.datasets$/;"	kind:variable	line:84
datasets	../perception/tools/capture_dataset.py	/^    datasets = {}$/;"	kind:variable	line:216
date_files_relative_path	../panda_autograsp/setup.py	/^date_files_relative_path = os.path.join(relative_site_packages, "panda_autograsp")$/;"	kind:variable	line:29
debug	../autolab_core/tools/compute_dataset_statistics.py	/^    debug = args.debug$/;"	kind:variable	line:166
decompose_matrix	../autolab_core/autolab_core/transformations.py	/^def decompose_matrix(matrix):$/;"	kind:function	line:700
default	../autolab_core/autolab_core/json_serialization.py	/^    def default(self, obj):$/;"	kind:member	line:15
default	../gqcnn/examples/antipodal_grasp_sampling.py	/^                        default="cfg\/examples\/antipodal_grasp_sampling.yaml",$/;"	kind:variable	line:55
default	../gqcnn/examples/policy.py	/^                        default=None,$/;"	kind:variable	line:65
default	../gqcnn/examples/policy.py	/^                        default=None,$/;"	kind:variable	line:74
default	../gqcnn/examples/policy.py	/^                        default=None,$/;"	kind:variable	line:78
default	../gqcnn/examples/policy.py	/^                        default=None,$/;"	kind:variable	line:82
default	../gqcnn/examples/policy.py	/^                        default=None,$/;"	kind:variable	line:86
default	../gqcnn/examples/policy.py	/^        default=None,$/;"	kind:variable	line:70
default	../gqcnn/examples/policy_ros.py	/^                        default="gqcnn",$/;"	kind:variable	line:80
default	../gqcnn/examples/policy_ros.py	/^                        default=0.05,$/;"	kind:variable	line:76
default	../gqcnn/examples/policy_ros.py	/^                        default=None,$/;"	kind:variable	line:68
default	../gqcnn/examples/policy_ros.py	/^                        default=None,$/;"	kind:variable	line:72
default	../gqcnn/examples/policy_ros.py	/^                        default=True,$/;"	kind:variable	line:84
default	../gqcnn/examples/policy_ros.py	/^        default=None,$/;"	kind:variable	line:64
default	../gqcnn/examples/policy_with_image_proc.py	/^                        default=None,$/;"	kind:variable	line:70
default	../gqcnn/examples/policy_with_image_proc.py	/^                        default=None,$/;"	kind:variable	line:74
default	../gqcnn/examples/policy_with_image_proc.py	/^                        default=None,$/;"	kind:variable	line:78
default	../gqcnn/examples/policy_with_image_proc.py	/^                        default=None,$/;"	kind:variable	line:82
default	../gqcnn/examples/policy_with_image_proc.py	/^                        default=None,$/;"	kind:variable	line:86
default	../gqcnn/examples/policy_with_image_proc.py	/^        default=None,$/;"	kind:variable	line:66
default	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        default=None,$/;"	kind:variable	line:51
default	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        default=None,$/;"	kind:variable	line:55
default	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        default=None,$/;"	kind:variable	line:64
default	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        default=None,$/;"	kind:variable	line:68
default	../gqcnn/tools/analyze_gqcnn_performance.py	/^        default=None,$/;"	kind:variable	line:60
default	../gqcnn/tools/finetune.py	/^                        default="image_wise",$/;"	kind:variable	line:63
default	../gqcnn/tools/finetune.py	/^                        default="tf",$/;"	kind:variable	line:97
default	../gqcnn/tools/finetune.py	/^                        default=None,$/;"	kind:variable	line:59
default	../gqcnn/tools/finetune.py	/^                        default=None,$/;"	kind:variable	line:67
default	../gqcnn/tools/finetune.py	/^                        default=None,$/;"	kind:variable	line:71
default	../gqcnn/tools/finetune.py	/^                        default=None,$/;"	kind:variable	line:75
default	../gqcnn/tools/finetune.py	/^                        default=None,$/;"	kind:variable	line:79
default	../gqcnn/tools/finetune.py	/^                        default=None,$/;"	kind:variable	line:83
default	../gqcnn/tools/finetune.py	/^                        default=None,$/;"	kind:variable	line:87
default	../gqcnn/tools/finetune.py	/^        default=False,$/;"	kind:variable	line:92
default	../gqcnn/tools/finetune.py	/^        default=None,$/;"	kind:variable	line:55
default	../gqcnn/tools/hyperparam_search.py	/^                        default="cfg\/tools\/analyze_gqcnn_performance.yaml")$/;"	kind:variable	line:62
default	../gqcnn/tools/hyperparam_search.py	/^                        default="models",$/;"	kind:variable	line:69
default	../gqcnn/tools/hyperparam_search.py	/^                        default=None,$/;"	kind:variable	line:50
default	../gqcnn/tools/hyperparam_search.py	/^                        default=None,$/;"	kind:variable	line:73
default	../gqcnn/tools/hyperparam_search.py	/^                        default=["cfg\/train.yaml"],$/;"	kind:variable	line:58
default	../gqcnn/tools/hyperparam_search.py	/^                        default=["image_wise"],$/;"	kind:variable	line:65
default	../gqcnn/tools/hyperparam_search.py	/^                        default=[],$/;"	kind:variable	line:54
default	../gqcnn/tools/hyperparam_search.py	/^                        default=[],$/;"	kind:variable	line:77
default	../gqcnn/tools/hyperparam_search.py	/^                        default=[],$/;"	kind:variable	line:81
default	../gqcnn/tools/run_policy.py	/^                        default="cfg\/tools\/run_policy.yaml",$/;"	kind:variable	line:61
default	../gqcnn/tools/run_policy.py	/^                        default=None,$/;"	kind:variable	line:57
default	../gqcnn/tools/run_policy.py	/^                        default=None,$/;"	kind:variable	line:65
default	../gqcnn/tools/train.py	/^                        default="image_wise",$/;"	kind:variable	line:58
default	../gqcnn/tools/train.py	/^                        default="tf",$/;"	kind:variable	line:88
default	../gqcnn/tools/train.py	/^                        default=None,$/;"	kind:variable	line:62
default	../gqcnn/tools/train.py	/^                        default=None,$/;"	kind:variable	line:66
default	../gqcnn/tools/train.py	/^                        default=None,$/;"	kind:variable	line:70
default	../gqcnn/tools/train.py	/^                        default=None,$/;"	kind:variable	line:74
default	../gqcnn/tools/train.py	/^                        default=None,$/;"	kind:variable	line:78
default	../gqcnn/tools/train.py	/^        default=False,$/;"	kind:variable	line:83
default	../gqcnn/tools/train.py	/^        default=None,$/;"	kind:variable	line:54
delete_from_ros	../autolab_core/autolab_core/rigid_transformations.py	/^    def delete_from_ros(self, service_name='rigid_transforms\/rigid_transform_publisher', namespace=None):$/;"	kind:member	line:560
delete_last	../autolab_core/autolab_core/tensor_dataset.py	/^    def delete_last(self):$/;"	kind:member	line:135
delete_last	../autolab_core/autolab_core/tensor_dataset.py	/^    def delete_last(self, num_to_delete=1):$/;"	kind:member	line:617
delete_split	../autolab_core/autolab_core/tensor_dataset.py	/^    def delete_split(self, split_name):$/;"	kind:member	line:878
deproject	../perception/perception/camera_intrinsics.py	/^    def deproject(self, depth_image):$/;"	kind:member	line:335
deproject	../perception/perception/orthographic_intrinsics.py	/^    def deproject(self, depth_image):$/;"	kind:member	line:193
deproject_pixel	../perception/perception/camera_intrinsics.py	/^    def deproject_pixel(self, depth, pixel):$/;"	kind:member	line:396
deproject_pixel	../perception/perception/orthographic_intrinsics.py	/^    def deproject_pixel(self, depth, pixel):$/;"	kind:member	line:254
deproject_start	../perception/tools/filter_images.py	/^    deproject_start = time.time()$/;"	kind:variable	line:64
deproject_to_image	../perception/perception/camera_intrinsics.py	/^    def deproject_to_image(self, depth_image):$/;"	kind:member	line:372
deproject_to_image	../perception/perception/orthographic_intrinsics.py	/^    def deproject_to_image(self, depth_image):$/;"	kind:member	line:230
depth	../gqcnn/gqcnn/grasping/grasp.py	/^    def depth(self):$/;"	kind:member	line:540
depth	../panda_autograsp/scripts/kinect_processing.py	/^        depth = frames["depth"]$/;"	kind:variable	line:127
depth	../perception/perception/image.py	/^    def depth(self):$/;"	kind:member	line:2887
depth	../perception/perception/image.py	/^    def depth(self):$/;"	kind:member	line:3159
depth	../perception/tools/capture_test_images.py	/^                depth = depth.resize(rescale_factor, interp='nearest')$/;"	kind:variable	line:110
depth	../perception/tools/register_camera.py	/^                depth = depth_im[clicked_pt[1], clicked_pt[0]]$/;"	kind:variable	line:157
depth_data	../gqcnn/examples/policy.py	/^    depth_data = np.load(depth_im_filename)$/;"	kind:variable	line:193
depth_data	../gqcnn/examples/policy_with_image_proc.py	/^    depth_data = depth_data.astype(np.float32) \/ 1000.0$/;"	kind:variable	line:133
depth_data	../gqcnn/examples/policy_with_image_proc.py	/^    depth_data = np.load(depth_im_filename)$/;"	kind:variable	line:132
depth_im	../gqcnn/examples/antipodal_grasp_sampling.py	/^    depth_im = depth_im.inpaint(rescale_factor=inpaint_rescale_factor)$/;"	kind:variable	line:83
depth_im	../gqcnn/examples/policy.py	/^    depth_im = DepthImage(depth_data, frame=camera_intr.frame)$/;"	kind:variable	line:194
depth_im	../gqcnn/examples/policy.py	/^    depth_im = depth_im.inpaint(rescale_factor=inpaint_rescale_factor)$/;"	kind:variable	line:210
depth_im	../gqcnn/examples/policy_ros.py	/^    depth_im = DepthImage.open(depth_im_filename, frame=camera_intr.frame)$/;"	kind:variable	line:121
depth_im	../gqcnn/examples/policy_with_image_proc.py	/^    depth_im = DepthImage(depth_data, frame=camera_intr.frame)$/;"	kind:variable	line:134
depth_im	../gqcnn/examples/policy_with_image_proc.py	/^    depth_im = depth_im.inpaint(rescale_factor=inpaint_rescale_factor)$/;"	kind:variable	line:189
depth_im	../perception/perception/detector.py	/^    def depth_im(self):$/;"	kind:member	line:72
depth_im	../perception/perception/object_render.py	/^    def depth_im(self):$/;"	kind:member	line:105
depth_im	../perception/tools/compute_normal_cloud_im.py	/^    depth_im = DepthImage.open(depth_im_filename, frame=camera_intr.frame)$/;"	kind:variable	line:26
depth_im	../perception/tools/compute_normal_cloud_im.py	/^    depth_im = depth_im.inpaint()$/;"	kind:variable	line:28
depth_im	../perception/tools/primesense_viewer.py	/^    depth_im = depth_im.inpaint(rescale_factor=0.5)$/;"	kind:variable	line:36
depth_im	../perception/tools/register_camera.py	/^                depth_im = depth_im.inpaint(0.25)$/;"	kind:variable	line:136
depth_im_filename	../gqcnn/examples/policy.py	/^            depth_im_filename = os.path.join($/;"	kind:variable	line:108
depth_im_filename	../gqcnn/examples/policy.py	/^            depth_im_filename = os.path.join($/;"	kind:variable	line:112
depth_im_filename	../gqcnn/examples/policy.py	/^    depth_im_filename = args.depth_image$/;"	kind:variable	line:95
depth_im_filename	../gqcnn/examples/policy_ros.py	/^        depth_im_filename = os.path.join($/;"	kind:variable	line:100
depth_im_filename	../gqcnn/examples/policy_ros.py	/^    depth_im_filename = args.depth_image$/;"	kind:variable	line:87
depth_im_filename	../gqcnn/examples/policy_with_image_proc.py	/^        depth_im_filename = os.path.join($/;"	kind:variable	line:97
depth_im_filename	../gqcnn/examples/policy_with_image_proc.py	/^    depth_im_filename = args.depth_image$/;"	kind:variable	line:89
depth_im_filename	../perception/tools/capture_dataset.py	/^                depth_im_filename = os.path.join(raw_dir, 'depth_%d.npy' %(k))$/;"	kind:variable	line:376
depth_im_filename	../perception/tools/compute_normal_cloud_im.py	/^    depth_im_filename = sys.argv[1]$/;"	kind:variable	line:22
depth_im_filtered	../perception/tools/filter_images.py	/^    depth_im_filtered = depth_im.copy()$/;"	kind:variable	line:54
depth_im_filtered	../perception/tools/filter_images.py	/^    depth_im_filtered = depth_im_filtered.inpaint(0.5)$/;"	kind:variable	line:187
depth_im_filtered	../perception/tools/filter_images.py	/^    depth_im_filtered = small_camera_intr.project_to_image(point_cloud_cam)    $/;"	kind:variable	line:178
depth_im_orig	../perception/tools/filter_images.py	/^    depth_im_orig = depth_im.inpaint(rescale_factor)$/;"	kind:variable	line:55
depth_im_seg	../perception/tools/capture_test_images.py	/^                depth_im_seg = camera_intr.project_to_image(seg_point_cloud_cam)$/;"	kind:variable	line:97
depth_im_table	../perception/perception/detector.py	/^    def depth_im_table(self):$/;"	kind:member	line:82
depth_img	../panda_autograsp/scripts/kinect_processing.py	/^        depth_img = cv2.imshow("depth", depth.asarray() \/ 4500.0)$/;"	kind:variable	line:145
depth_img_msg	../panda_autograsp/nodes/grasp_planner_server.py	/^        depth_img_msg = rospy.wait_for_message($/;"	kind:variable	line:249
depth_segment	../gqcnn/examples/policy_with_image_proc.py	/^        depth_segment = camera_intr.project_to_image(segment)$/;"	kind:variable	line:183
description	../autolab_core/setup.py	/^    description = 'Core utilities for the Berkeley AutoLab',$/;"	kind:variable	line:25
description	../gqcnn/examples/policy.py	/^        description="Run a grasping policy on an example image")$/;"	kind:variable	line:62
description	../gqcnn/examples/policy_ros.py	/^        description="Run a grasping policy on an example image")$/;"	kind:variable	line:60
description	../gqcnn/examples/policy_with_image_proc.py	/^        description="Run a grasping policy on an example image")$/;"	kind:variable	line:62
description	../gqcnn/setup.py	/^    description=("Project code for running Grasp Quality Convolutional"$/;"	kind:variable	line:169
description	../gqcnn/tools/analyze_gqcnn_performance.py	/^        description=("Analyze a Grasp Quality Convolutional Neural Network"$/;"	kind:variable	line:47
description	../gqcnn/tools/hyperparam_search.py	/^        description="Hyper-parameter search for GQ-CNN.")$/;"	kind:variable	line:47
description	../gqcnn/tools/run_policy.py	/^        description=("Run a saved test case through a GQ-CNN policy. For"$/;"	kind:variable	line:53
description	../gqcnn/tools/train.py	/^        description=("Train a Grasp Quality Convolutional Neural Network with"$/;"	kind:variable	line:49
description	../panda_autograsp/setup.py	/^    description=("Project code for the panda_autograsp automatic grasping solution."),$/;"	kind:variable	line:241
description	../perception/setup.py	/^      description='Perception utilities for the Berkeley AutoLab',$/;"	kind:variable	line:29
description	../setup.py	/^    description=("Project code for the panda_autograsp automatic grasping solution."),$/;"	kind:variable	line:390
descriptor	../perception/perception/features.py	/^    def descriptor(self):$/;"	kind:member	line:38
descriptor	../perception/perception/features.py	/^    def descriptor(self):$/;"	kind:member	line:77
descriptors	../perception/perception/features.py	/^    def descriptors(self):$/;"	kind:member	line:170
desired_mass_param.cfg	../franka_ros/franka_example_controllers/cfg/desired_mass_param.cfg	1;"	kind:file	line:1
deskew	../autolab_core/autolab_core/utils.py	/^def deskew(S):$/;"	kind:function	line:126
detect	../perception/perception/detector.py	/^    def detect(self, color_im, depth_im, cfg, camera_intr,$/;"	kind:member	line:435
detect	../perception/perception/detector.py	/^    def detect(self, color_im, depth_im, cfg, camera_intr=None,$/;"	kind:member	line:118
detect	../perception/perception/detector.py	/^    def detect(self, color_im, depth_im, cfg, camera_intr=None,$/;"	kind:member	line:149
detect	../perception/perception/detector.py	/^    def detect(self, color_im, depth_im, cfg, camera_intr=None,$/;"	kind:member	line:300
detectedCorners	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            detectedCorners=corners,$/;"	kind:variable	line:155
detectedIds	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            detectedIds=ids,$/;"	kind:variable	line:156
detector	../perception/perception/detector.py	/^    def detector(detector_type):$/;"	kind:member	line:604
detector.py	../perception/perception/detector.py	1;"	kind:file	line:1
device	../panda_autograsp/scripts/kinect_processing.py	/^    device = fn.openDevice(serial, pipeline=pipeline)$/;"	kind:variable	line:95
dictionary	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            dictionary=ARUCO_DICT,$/;"	kind:variable	line:144
dictionary	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    dictionary=ARUCO_DICT,$/;"	kind:variable	line:74
dictionary	../panda_autograsp/scripts/generate_arucoboard.py	/^        dictionary=ARUCO_DICT,$/;"	kind:variable	line:95
dictionary	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    dictionary=ARUCO_DICT,$/;"	kind:variable	line:122
diff_with_target	../perception/perception/image.py	/^    def diff_with_target(self, binary_im):$/;"	kind:member	line:2697
diffs	../perception/tools/register_camera.py	/^                    diffs = fixed_robot_points_world - true_robot_points_world.data$/;"	kind:variable	line:207
diffs	../perception/tools/register_camera.py	/^                diffs = fixed_robot_points_world - true_robot_points_world.data$/;"	kind:variable	line:193
dim	../autolab_core/autolab_core/points.py	/^    def dim(self):$/;"	kind:member	line:86
dims	../autolab_core/autolab_core/primitives.py	/^    def dims(self):$/;"	kind:member	line:63
dir_world	../perception/tools/register_camera.py	/^            dir_world = dir_world \/ np.linalg.norm(dir_world)$/;"	kind:variable	line:271
dir_world	../perception/tools/register_camera.py	/^            dir_world = dir_world \/ np.linalg.norm(dir_world)$/;"	kind:variable	line:363
dir_world	../perception/tools/register_camera.py	/^            dir_world = np.array([-1.0, 1.0, 0])$/;"	kind:variable	line:270
dir_world	../perception/tools/register_camera.py	/^            dir_world = np.array([1.0, 1.0, 0])$/;"	kind:variable	line:362
dirs	../autolab_core/autolab_core/experiment_logger.py	/^    def dirs(self):$/;"	kind:member	line:137
dirs_to_path	../autolab_core/autolab_core/experiment_logger.py	/^    def dirs_to_path(self, dirs):$/;"	kind:member	line:161
discover_cams	../perception/tools/test_realsense.py	/^def discover_cams():$/;"	kind:function	line:7
display_rate	../autolab_core/tools/aggregate_tensor_datasets.py	/^    display_rate = cfg['display_rate']$/;"	kind:variable	line:52
dist	../panda_autograsp/scripts/chessboard_calibration.py	/^        dist = np.array(ir_mtx)$/;"	kind:variable	line:424
distCoeffs	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            distCoeffs=dist_coeffs,$/;"	kind:variable	line:159
dist_coeffs	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        dist_coeffs = np.array(ir_mtx)$/;"	kind:variable	line:131
dist_metrics.py	../autolab_core/autolab_core/dist_metrics.py	1;"	kind:file	line:1
dist_thresh	../perception/tools/register_camera.py	/^            dist_thresh = 0.0015$/;"	kind:variable	line:183
dists	../perception/tools/register_camera.py	/^                    dists = np.linalg.norm(diffs, axis=0)$/;"	kind:variable	line:208
dists	../perception/tools/register_camera.py	/^                dists = np.linalg.norm(diffs, axis=0)$/;"	kind:variable	line:194
dot	../autolab_core/autolab_core/rigid_transformations.py	/^    def dot(self, other_tf):$/;"	kind:member	line:1187
dot	../autolab_core/autolab_core/rigid_transformations.py	/^    def dot(self, other_tf):$/;"	kind:member	line:394
down	../autolab_core/autolab_core/transformations.py	/^    def down(self, point):$/;"	kind:member	line:1435
download_model	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^def download_model($/;"	kind:function	line:62
drag	../autolab_core/autolab_core/transformations.py	/^    def drag(self, point):$/;"	kind:member	line:1446
draw_axis	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^def draw_axis(img, corners, imgpts):$/;"	kind:function	line:295
draw_box	../perception/perception/image.py	/^    def draw_box(self, box):$/;"	kind:member	line:1317
dst	../panda_autograsp/scripts/chessboard_calibration.py	/^                    dst=dist,$/;"	kind:variable	line:530
dtype	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^            dtype = str(data.dtype)$/;"	kind:variable	line:45
dtype	../perception/ros_nodes/image_buffer.py	/^    dtype = 'float32'$/;"	kind:variable	line:48
dual_quaternion	../autolab_core/autolab_core/rigid_transformations.py	/^    def dual_quaternion(self):$/;"	kind:member	line:207
dual_quaternion.py	../autolab_core/autolab_core/dual_quaternion.py	1;"	kind:file	line:1
dump	../autolab_core/autolab_core/json_serialization.py	/^def dump(*args, **kwargs):$/;"	kind:function	line:63
dync_reconf_callback	../panda_autograsp/src/panda_autograsp/tf2_broadcaster_ros.py	/^    def dync_reconf_callback(self, config, level):$/;"	kind:member	line:198
ec	../gqcnn/examples/policy_with_image_proc.py	/^    ec = pcl_cloud.make_EuclideanClusterExtraction()$/;"	kind:variable	line:161
ec	../perception/tools/filter_images.py	/^    ec = pcl_cloud.make_EuclideanClusterExtraction()$/;"	kind:variable	line:115
encoding	../perception/perception/image.py	/^    def encoding(self):$/;"	kind:member	line:235
endpoints	../gqcnn/gqcnn/grasping/grasp.py	/^    def endpoints(self):$/;"	kind:member	line:134
ensenso_sensor.py	../perception/perception/ensenso_sensor.py	1;"	kind:file	line:1
enums.py	../gqcnn/gqcnn/grasping/policy/enums.py	1;"	kind:file	line:1
enums.py	../gqcnn/gqcnn/search/enums.py	1;"	kind:file	line:1
enums.py	../gqcnn/gqcnn/utils/enums.py	1;"	kind:file	line:1
epsilon	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def epsilon(self):$/;"	kind:member	line:1426
epsilon	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def epsilon(self, val):$/;"	kind:member	line:1430
error	../panda_autograsp/scripts/chessboard_calibration.py	/^            error = cv2.norm(imgpoints[index], imgpoints2, cv2.NORM_L2) \/ len($/;"	kind:variable	line:395
error_msg	../gqcnn/gqcnn/search/trial.py	/^    def error_msg(self):$/;"	kind:member	line:162
error_rate	../autolab_core/autolab_core/learning_analysis.py	/^    def error_rate(self):$/;"	kind:member	line:65
errored_out	../gqcnn/gqcnn/search/trial.py	/^    def errored_out(self):$/;"	kind:member	line:158
est_robot_points_world	../perception/tools/register_camera.py	/^                est_robot_points_world = T_camera_world * PointCloud(np.array(robot_points_camera).T,$/;"	kind:variable	line:234
est_robot_points_world	../perception/tools/register_camera.py	/^            est_robot_points_world = T_camera_world * PointCloud(np.array(robot_points_camera).T,$/;"	kind:variable	line:170
euler	../autolab_core/autolab_core/rigid_transformations.py	/^    def euler(self):$/;"	kind:member	line:230
euler_angles	../autolab_core/autolab_core/rigid_transformations.py	/^    def euler_angles(self):$/;"	kind:member	line:191
euler_from_matrix	../autolab_core/autolab_core/transformations.py	/^def euler_from_matrix(matrix, axes='sxyz'):$/;"	kind:function	line:1031
euler_from_quaternion	../autolab_core/autolab_core/transformations.py	/^def euler_from_quaternion(quaternion, axes='sxyz'):$/;"	kind:function	line:1089
euler_matrix	../autolab_core/autolab_core/transformations.py	/^def euler_matrix(ai, aj, ak, axes='sxyz'):$/;"	kind:function	line:968
exceptions.py	../autolab_core/autolab_core/exceptions.py	1;"	kind:file	line:1
exceptions.py	../perception/perception/exceptions.py	1;"	kind:file	line:1
exclude_patterns	../autolab_core/docs/source/conf.py	/^exclude_patterns = []$/;"	kind:variable	line:85
exclude_patterns	../docs/source/conf.py	/^exclude_patterns = []$/;"	kind:variable	line:94
exclude_patterns	../gqcnn/docs/source/conf.py	/^exclude_patterns = []$/;"	kind:variable	line:88
exclude_patterns	../perception/docs/source/conf.py	/^exclude_patterns = []$/;"	kind:variable	line:85
execute_grasp_service	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def execute_grasp_service(self, req):$/;"	kind:member	line:788
execute_gripper_plan_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def execute_gripper_plan_service(self, req):$/;"	kind:member	line:663
execute_plan_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def execute_plan_service(self, req):$/;"	kind:member	line:581
execute_plan_srv	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        execute_plan_srv = rospy.ServiceProxy($/;"	kind:variable	line:104
execute_policy	../gqcnn/ros_nodes/grasp_planner_node.py	/^    def execute_policy(self, rgbd_image_state, grasping_policy,$/;"	kind:member	line:298
execute_policy	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def execute_policy(self, rgbd_image_state, grasping_policy, pose_frame):$/;"	kind:member	line:581
execute_policy	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    def execute_policy($/;"	kind:member	line:323
experiment_logger.py	../autolab_core/autolab_core/experiment_logger.py	1;"	kind:file	line:1
experiment_meta_data	../autolab_core/autolab_core/experiment_logger.py	/^    def experiment_meta_data(self):$/;"	kind:member	line:126
experiment_meta_headers	../autolab_core/autolab_core/experiment_logger.py	/^    def experiment_meta_headers(self):$/;"	kind:member	line:115
extend	../perception/perception/features.py	/^    def extend(self, features):$/;"	kind:member	line:120
extensions	../autolab_core/docs/source/conf.py	/^extensions = [$/;"	kind:variable	line:33
extensions	../docs/source/conf.py	/^extensions = [$/;"	kind:variable	line:38
extensions	../gqcnn/docs/source/conf.py	/^extensions = ["sphinx.ext.autodoc", "sphinxcontrib.napoleon"]$/;"	kind:variable	line:38
extensions	../moveit_tutorials/conf.py	/^extensions = [ 'sphinx.ext.extlinks',$/;"	kind:variable	line:5
extensions	../perception/docs/source/conf.py	/^extensions = [$/;"	kind:variable	line:33
extlinks	../moveit_tutorials/conf.py	/^extlinks = {'codedir': ('https:\/\/github.com\/' + html_context["github_user"] + '\/moveit_tutorials\/tree\/' + html_context["github_version"] + '\/doc\/%s', ''),$/;"	kind:variable	line:53
extract	../perception/perception/feature_extractors.py	/^    def extract(self, image):$/;"	kind:member	line:22
extract	../perception/perception/feature_extractors.py	/^    def extract(self, images):$/;"	kind:member	line:88
extras_require	../autolab_core/setup.py	/^    extras_require = { 'docs' : [$/;"	kind:variable	line:44
extras_require	../gqcnn/setup.py	/^    extras_require={$/;"	kind:variable	line:187
extras_require	../panda_autograsp/setup.py	/^    extras_require={$/;"	kind:variable	line:259
extras_require	../perception/setup.py	/^      extras_require = { 'docs' : [$/;"	kind:variable	line:47
extras_require	../setup.py	/^    extras_require={$/;"	kind:variable	line:406
f	../perception/tools/register_camera.py	/^        f = open(os.path.join(output_dir, 'corners_cb_%s.npy' %(sensor_frame)), 'w')$/;"	kind:variable	line:257
f1_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def f1_curve(self, delta_tau=0.01):$/;"	kind:member	line:599
f1_score	../autolab_core/autolab_core/learning_analysis.py	/^    def f1_score(self):$/;"	kind:member	line:395
f_x	../panda_autograsp/scripts/chessboard_calibration.py	/^        f_x = color_mtx[0, 0]  # x focal length$/;"	kind:variable	line:367
f_y	../panda_autograsp/scripts/chessboard_calibration.py	/^        f_y = color_mtx[1, 1]  # Y focal length$/;"	kind:variable	line:368
false_negative_indices	../autolab_core/autolab_core/learning_analysis.py	/^    def false_negative_indices(self):$/;"	kind:member	line:415
false_positive_indices	../autolab_core/autolab_core/learning_analysis.py	/^    def false_positive_indices(self):$/;"	kind:member	line:407
fc_network_tf.py	../gqcnn/gqcnn/model/tf/fc_network_tf.py	1;"	kind:file	line:1
fc_policy.py	../gqcnn/gqcnn/grasping/policy/fc_policy.py	1;"	kind:file	line:1
feature	../perception/perception/features.py	/^    def feature(self, index):$/;"	kind:member	line:131
feature_extractors.py	../perception/perception/feature_extractors.py	1;"	kind:file	line:1
feature_matcher.py	../perception/perception/feature_matcher.py	1;"	kind:file	line:1
feature_subset	../perception/perception/features.py	/^    def feature_subset(self, indices):$/;"	kind:member	line:147
feature_vec	../gqcnn/gqcnn/grasping/grasp.py	/^    def feature_vec(self):$/;"	kind:member	line:141
feature_vec	../gqcnn/gqcnn/grasping/grasp.py	/^    def feature_vec(self):$/;"	kind:member	line:347
feature_vec	../gqcnn/gqcnn/grasping/grasp.py	/^    def feature_vec(self):$/;"	kind:member	line:559
features.py	../perception/perception/features.py	1;"	kind:file	line:1
featurize	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def featurize(self,$/;"	kind:member	line:934
featurize	../perception/perception/cnn.py	/^    def featurize(self, image_arr):$/;"	kind:member	line:204
field_config	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    field_config = {}$/;"	kind:variable	line:30
field_name	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^        field_name = f[:u_ind]$/;"	kind:variable	line:38
field_name	../autolab_core/tools/split_dataset.py	/^    field_name = args.field_name$/;"	kind:variable	line:56
field_names	../autolab_core/autolab_core/tensor_dataset.py	/^    def field_names(self):$/;"	kind:member	line:212
field_names	../autolab_core/autolab_core/tensor_dataset.py	/^    def field_names(self):$/;"	kind:member	line:376
field_names	../autolab_core/tools/aggregate_tensor_datasets.py	/^    field_names = tensor_config['fields'].keys()$/;"	kind:variable	line:71
filename	../autolab_core/autolab_core/tensor_dataset.py	/^    def filename(self):$/;"	kind:member	line:344
filename	../gqcnn/tools/run_policy.py	/^            filename = os.path.join(output_dir, "input_images.png")$/;"	kind:variable	line:126
filename	../gqcnn/tools/run_policy.py	/^            filename = os.path.join(output_dir, "planned_grasp.png")$/;"	kind:variable	line:161
filename	../gqcnn/tools/run_policy.py	/^        filename = None$/;"	kind:variable	line:124
filename	../gqcnn/tools/run_policy.py	/^        filename = None$/;"	kind:variable	line:159
filenames	../autolab_core/autolab_core/utils.py	/^def filenames(directory, tag='', sorted=False, recursive=False):$/;"	kind:function	line:178
filenames	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    filenames = utils.filenames(dataset_dir)$/;"	kind:variable	line:26
filler	../perception/tools/register_webcam.py	/^            filler = filler.reshape((filler.shape[0], filler.shape[1] * filler.shape[2])).T$/;"	kind:variable	line:68
filler	../perception/tools/register_webcam.py	/^            filler = np.mgrid[ystart:yend:sy, xstart:xend:sx]$/;"	kind:variable	line:67
filter_images.py	../perception/tools/filter_images.py	1;"	kind:file	line:1
filter_start	../perception/tools/filter_images.py	/^    filter_start = time.time()$/;"	kind:variable	line:58
filter_stop	../perception/tools/filter_images.py	/^    filter_stop = time.time()$/;"	kind:variable	line:189
filtered_points	../perception/tools/filter_images.py	/^    filtered_points = np.zeros([3,point_cloud_masked.num_points])$/;"	kind:variable	line:126
filters	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def filters(self):$/;"	kind:member	line:660
final_argument_whitespace	../moveit_tutorials/_scripts/tutorialformatter.py	/^    final_argument_whitespace = True$/;"	kind:variable	line:83
finalize_options	../gqcnn/setup.py	/^    def finalize_options(self):$/;"	kind:member	line:120
finalize_options	../gqcnn/setup.py	/^    def finalize_options(self):$/;"	kind:member	line:85
finalize_options	../panda_autograsp/setup.py	/^    def finalize_options(self):$/;"	kind:member	line:150
finalize_options	../panda_autograsp/setup.py	/^    def finalize_options(self):$/;"	kind:member	line:192
finalize_options	../setup.py	/^    def finalize_options(self):$/;"	kind:member	line:278
finalize_options	../setup.py	/^    def finalize_options(self):$/;"	kind:member	line:321
find_chessboard	../perception/perception/image.py	/^    def find_chessboard(self, sx=6, sy=9):$/;"	kind:member	line:1135
find_contours	../perception/perception/image.py	/^    def find_contours(self, min_area=0.0, max_area=np.inf):$/;"	kind:member	line:2377
finetune	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def finetune(self, base_model_dir):$/;"	kind:member	line:255
finetune.py	../gqcnn/tools/finetune.py	1;"	kind:file	line:1
finetune_classification_cnn	../perception/tools/finetune_classification_cnn.py	/^def finetune_classification_cnn(config):$/;"	kind:function	line:38
finetune_classification_cnn.py	../perception/tools/finetune_classification_cnn.py	1;"	kind:file	line:1
finished	../gqcnn/gqcnn/search/trial.py	/^    def finished(self):$/;"	kind:member	line:154
finite_pixels	../perception/perception/image.py	/^    def finite_pixels(self):$/;"	kind:member	line:852
fixed_robot_points_world	../perception/tools/register_camera.py	/^                    fixed_robot_points_world = R_cb_world.dot(est_robot_points_world.data)$/;"	kind:variable	line:206
fixed_robot_points_world	../perception/tools/register_camera.py	/^                fixed_robot_points_world = R_cb_world.dot(est_robot_points_world.data)$/;"	kind:variable	line:192
fixed_robot_points_world	../perception/tools/register_camera.py	/^                fixed_robot_points_world = T_corrected_cb_world * est_robot_points_world$/;"	kind:variable	line:238
flatten_combo	../gqcnn/gqcnn/search/utils.py	/^    def flatten_combo(combo):$/;"	kind:function	line:135
flatten_sub_tutorials	../moveit_tutorials/_scripts/tutorialformatter.py	/^    def flatten_sub_tutorials(self, file_):$/;"	kind:member	line:90
flush	../autolab_core/autolab_core/data_stream_syncer.py	/^    def flush(self):$/;"	kind:member	line:146
flush	../autolab_core/autolab_core/tensor_dataset.py	/^    def flush(self):$/;"	kind:member	line:711
flush	../perception/perception/opencv_camera_sensor.py	/^    def flush(self):$/;"	kind:member	line:28
fn	../panda_autograsp/scripts/kinect_processing.py	/^    fn = Freenect2()$/;"	kind:variable	line:89
focal_point	../perception/tools/filter_images.py	/^                     focal_point=focal_point)$/;"	kind:variable	line:151
focal_point	../perception/tools/filter_images.py	/^                     focal_point=focal_point)$/;"	kind:variable	line:163
focal_point	../perception/tools/filter_images.py	/^                     focal_point=focal_point)$/;"	kind:variable	line:91
focal_point	../perception/tools/filter_images.py	/^    focal_point = np.mean(point_cloud_filtered.data,$/;"	kind:variable	line:86
focus	../perception/perception/image.py	/^    def focus(self, height, width, center_i=None, center_j=None):$/;"	kind:member	line:740
font	../panda_autograsp/scripts/chessboard_calibration.py	/^font = cv2.FONT_HERSHEY_SIMPLEX$/;"	kind:variable	line:65
fontColor	../panda_autograsp/scripts/chessboard_calibration.py	/^fontColor = (0, 0, 0)$/;"	kind:variable	line:67
fontScale	../panda_autograsp/scripts/chessboard_calibration.py	/^fontScale = 0.90$/;"	kind:variable	line:66
force_closure	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def force_closure(self, action):$/;"	kind:member	line:137
force_closure	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^def force_closure(p1, p2, n1, n2, mu):$/;"	kind:function	line:54
foreground_mask	../perception/perception/image.py	/^    def foreground_mask($/;"	kind:member	line:1202
fpr	../autolab_core/autolab_core/learning_analysis.py	/^    def fpr(self):$/;"	kind:member	line:389
fpr	../autolab_core/autolab_core/learning_analysis.py	/^    def fpr(self):$/;"	kind:member	line:87
frame	../autolab_core/autolab_core/points.py	/^    def frame(self):$/;"	kind:member	line:1194
frame	../autolab_core/autolab_core/points.py	/^    def frame(self):$/;"	kind:member	line:73
frame	../autolab_core/autolab_core/primitives.py	/^    def frame(self):$/;"	kind:member	line:115
frame	../gqcnn/examples/policy.py	/^                          frame=camera_intr.frame)$/;"	kind:variable	line:197
frame	../gqcnn/examples/policy_ros.py	/^                               frame=camera_intr.frame)$/;"	kind:variable	line:158
frame	../gqcnn/examples/policy_ros.py	/^                          frame=camera_intr.frame)$/;"	kind:variable	line:124
frame	../gqcnn/examples/policy_ros.py	/^                       frame=camera_intr.frame)$/;"	kind:variable	line:140
frame	../gqcnn/examples/policy_ros.py	/^                       frame=camera_intr.frame)$/;"	kind:variable	line:148
frame	../gqcnn/examples/policy_with_image_proc.py	/^                          frame=camera_intr.frame)$/;"	kind:variable	line:137
frame	../gqcnn/gqcnn/grasping/grasp.py	/^    def frame(self):$/;"	kind:member	line:110
frame	../gqcnn/gqcnn/grasping/grasp.py	/^    def frame(self):$/;"	kind:member	line:315
frame	../gqcnn/gqcnn/grasping/grasp.py	/^    def frame(self):$/;"	kind:member	line:502
frame	../panda_autograsp/scripts/chessboard_calibration.py	/^        frame = 0$/;"	kind:variable	line:156
frame	../perception/perception/camera_intrinsics.py	/^    def frame(self):$/;"	kind:member	line:62
frame	../perception/perception/camera_sensor.py	/^    def frame(self):$/;"	kind:member	line:137
frame	../perception/perception/colorized_phoxi_sensor.py	/^    def frame(self):$/;"	kind:member	line:64
frame	../perception/perception/ensenso_sensor.py	/^    def frame(self):$/;"	kind:member	line:108
frame	../perception/perception/image.py	/^    def frame(self):$/;"	kind:member	line:213
frame	../perception/perception/kinect2_sensor.py	/^    def frame(self):$/;"	kind:member	line:154
frame	../perception/perception/kinect2_sensor.py	/^    def frame(self):$/;"	kind:member	line:475
frame	../perception/perception/kinect2_sensor.py	/^    def frame(self):$/;"	kind:member	line:651
frame	../perception/perception/orthographic_intrinsics.py	/^    def frame(self):$/;"	kind:member	line:55
frame	../perception/perception/phoxi_sensor.py	/^    def frame(self):$/;"	kind:member	line:91
frame	../perception/perception/primesense_sensor.py	/^    def frame(self):$/;"	kind:member	line:91
frame	../perception/perception/realsense_sensor.py	/^    def frame(self):$/;"	kind:member	line:145
frame	../perception/perception/webcam_sensor.py	/^    def frame(self):$/;"	kind:member	line:58
frame	../perception/tools/capture_dataset.py	/^                        frame='world')$/;"	kind:variable	line:201
frame	../perception/tools/capture_test_images.py	/^                        frame='world')$/;"	kind:variable	line:47
frame	../perception/tools/filter_images.py	/^    frame = args.frame$/;"	kind:variable	line:40
frame	../perception/tools/register_camera.py	/^                                                                     frame=ir_intrinsics.frame)$/;"	kind:variable	line:235
frame	../perception/tools/register_camera.py	/^                                                                 frame=ir_intrinsics.frame)$/;"	kind:variable	line:171
frame	../perception/tools/register_camera.py	/^                                                     frame=ir_intrinsics.frame)$/;"	kind:variable	line:233
frame	../perception/tools/register_camera.py	/^                                                 frame=ir_intrinsics.frame)$/;"	kind:variable	line:169
frame_rates	../perception/tools/primesense_viewer.py	/^    frame_rates = []$/;"	kind:variable	line:25
frames	../autolab_core/autolab_core/rigid_transformations.py	/^    def frames(self):$/;"	kind:member	line:283
frames	../panda_autograsp/scripts/kinect_processing.py	/^        frames = listener.waitForNewFrame()$/;"	kind:variable	line:124
frames	../perception/perception/camera_sensor.py	/^    def frames(self):$/;"	kind:member	line:190
frames	../perception/perception/camera_sensor.py	/^    def frames(self):$/;"	kind:member	line:275
frames	../perception/perception/camera_sensor.py	/^    def frames(self):$/;"	kind:member	line:38
frames	../perception/perception/colorized_phoxi_sensor.py	/^    def frames(self):$/;"	kind:member	line:106
frames	../perception/perception/ensenso_sensor.py	/^    def frames(self):$/;"	kind:member	line:137
frames	../perception/perception/kinect2_sensor.py	/^    def frames(self):$/;"	kind:member	line:518
frames	../perception/perception/kinect2_sensor.py	/^    def frames(self):$/;"	kind:member	line:704
frames	../perception/perception/kinect2_sensor.py	/^    def frames(self, skip_registration=False):$/;"	kind:member	line:267
frames	../perception/perception/opencv_camera_sensor.py	/^    def frames(self, flush=True):$/;"	kind:member	line:36
frames	../perception/perception/phoxi_sensor.py	/^    def frames(self):$/;"	kind:member	line:148
frames	../perception/perception/primesense_sensor.py	/^    def frames(self):$/;"	kind:member	line:200
frames	../perception/perception/realsense_sensor.py	/^    def frames(self):$/;"	kind:member	line:231
frames	../perception/perception/webcam_sensor.py	/^    def frames(self, most_recent=False):$/;"	kind:member	line:104
franka_state_callback	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	/^def franka_state_callback(msg):$/;"	kind:function	line:27
friction_cone_angle	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def friction_cone_angle(self, action):$/;"	kind:member	line:121
from_array	../perception/perception/image.py	/^    def from_array(x, frame='unspecified'):$/;"	kind:member	line:307
from_color_and_depth	../perception/perception/image.py	/^    def from_color_and_depth(color_im, depth_im):$/;"	kind:member	line:2864
from_feature_vec	../gqcnn/gqcnn/grasping/grasp.py	/^    def from_feature_vec(v, camera_intr=None, depth=None, axis=None):$/;"	kind:member	line:357
from_feature_vec	../gqcnn/gqcnn/grasping/grasp.py	/^    def from_feature_vec(v, width=0.0, camera_intr=None):$/;"	kind:member	line:151
from_feature_vec	../gqcnn/gqcnn/grasping/grasp.py	/^    def from_feature_vec(v,$/;"	kind:member	line:571
from_frame	../autolab_core/autolab_core/rigid_transformations.py	/^    def from_frame(self):$/;"	kind:member	line:171
from_frame	../autolab_core/autolab_core/rigid_transformations.py	/^    def from_frame(self, from_frame):$/;"	kind:member	line:177
from_frame	../perception/tools/register_camera.py	/^                                                   from_frame='gripper',$/;"	kind:variable	line:115
from_frame	../perception/tools/register_camera.py	/^                                                  from_frame='world',$/;"	kind:variable	line:218
from_frame	../perception/tools/register_camera.py	/^                                             from_frame='gripper',$/;"	kind:variable	line:304
from_frame	../perception/tools/register_camera.py	/^                                             from_frame='gripper',$/;"	kind:variable	line:347
from_frame	../perception/tools/register_camera.py	/^                                             from_frame='gripper',$/;"	kind:variable	line:374
from_frame	../perception/tools/register_camera.py	/^                                        from_frame=T_cb_world.from_frame,$/;"	kind:variable	line:223
from_grayscale_and_depth	../perception/perception/image.py	/^    def from_grayscale_and_depth(gray_im, depth_im):$/;"	kind:member	line:3134
from_pose_msg	../autolab_core/autolab_core/rigid_transformations.py	/^    def from_pose_msg(pose_msg, from_frame='unassigned', to_frame='world'):$/;"	kind:member	line:646
from_ros_pose_msg	../autolab_core/autolab_core/rigid_transformations.py	/^    def from_ros_pose_msg(pose_msg,$/;"	kind:member	line:615
from_vec	../autolab_core/autolab_core/rigid_transformations.py	/^    def from_vec(vec, from_frame='unassigned', to_frame='world'):$/;"	kind:member	line:639
from_vec	../perception/perception/camera_intrinsics.py	/^    def from_vec(vec, frame='unassigned'):$/;"	kind:member	line:174
fully_conv	../gqcnn/examples/policy.py	/^    fully_conv = args.fully_conv$/;"	kind:variable	line:100
fully_conv	../panda_autograsp/nodes/grasp_planner_server.py	/^    fully_conv = ($/;"	kind:variable	line:108
func_log	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^func_log = Logger.get_logger(__name__)$/;"	kind:variable	line:27
functions.py	../panda_autograsp/src/panda_autograsp/functions/functions.py	1;"	kind:file	line:1
fx	../perception/perception/camera_intrinsics.py	/^    def fx(self):$/;"	kind:member	line:68
fy	../perception/perception/camera_intrinsics.py	/^    def fy(self):$/;"	kind:member	line:74
g_data	../perception/perception/image.py	/^    def g_data(self):$/;"	kind:member	line:1068
gazebo	../panda_autograsp/nodes/panda_autograsp_server.py	/^        gazebo = False$/;"	kind:variable	line:51
gazebo	../panda_autograsp/nodes/panda_autograsp_server.py	/^        gazebo = rospy.get_param("~gazebo")$/;"	kind:variable	line:49
gen	../franka_ros/franka_example_controllers/cfg/compliance_param.cfg	/^gen = ParameterGenerator()$/;"	kind:variable	line:6
gen	../franka_ros/franka_example_controllers/cfg/desired_mass_param.cfg	/^gen = ParameterGenerator()$/;"	kind:variable	line:6
gen	../panda_autograsp/cfg/CalibFrames.cfg	/^gen = ParameterGenerator()$/;"	kind:variable	line:13
gen_config_summary_dict	../gqcnn/gqcnn/search/utils.py	/^def gen_config_summary_dict(hyperparam_combination):$/;"	kind:function	line:86
gen_experiment_id	../autolab_core/autolab_core/utils.py	/^def gen_experiment_id(n=10):$/;"	kind:function	line:11
gen_experiment_ref	../autolab_core/autolab_core/experiment_logger.py	/^    def gen_experiment_ref(experiment_tag, n=10):$/;"	kind:member	line:82
gen_timestamp	../gqcnn/gqcnn/search/utils.py	/^def gen_timestamp():$/;"	kind:function	line:158
gen_trial_params	../gqcnn/gqcnn/search/utils.py	/^def gen_trial_params(master_train_configs,$/;"	kind:function	line:192
gen_trial_params_finetune	../gqcnn/gqcnn/search/utils.py	/^def gen_trial_params_finetune(master_train_configs, datasets, base_models,$/;"	kind:function	line:176
gen_trial_params_train	../gqcnn/gqcnn/search/utils.py	/^def gen_trial_params_train(master_train_configs, datasets, split_names):$/;"	kind:function	line:162
generate_arucoboard.py	../panda_autograsp/scripts/generate_arucoboard.py	1;"	kind:file	line:1
generate_tensor_filename	../autolab_core/autolab_core/tensor_dataset.py	/^    def generate_tensor_filename(self, field_name, file_num, compressed=True):$/;"	kind:member	line:427
get_by_col	../autolab_core/autolab_core/csv_model.py	/^    def get_by_col(self, col, val):$/;"	kind:member	line:284
get_by_col_last	../autolab_core/autolab_core/csv_model.py	/^    def get_by_col_last(self, col, val):$/;"	kind:member	line:305
get_by_cols	../autolab_core/autolab_core/csv_model.py	/^    def get_by_cols(self, cols, direction=1):$/;"	kind:member	line:245
get_by_row	../autolab_core/autolab_core/csv_model.py	/^    def get_by_row(self, row):$/;"	kind:member	line:196
get_by_uid	../autolab_core/autolab_core/csv_model.py	/^    def get_by_uid(self, uid):$/;"	kind:member	line:180
get_col	../autolab_core/autolab_core/csv_model.py	/^    def get_col(self, col_name, filter = lambda _ : True):$/;"	kind:member	line:212
get_cur_uid	../autolab_core/autolab_core/csv_model.py	/^    def get_cur_uid(self):$/;"	kind:member	line:93
get_elapsed_time	../autolab_core/autolab_core/utils.py	/^def get_elapsed_time(time_in_seconds):$/;"	kind:function	line:28
get_fc_gqcnn_model	../gqcnn/gqcnn/model/__init__.py	/^def get_fc_gqcnn_model(backend="tf", verbose=True):$/;"	kind:function	line:67
get_fields_to_search_over	../gqcnn/gqcnn/search/utils.py	/^def get_fields_to_search_over(train_config, prev_keys=[]):$/;"	kind:function	line:41
get_git_submods	../setup.py	/^def get_git_submods():$/;"	kind:function	line:83
get_gqcnn_model	../gqcnn/gqcnn/model/__init__.py	/^def get_gqcnn_model(backend="tf", verbose=True):$/;"	kind:function	line:37
get_gqcnn_trainer	../gqcnn/gqcnn/training/__init__.py	/^def get_gqcnn_trainer(backend="tf"):$/;"	kind:function	line:36
get_html_theme_path	../moveit_tutorials/_themes/sphinx_rtd_theme/__init__.py	/^def get_html_theme_path():$/;"	kind:function	line:14
get_im_mean	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def get_im_mean(self):$/;"	kind:member	line:706
get_im_std	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def get_im_std(self):$/;"	kind:member	line:727
get_logger	../autolab_core/autolab_core/logger.py	/^    def get_logger(name, log_level=logging.INFO, log_file=None, global_log_file=False, silence=False):$/;"	kind:member	line:68
get_logger	../panda_autograsp/src/panda_autograsp/loggers.py	/^    def get_logger($/;"	kind:member	line:170
get_nested_key	../gqcnn/gqcnn/search/utils.py	/^def get_nested_key(cfg, key):$/;"	kind:function	line:72
get_or_create	../autolab_core/autolab_core/csv_model.py	/^    def get_or_create(full_filename, headers_types=None, default_entry=''):$/;"	kind:member	line:441
get_point_index	../perception/perception/feature_matcher.py	/^    def get_point_index(point, all_points, eps = 1e-4):$/;"	kind:member	line:111
get_pose_callback	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def get_pose_callback(self, pose_msg):$/;"	kind:member	line:513
get_pose_mean	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def get_pose_mean(self):$/;"	kind:member	line:748
get_pose_std	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def get_pose_std(self):$/;"	kind:member	line:770
get_rows_by_cols	../autolab_core/autolab_core/csv_model.py	/^    def get_rows_by_cols(self, matching_dict):$/;"	kind:member	line:326
get_tf_dep	../gqcnn/setup.py	/^def get_tf_dep():$/;"	kind:function	line:51
get_tf_dep	../panda_autograsp/setup.py	/^def get_tf_dep():$/;"	kind:function	line:53
get_trajectory_duration	../panda_autograsp/src/panda_autograsp/functions/moveit.py	/^def get_trajectory_duration(trajectory):$/;"	kind:function	line:31
getconstrain	../autolab_core/autolab_core/transformations.py	/^    def getconstrain(self):$/;"	kind:member	line:1431
gpu_devices	../gqcnn/tools/hyperparam_search.py	/^                         gpu_devices=gpu_devices,$/;"	kind:variable	line:127
gpu_devices	../gqcnn/tools/hyperparam_search.py	/^    gpu_devices = [int(device) for device in args.gpu_devices]$/;"	kind:variable	line:92
gqcnn	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def gqcnn(self):$/;"	kind:member	line:1107
gqcnn	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def gqcnn(self):$/;"	kind:member	line:1264
gqcnn	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def gqcnn(self):$/;"	kind:member	line:944
gqcnn	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def gqcnn(self):$/;"	kind:member	line:357
gqcnn	../gqcnn/tools/finetune.py	/^    gqcnn = get_gqcnn_model(backend)(gqcnn_params)$/;"	kind:variable	line:166
gqcnn	../gqcnn/tools/train.py	/^    gqcnn = get_gqcnn_model(backend)(gqcnn_params)$/;"	kind:variable	line:145
gqcnn_config	../gqcnn/examples/policy.py	/^        gqcnn_config = model_config["gqcnn"]$/;"	kind:variable	line:134
gqcnn_config	../gqcnn/examples/policy.py	/^        gqcnn_config = model_config["gqcnn_config"]$/;"	kind:variable	line:137
gqcnn_config	../panda_autograsp/nodes/grasp_planner_server.py	/^        gqcnn_config = model_config["gqcnn"]$/;"	kind:variable	line:163
gqcnn_config	../panda_autograsp/nodes/grasp_planner_server.py	/^        gqcnn_config = model_config["gqcnn_config"]$/;"	kind:variable	line:166
gqcnn_grasp_planner.py	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	1;"	kind:file	line:1
gqcnn_grasp_planner_ros.py	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	1;"	kind:file	line:1
gqcnn_params	../gqcnn/tools/finetune.py	/^    gqcnn_params = train_config["gqcnn"]$/;"	kind:variable	line:151
gqcnn_params	../gqcnn/tools/train.py	/^    gqcnn_params = train_config["gqcnn"]$/;"	kind:variable	line:130
gqcnn_recep_height	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def gqcnn_recep_height(self):$/;"	kind:member	line:949
gqcnn_recep_width	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def gqcnn_recep_width(self):$/;"	kind:member	line:953
gqcnn_stride	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def gqcnn_stride(self):$/;"	kind:member	line:957
gradients	../perception/perception/image.py	/^    def gradients(self):$/;"	kind:member	line:419
grasp	../gqcnn/examples/policy_ros.py	/^    grasp = grasp_resp.grasp$/;"	kind:variable	line:134
grasp	../panda_autograsp/scripts/plan_grasp.py	/^    grasp = grasp_planner.plan_grasp()$/;"	kind:variable	line:63
grasp.py	../gqcnn/gqcnn/grasping/grasp.py	1;"	kind:file	line:1
grasp_2d	../gqcnn/examples/policy_ros.py	/^        grasp_2d = Grasp2D(center,$/;"	kind:variable	line:141
grasp_2d	../gqcnn/examples/policy_ros.py	/^        grasp_2d = SuctionPoint2D(center,$/;"	kind:variable	line:149
grasp_approach_dir	../gqcnn/examples/policy_with_image_proc.py	/^        grasp_approach_dir=-T_camera_world.inverse().z_axis)$/;"	kind:variable	line:243
grasp_constraint_fn	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def grasp_constraint_fn(self):$/;"	kind:member	line:346
grasp_planner	../gqcnn/ros_nodes/grasp_planner_node.py	/^    grasp_planner = GraspPlanner(cfg, cv_bridge, grasping_policy,$/;"	kind:variable	line:413
grasp_planner	../panda_autograsp/nodes/grasp_planner_server.py	/^    grasp_planner = GraspPlannerROS($/;"	kind:variable	line:319
grasp_planner	../panda_autograsp/scripts/plan_grasp.py	/^    grasp_planner = GraspPlanner(model=MODEL_NAME)$/;"	kind:variable	line:59
grasp_planner_client	../panda_autograsp/nodes/panda_autograsp_server.py	/^    grasp_planner_client = PandaAutograspServer($/;"	kind:variable	line:54
grasp_planner_node.py	../gqcnn/ros_nodes/grasp_planner_node.py	1;"	kind:file	line:1
grasp_planner_server.py	../panda_autograsp/nodes/grasp_planner_server.py	1;"	kind:file	line:1
grasp_planning_service	../gqcnn/ros_nodes/grasp_planner_node.py	/^    grasp_planning_service = rospy.Service("grasp_planner", GQCNNGraspPlanner,$/;"	kind:variable	line:417
grasp_planning_service	../panda_autograsp/nodes/grasp_planner_server.py	/^    grasp_planning_service = rospy.Service($/;"	kind:variable	line:324
grasp_planning_service_bb	../gqcnn/ros_nodes/grasp_planner_node.py	/^    grasp_planning_service_bb = rospy.Service("grasp_planner_bounding_box",$/;"	kind:variable	line:419
grasp_planning_service_bb	../panda_autograsp/nodes/grasp_planner_server.py	/^    grasp_planning_service_bb = rospy.Service($/;"	kind:variable	line:327
grasp_planning_service_segmask	../gqcnn/ros_nodes/grasp_planner_node.py	/^    grasp_planning_service_segmask = rospy.Service($/;"	kind:variable	line:422
grasp_planning_service_segmask	../panda_autograsp/nodes/grasp_planner_server.py	/^    grasp_planning_service_segmask = rospy.Service($/;"	kind:variable	line:332
grasp_policy_type	../panda_autograsp/nodes/grasp_planner_server.py	/^    grasp_policy_type = policy_cfg["type"]$/;"	kind:variable	line:289
grasp_pose_msg	../gqcnn/examples/policy_with_image_proc.py	/^    grasp_pose_msg = T_grasp_camera.pose_msg$/;"	kind:variable	line:244
grasp_pose_publisher	../gqcnn/ros_nodes/grasp_planner_node.py	/^    grasp_pose_publisher = rospy.Publisher("\/gqcnn_grasp\/pose",$/;"	kind:variable	line:404
grasp_pose_publisher	../panda_autograsp/nodes/grasp_planner_server.py	/^    grasp_pose_publisher = rospy.Publisher($/;"	kind:variable	line:284
grasp_quality_fn	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def grasp_quality_fn(self):$/;"	kind:member	line:335
grasp_quality_function.py	../gqcnn/gqcnn/grasping/grasp_quality_function.py	1;"	kind:file	line:1
grasp_resp	../gqcnn/examples/policy_ros.py	/^        grasp_resp = plan_grasp(color_im.rosmsg, depth_im.rosmsg,$/;"	kind:variable	line:132
grasp_resp	../gqcnn/examples/policy_ros.py	/^        grasp_resp = plan_grasp_segmask(color_im.rosmsg, depth_im.rosmsg,$/;"	kind:variable	line:129
grasp_sampler	../gqcnn/examples/antipodal_grasp_sampling.py	/^    grasp_sampler = AntipodalDepthImageGraspSampler(sample_config,$/;"	kind:variable	line:87
grasp_sampler	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def grasp_sampler(self):$/;"	kind:member	line:324
grasp_type	../gqcnn/examples/policy_ros.py	/^    grasp_type = grasp.grasp_type$/;"	kind:variable	line:137
grasped_obj_key	../autolab_core/tools/aggregate_tensor_datasets.py	/^                grasped_obj_key = dataset_obj_ids[str(dataset_grasped_obj_id)]$/;"	kind:variable	line:114
grasping_policy	../gqcnn/ros_nodes/grasp_planner_node.py	/^    grasping_policy = CrossEntropyRobustGraspingPolicy(policy_cfg)$/;"	kind:variable	line:410
grasping_policy	../panda_autograsp/nodes/grasp_planner_server.py	/^                grasping_policy = FullyConvolutionalGraspingPolicyParallelJaw($/;"	kind:variable	line:294
grasping_policy	../panda_autograsp/nodes/grasp_planner_server.py	/^                grasping_policy = FullyConvolutionalGraspingPolicySuction(policy_cfg)$/;"	kind:variable	line:298
grasping_policy	../panda_autograsp/nodes/grasp_planner_server.py	/^            grasping_policy = CrossEntropyRobustGraspingPolicy(policy_cfg)$/;"	kind:variable	line:305
grasps	../gqcnn/examples/antipodal_grasp_sampling.py	/^    grasps = grasp_sampler.sample(rgbd_im,$/;"	kind:variable	line:89
grasps_to_tensors	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def grasps_to_tensors(self, grasps, state):$/;"	kind:member	line:1116
grasps_to_tensors	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def grasps_to_tensors(self, grasps, state):$/;"	kind:member	line:965
gray	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        gray = cv2.cvtColor(color_im.data, cv2.COLOR_BGR2GRAY)$/;"	kind:variable	line:135
gray	../panda_autograsp/scripts/chessboard_calibration.py	/^                gray = cv2.cvtColor(color_im.data, cv2.COLOR_BGR2GRAY)$/;"	kind:variable	line:162
gray	../panda_autograsp/scripts/chessboard_calibration.py	/^        gray = cv2.cvtColor(color_im.data, cv2.COLOR_BGR2GRAY)$/;"	kind:variable	line:455
gray	../perception/perception/image.py	/^    def gray(self):$/;"	kind:member	line:3153
greedy_action	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def greedy_action(self, state):$/;"	kind:member	line:1433
green	../autolab_core/autolab_core/points.py	/^    def green(self):$/;"	kind:member	line:1087
grid_center_x	../perception/tools/register_camera.py	/^            grid_center_x = config['grid_center_x']$/;"	kind:variable	line:98
grid_center_y	../perception/tools/register_camera.py	/^            grid_center_y = config['grid_center_y']$/;"	kind:variable	line:99
grid_height	../perception/tools/register_camera.py	/^            grid_height = config['grid_height']$/;"	kind:variable	line:96
grid_width	../perception/tools/register_camera.py	/^            grid_width = config['grid_width']$/;"	kind:variable	line:95
gridboard	../panda_autograsp/scripts/generate_arucoboard.py	/^    gridboard = aruco.GridBoard_create($/;"	kind:variable	line:90
gridboard_img	../panda_autograsp/scripts/generate_arucoboard.py	/^    gridboard_img = gridboard.draw($/;"	kind:variable	line:99
gripper_height	../perception/tools/register_camera.py	/^            gripper_height = config['gripper_height']$/;"	kind:variable	line:97
gripper_mode	../gqcnn/examples/policy.py	/^            gripper_mode = GripperMode.LEGACY_PARALLEL_JAW$/;"	kind:variable	line:140
gripper_mode	../gqcnn/examples/policy.py	/^            gripper_mode = GripperMode.LEGACY_SUCTION$/;"	kind:variable	line:142
gripper_mode	../gqcnn/examples/policy.py	/^            gripper_mode = GripperMode.MULTI_SUCTION$/;"	kind:variable	line:146
gripper_mode	../gqcnn/examples/policy.py	/^            gripper_mode = GripperMode.PARALLEL_JAW$/;"	kind:variable	line:148
gripper_mode	../gqcnn/examples/policy.py	/^            gripper_mode = GripperMode.SUCTION$/;"	kind:variable	line:144
gripper_mode	../gqcnn/examples/policy.py	/^        gripper_mode = gqcnn_config["gripper_mode"]$/;"	kind:variable	line:135
gripper_mode	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def gripper_mode(self):$/;"	kind:member	line:612
gripper_mode	../panda_autograsp/nodes/grasp_planner_server.py	/^            gripper_mode = GripperMode.LEGACY_PARALLEL_JAW$/;"	kind:variable	line:169
gripper_mode	../panda_autograsp/nodes/grasp_planner_server.py	/^            gripper_mode = GripperMode.LEGACY_SUCTION$/;"	kind:variable	line:171
gripper_mode	../panda_autograsp/nodes/grasp_planner_server.py	/^            gripper_mode = GripperMode.MULTI_SUCTION$/;"	kind:variable	line:175
gripper_mode	../panda_autograsp/nodes/grasp_planner_server.py	/^            gripper_mode = GripperMode.PARALLEL_JAW$/;"	kind:variable	line:177
gripper_mode	../panda_autograsp/nodes/grasp_planner_server.py	/^            gripper_mode = GripperMode.SUCTION$/;"	kind:variable	line:173
gripper_mode	../panda_autograsp/nodes/grasp_planner_server.py	/^        gripper_mode = gqcnn_config["gripper_mode"]$/;"	kind:variable	line:164
gripper_width	../gqcnn/examples/antipodal_grasp_sampling.py	/^    gripper_width = config["gripper_width"]$/;"	kind:variable	line:65
gripper_width	../gqcnn/examples/policy_ros.py	/^    gripper_width = args.gripper_width$/;"	kind:variable	line:90
gui	../perception/tools/capture_dataset.py	/^                gui = plt.figure(0)$/;"	kind:variable	line:333
gui	../perception/tools/capture_dataset.py	/^    gui = plt.figure(0, figsize=(8,8))$/;"	kind:variable	line:189
handle_request	../autolab_core/ros_nodes/rigid_transform_listener.py	/^    def handle_request(req):$/;"	kind:function	line:24
handle_request	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    def handle_request(req):$/;"	kind:function	line:21
handle_request	../perception/ros_nodes/image_buffer.py	/^    def handle_request(req):$/;"	kind:function	line:71
handler	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^        def handler(signum, frame):$/;"	kind:function	line:353
handler	../perception/tests/kinect2_sensor_bridge.py	/^    def handler(signum, frame):$/;"	kind:function	line:39
handler	../setup.py	/^handler = logging.StreamHandler(sys.stdout)$/;"	kind:variable	line:75
has_content	../moveit_tutorials/_scripts/tutorialformatter.py	/^    has_content = False$/;"	kind:variable	line:82
has_data	../autolab_core/autolab_core/tensor_dataset.py	/^    def has_data(self):$/;"	kind:member	line:93
has_internal_dirs	../autolab_core/autolab_core/experiment_logger.py	/^    def has_internal_dirs(self, dirs):$/;"	kind:member	line:153
has_split	../autolab_core/autolab_core/tensor_dataset.py	/^    def has_split(self, split_name):$/;"	kind:member	line:447
height	../autolab_core/autolab_core/primitives.py	/^    def height(self):$/;"	kind:member	line:75
height	../autolab_core/autolab_core/tensor_dataset.py	/^    def height(self):$/;"	kind:member	line:71
height	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^                height = data.shape[1]$/;"	kind:variable	line:48
height	../perception/perception/camera_intrinsics.py	/^    def height(self):$/;"	kind:member	line:112
height	../perception/perception/detector.py	/^    def height(self):$/;"	kind:member	line:54
height	../perception/perception/image.py	/^    def height(self):$/;"	kind:member	line:167
help	../autolab_core/tools/split_dataset.py	/^                        help='name of the field to split on')$/;"	kind:variable	line:51
help	../autolab_core/tools/split_dataset.py	/^                        help='name to use for the split')$/;"	kind:variable	line:47
help	../autolab_core/tools/split_dataset.py	/^                        help='path to the dataset to use for training and validation')$/;"	kind:variable	line:45
help	../autolab_core/tools/split_dataset.py	/^                        help='percent of data to use for training')$/;"	kind:variable	line:49
help	../gqcnn/examples/antipodal_grasp_sampling.py	/^                        help="path to configuration file to use")$/;"	kind:variable	line:56
help	../gqcnn/examples/policy.py	/^                        help="name of a trained model to run")$/;"	kind:variable	line:66
help	../gqcnn/examples/policy.py	/^                        help="path to an optional segmask to use")$/;"	kind:variable	line:75
help	../gqcnn/examples/policy.py	/^                        help="path to configuration file to use")$/;"	kind:variable	line:87
help	../gqcnn/examples/policy.py	/^                        help="path to the camera intrinsics")$/;"	kind:variable	line:79
help	../gqcnn/examples/policy.py	/^                        help="path to the folder in which the model is stored")$/;"	kind:variable	line:83
help	../gqcnn/examples/policy.py	/^        help="path to a test depth image stored as a .npy file")$/;"	kind:variable	line:71
help	../gqcnn/examples/policy.py	/^        help=("run Fully-Convolutional GQ-CNN policy instead of standard"$/;"	kind:variable	line:91
help	../gqcnn/examples/policy_ros.py	/^                        help="namespace of the ROS grasp planning service")$/;"	kind:variable	line:81
help	../gqcnn/examples/policy_ros.py	/^                        help="path to an optional segmask to use")$/;"	kind:variable	line:69
help	../gqcnn/examples/policy_ros.py	/^                        help="path to the camera intrinsics")$/;"	kind:variable	line:73
help	../gqcnn/examples/policy_ros.py	/^                        help="whether or not to visualize the grasp")$/;"	kind:variable	line:85
help	../gqcnn/examples/policy_ros.py	/^                        help="width of the gripper to plan for")$/;"	kind:variable	line:77
help	../gqcnn/examples/policy_ros.py	/^        help="path to a test depth image stored as a .npy file")$/;"	kind:variable	line:65
help	../gqcnn/examples/policy_with_image_proc.py	/^                        help="path to a trained model to run")$/;"	kind:variable	line:83
help	../gqcnn/examples/policy_with_image_proc.py	/^                        help="path to an optional segmask to use")$/;"	kind:variable	line:71
help	../gqcnn/examples/policy_with_image_proc.py	/^                        help="path to configuration file to use")$/;"	kind:variable	line:87
help	../gqcnn/examples/policy_with_image_proc.py	/^                        help="path to the camera intrinsics")$/;"	kind:variable	line:75
help	../gqcnn/examples/policy_with_image_proc.py	/^                        help="path to the camera pose")$/;"	kind:variable	line:79
help	../gqcnn/examples/policy_with_image_proc.py	/^        help="path to a test depth image stored as a .npy file")$/;"	kind:variable	line:67
help	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        help="name of model to analyze")$/;"	kind:variable	line:52
help	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        help="path to save the analysis")$/;"	kind:variable	line:56
help	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        help="path to the configuration file to use")$/;"	kind:variable	line:65
help	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        help="path to the model")$/;"	kind:variable	line:69
help	../gqcnn/tools/analyze_gqcnn_performance.py	/^        help="path to a configuration file for testing on a custom dataset")$/;"	kind:variable	line:61
help	../gqcnn/tools/finetune.py	/^                        help="name for the trained model")$/;"	kind:variable	line:88
help	../gqcnn/tools/finetune.py	/^                        help="name of the pre-trained model to fine-tune")$/;"	kind:variable	line:60
help	../gqcnn/tools/finetune.py	/^                        help="name of the split to train on")$/;"	kind:variable	line:64
help	../gqcnn/tools/finetune.py	/^                        help="path to store the model")$/;"	kind:variable	line:68
help	../gqcnn/tools/finetune.py	/^                        help="path to the configuration file to use")$/;"	kind:variable	line:80
help	../gqcnn/tools/finetune.py	/^                        help="path to the pre-trained model to fine-tune")$/;"	kind:variable	line:84
help	../gqcnn/tools/finetune.py	/^                        help="port to launch tensorboard on")$/;"	kind:variable	line:72
help	../gqcnn/tools/finetune.py	/^                        help="random seed for training")$/;"	kind:variable	line:76
help	../gqcnn/tools/finetune.py	/^                        help="the deep learning framework to use")$/;"	kind:variable	line:98
help	../gqcnn/tools/finetune.py	/^        help="path to the dataset to use for training and validation")$/;"	kind:variable	line:56
help	../gqcnn/tools/finetune.py	/^        help=("whether or not to save a model with the date and time of"$/;"	kind:variable	line:93
help	../gqcnn/tools/hyperparam_search.py	/^                        help="CPU cores to use")$/;"	kind:variable	line:78
help	../gqcnn/tools/hyperparam_search.py	/^                        help="GPU devices to use")$/;"	kind:variable	line:82
help	../gqcnn/tools/hyperparam_search.py	/^                        help="dataset splits to use")$/;"	kind:variable	line:66
help	../gqcnn/tools/hyperparam_search.py	/^                        help="name of search")$/;"	kind:variable	line:74
help	../gqcnn/tools/hyperparam_search.py	/^                        help="path to datasets")$/;"	kind:variable	line:51
help	../gqcnn/tools/hyperparam_search.py	/^                        help="path to pre-trained base models for fine-tuning")$/;"	kind:variable	line:55
help	../gqcnn/tools/hyperparam_search.py	/^                        help="path to store search data")$/;"	kind:variable	line:70
help	../gqcnn/tools/hyperparam_search.py	/^                        help="path to training configs")$/;"	kind:variable	line:59
help	../gqcnn/tools/run_policy.py	/^                        help="directory to store output")$/;"	kind:variable	line:66
help	../gqcnn/tools/run_policy.py	/^                        help="path to configuration file to use")$/;"	kind:variable	line:62
help	../gqcnn/tools/run_policy.py	/^                        help="path to test case")$/;"	kind:variable	line:58
help	../gqcnn/tools/train.py	/^                        help="name for the trained model")$/;"	kind:variable	line:79
help	../gqcnn/tools/train.py	/^                        help="name of the split to train on")$/;"	kind:variable	line:59
help	../gqcnn/tools/train.py	/^                        help="path to store the model")$/;"	kind:variable	line:63
help	../gqcnn/tools/train.py	/^                        help="path to the configuration file to use")$/;"	kind:variable	line:75
help	../gqcnn/tools/train.py	/^                        help="port to launch tensorboard on")$/;"	kind:variable	line:67
help	../gqcnn/tools/train.py	/^                        help="random seed for training")$/;"	kind:variable	line:71
help	../gqcnn/tools/train.py	/^                        help="the deep learning framework to use")$/;"	kind:variable	line:89
help	../gqcnn/tools/train.py	/^        help="path to the dataset to use for training and validation")$/;"	kind:variable	line:55
help	../gqcnn/tools/train.py	/^        help=("whether or not to save a model with the date and time of"$/;"	kind:variable	line:84
high_indices	../perception/tools/filter_images.py	/^    high_indices = np.where(point_cloud_world.data[2,:] > max_height)[0] $/;"	kind:variable	line:78
histogram	../autolab_core/autolab_core/utils.py	/^def histogram(values, num_bins, bounds, normalized=True, plot=False, color='b'):$/;"	kind:function	line:64
html_context	../docs/source/conf.py	/^html_context = {$/;"	kind:variable	line:135
html_context	../moveit_tutorials/conf.py	/^html_context = {$/;"	kind:variable	line:37
html_logo	../docs/source/conf.py	/^html_logo = "_images\/panda_autograsp.svg"$/;"	kind:variable	line:142
html_static_path	../autolab_core/docs/source/conf.py	/^html_static_path = ['_static']$/;"	kind:variable	line:149
html_static_path	../docs/source/conf.py	/^html_static_path = ["_static"]$/;"	kind:variable	line:134
html_static_path	../docs/source/conf.py	/^html_static_path = ["_static"]$/;"	kind:variable	line:170
html_static_path	../moveit_tutorials/conf.py	/^html_static_path = ['_static']$/;"	kind:variable	line:35
html_static_path	../perception/docs/source/conf.py	/^html_static_path = ['_static']$/;"	kind:variable	line:150
html_theme	../autolab_core/docs/source/conf.py	/^html_theme = 'sphinx_rtd_theme'$/;"	kind:variable	line:119
html_theme	../docs/source/conf.py	/^html_theme = "sphinx_rtd_theme"$/;"	kind:variable	line:128
html_theme	../gqcnn/docs/source/conf.py	/^html_theme = "sphinx_rtd_theme"$/;"	kind:variable	line:121
html_theme	../moveit_tutorials/conf.py	/^html_theme = 'sphinx_rtd_theme'$/;"	kind:variable	line:29
html_theme	../perception/docs/source/conf.py	/^html_theme = 'sphinx_rtd_theme'$/;"	kind:variable	line:120
html_theme_path	../autolab_core/docs/source/conf.py	/^html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]$/;"	kind:variable	line:120
html_theme_path	../docs/source/conf.py	/^html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]$/;"	kind:variable	line:129
html_theme_path	../gqcnn/docs/source/conf.py	/^html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]$/;"	kind:variable	line:122
html_theme_path	../moveit_tutorials/conf.py	/^html_theme_path = ['_themes',]$/;"	kind:variable	line:30
html_theme_path	../perception/docs/source/conf.py	/^html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]$/;"	kind:variable	line:121
htmlhelp_basename	../autolab_core/docs/source/conf.py	/^htmlhelp_basename = 'coredoc'$/;"	kind:variable	line:212
htmlhelp_basename	../docs/source/conf.py	/^htmlhelp_basename = "panda_autograsp_doc"$/;"	kind:variable	line:145
htmlhelp_basename	../gqcnn/docs/source/conf.py	/^htmlhelp_basename = "GQCNNdoc"$/;"	kind:variable	line:214
htmlhelp_basename	../moveit_tutorials/conf.py	/^htmlhelp_basename = 'MoveItDocumentation'$/;"	kind:variable	line:69
htmlhelp_basename	../perception/docs/source/conf.py	/^htmlhelp_basename = 'perceptiondoc'$/;"	kind:variable	line:213
hyperparam_search.py	../gqcnn/tools/hyperparam_search.py	1;"	kind:file	line:1
i	../gqcnn/tools/plot_training_losses.py	/^    i = 0$/;"	kind:variable	line:82
i_coords	../autolab_core/autolab_core/points.py	/^    def i_coords(self):$/;"	kind:member	line:1009
id	../gqcnn/gqcnn/grasping/actions.py	/^    def id(self):$/;"	kind:member	line:68
identity_matrix	../autolab_core/autolab_core/transformations.py	/^def identity_matrix():$/;"	kind:function	line:180
ij_to_linear	../perception/perception/image.py	/^    def ij_to_linear(self, i, j):$/;"	kind:member	line:430
im	../perception/tools/keras_resnet.py	/^    im = ColorImage.open(image_filename)$/;"	kind:variable	line:23
im	../perception/tools/keras_vgg.py	/^    im = ColorImage.open(image_filename)$/;"	kind:variable	line:23
im	../perception/tools/predict_class_label.py	/^    im = ColorImage.open(image_filename)$/;"	kind:variable	line:23
im	../perception/tools/register_camera.py	/^                        im = color_im.data.copy()$/;"	kind:variable	line:143
im_height	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def im_height(self):$/;"	kind:member	line:596
im_rescale_factor	../perception/tools/capture_dataset.py	/^    im_rescale_factor = image_proc_config['im_rescale_factor']$/;"	kind:variable	line:183
im_width	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def im_width(self):$/;"	kind:member	line:600
image	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            image=gray,$/;"	kind:variable	line:143
image	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            image=gray,$/;"	kind:variable	line:153
image	../perception/perception/detector.py	/^    def image(self, render_mode):$/;"	kind:member	line:101
image	../perception/perception/object_render.py	/^    def image(self, render_mode):$/;"	kind:member	line:110
image.py	../perception/perception/image.py	1;"	kind:file	line:1
image_buffer.py	../perception/ros_nodes/image_buffer.py	1;"	kind:file	line:1
image_dir	../perception/tools/filter_images.py	/^    image_dir = args.image_dir$/;"	kind:variable	line:39
image_dist	../gqcnn/gqcnn/grasping/grasp.py	/^    def image_dist(g1, g2, alpha=1.0):$/;"	kind:member	line:241
image_dist	../gqcnn/gqcnn/grasping/grasp.py	/^    def image_dist(g1, g2, alpha=1.0):$/;"	kind:member	line:436
image_dist	../gqcnn/gqcnn/grasping/grasp.py	/^    def image_dist(g1, g2, alpha=1.0):$/;"	kind:member	line:630
image_filename	../perception/tools/keras_resnet.py	/^    image_filename = sys.argv[1]$/;"	kind:variable	line:18
image_filename	../perception/tools/keras_vgg.py	/^    image_filename = sys.argv[1]$/;"	kind:variable	line:18
image_filename	../perception/tools/predict_class_label.py	/^    image_filename = sys.argv[3]$/;"	kind:variable	line:18
image_grasp_sampler.py	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	1;"	kind:file	line:1
image_proc_config	../perception/tools/capture_dataset.py	/^    image_proc_config = config['image_proc']$/;"	kind:variable	line:160
images	../panda_autograsp/scripts/chessboard_calibration.py	/^        images = []$/;"	kind:variable	line:155
images_so_far	../perception/ros_nodes/image_buffer.py	/^            images_so_far = 0$/;"	kind:variable	line:106
images_so_far	../perception/ros_nodes/image_buffer.py	/^    images_so_far = 0$/;"	kind:variable	line:49
img_detections	../panda_autograsp/scripts/chessboard_calibration.py	/^                    img_detections = cv2.drawChessboardCorners($/;"	kind:variable	line:176
img_save_pth	../panda_autograsp/scripts/generate_arucoboard.py	/^    img_save_pth = os.path.abspath($/;"	kind:variable	line:123
imgpoints	../panda_autograsp/scripts/chessboard_calibration.py	/^    imgpoints = []  # 2d points in image plane.$/;"	kind:variable	line:137
imresize	../perception/perception/image.py	/^def imresize(image, size, interp="nearest"):$/;"	kind:function	line:38
include_package_data	../panda_autograsp/setup.py	/^    include_package_data=True,$/;"	kind:variable	line:271
include_package_data	../setup.py	/^    include_package_data=True,$/;"	kind:variable	line:404
ind	../autolab_core/tools/shuffle_tensor_dataset.py	/^    ind = np.arange(dataset.num_datapoints)$/;"	kind:variable	line:50
ind	../autolab_core/tools/subsample_tensor_dataset.py	/^    ind = ind[:num_datapoints]$/;"	kind:variable	line:56
ind	../autolab_core/tools/subsample_tensor_dataset.py	/^    ind = np.arange(dataset.num_datapoints)$/;"	kind:variable	line:54
ind	../autolab_core/tools/subsample_tensor_dataset.py	/^    ind = np.sort(ind)$/;"	kind:variable	line:57
ind	../perception/tools/register_camera.py	/^                    ind = inliers$/;"	kind:variable	line:201
ind	../perception/tools/register_camera.py	/^                ind = np.random.choice(num_poses, size=sample_size, replace=False)$/;"	kind:variable	line:187
indent	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^              indent=JSON_INDENT,$/;"	kind:variable	line:66
indent	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^              indent=JSON_INDENT,$/;"	kind:variable	line:72
index_map	../perception/perception/feature_matcher.py	/^    def index_map(self):$/;"	kind:member	line:35
individual_weights	../perception/perception/weight_sensor.py	/^    def individual_weights(self):$/;"	kind:member	line:69
init_mean_and_std	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def init_mean_and_std(self, model_dir):$/;"	kind:member	line:228
init_val_error	../gqcnn/tools/plot_training_losses.py	/^    init_val_error = val_errors[0]$/;"	kind:variable	line:100
init_weights_file	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def init_weights_file(self, ckpt_file):$/;"	kind:member	line:359
initial_pose_found	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	/^initial_pose_found = False$/;"	kind:variable	line:15
initialize_network	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def initialize_network(self,$/;"	kind:member	line:493
initialize_options	../gqcnn/setup.py	/^    def initialize_options(self):$/;"	kind:member	line:114
initialize_options	../gqcnn/setup.py	/^    def initialize_options(self):$/;"	kind:member	line:79
initialize_options	../panda_autograsp/setup.py	/^    def initialize_options(self):$/;"	kind:member	line:143
initialize_options	../panda_autograsp/setup.py	/^    def initialize_options(self):$/;"	kind:member	line:184
initialize_options	../setup.py	/^    def initialize_options(self):$/;"	kind:member	line:271
initialize_options	../setup.py	/^    def initialize_options(self):$/;"	kind:member	line:314
inliers	../panda_autograsp/scripts/chessboard_calibration.py	/^                    inliers=inliers,$/;"	kind:variable	line:533
inliers	../perception/tools/register_camera.py	/^                inliers = np.where(dists < dist_thresh)[0]$/;"	kind:variable	line:195
inpaint	../perception/perception/image.py	/^    def inpaint(self, rescale_factor=1.0):$/;"	kind:member	line:1710
inpaint	../perception/perception/image.py	/^    def inpaint(self, win_size=3, rescale_factor=1.0):$/;"	kind:member	line:1403
inpaint_rescale_factor	../gqcnn/examples/antipodal_grasp_sampling.py	/^    inpaint_rescale_factor = config["inpaint_rescale_factor"]$/;"	kind:variable	line:66
inpaint_rescale_factor	../gqcnn/examples/policy.py	/^    inpaint_rescale_factor = config["inpaint_rescale_factor"]$/;"	kind:variable	line:178
inpaint_rescale_factor	../gqcnn/examples/policy_with_image_proc.py	/^    inpaint_rescale_factor = config["inpaint_rescale_factor"]$/;"	kind:variable	line:115
input	../panda_autograsp/nodes/grasp_planner_server.py	/^    input = raw_input$/;"	kind:variable	line:23
input	../panda_autograsp/nodes/moveit_random_planner_client.py	/^    input = raw_input$/;"	kind:variable	line:12
input	../panda_autograsp/nodes/panda_autograsp_cli.py	/^    input = raw_input$/;"	kind:variable	line:12
input	../panda_autograsp/nodes/panda_autograsp_server.py	/^    input = raw_input$/;"	kind:variable	line:24
input	../panda_autograsp/nodes/tf2_broadcaster.py	/^    input = raw_input$/;"	kind:variable	line:13
input	../panda_autograsp/src/panda_autograsp/functions/conversions.py	/^    input = raw_input$/;"	kind:variable	line:10
input	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^    input = raw_input$/;"	kind:variable	line:12
input	../panda_autograsp/src/panda_autograsp/functions/moveit.py	/^    input = raw_input$/;"	kind:variable	line:10
input	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    input = raw_input$/;"	kind:variable	line:13
input	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    input = raw_input$/;"	kind:variable	line:13
input	../panda_autograsp/src/panda_autograsp/loggers.py	/^    input = raw_input$/;"	kind:variable	line:14
input	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    input = raw_input$/;"	kind:variable	line:11
input	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    input = raw_input$/;"	kind:variable	line:12
input_data_mode	../gqcnn/examples/policy.py	/^        input_data_mode = gqcnn_config["input_data_mode"]$/;"	kind:variable	line:138
input_data_mode	../panda_autograsp/nodes/grasp_planner_server.py	/^        input_data_mode = gqcnn_config["input_data_mode"]$/;"	kind:variable	line:167
input_dataset_names	../autolab_core/tools/aggregate_tensor_datasets.py	/^    input_dataset_names = cfg['input_datasets']$/;"	kind:variable	line:50
input_depth_mode	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def input_depth_mode(self):$/;"	kind:member	line:588
input_drop_rate_node	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def input_drop_rate_node(self):$/;"	kind:member	line:624
input_im_node	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def input_im_node(self):$/;"	kind:member	line:616
input_pose_node	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def input_pose_node(self):$/;"	kind:member	line:620
insert	../autolab_core/autolab_core/csv_model.py	/^    def insert(self, data):$/;"	kind:member	line:117
install_requirements	../setup.py	/^install_requirements = ["scipy", "numpy", "cython"]$/;"	kind:variable	line:43
install_requires	../autolab_core/setup.py	/^    install_requires = requirements,$/;"	kind:variable	line:43
install_requires	../gqcnn/setup.py	/^    install_requires=requirements,$/;"	kind:variable	line:186
install_requires	../panda_autograsp/setup.py	/^    install_requires=requirements,$/;"	kind:variable	line:258
install_requires	../perception/setup.py	/^      install_requires = requirements,$/;"	kind:variable	line:46
install_requires	../setup.py	/^    install_requires=requirements,$/;"	kind:variable	line:405
install_submods	../setup.py	/^def install_submods(sub_mods, mode="install", install_dependencies=True):$/;"	kind:function	line:187
instream	../perception/ros_nodes/image_buffer.py	/^    instream       = rospy.get_param('~instream')$/;"	kind:variable	line:36
interactive_marker.py	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	1;"	kind:file	line:1
interp	../perception/tools/capture_dataset.py	/^                                               interp='nearest')$/;"	kind:variable	line:320
interpolate	../autolab_core/autolab_core/dual_quaternion.py	/^    def interpolate(dq0, dq1, t):$/;"	kind:member	line:129
interpolate	../autolab_core/autolab_core/rigid_transformations.py	/^    def interpolate(T0, T1, t):$/;"	kind:member	line:973
interpolate_with	../autolab_core/autolab_core/rigid_transformations.py	/^    def interpolate_with(self, other_tf, t):$/;"	kind:member	line:288
intersphinx_mapping	../docs/source/conf.py	/^intersphinx_mapping = {$/;"	kind:variable	line:59
intr_filename	../perception/tools/register_camera.py	/^        intr_filename = os.path.join(output_dir, '%s.intr' %(sensor_frame))$/;"	kind:variable	line:255
intr_filename	../perception/tools/register_webcam.py	/^        intr_filename = os.path.join(output_dir, '%s.intr' %(sensor_frame))$/;"	kind:variable	line:94
intrinsics	../perception/tools/register_webcam.py	/^            intrinsics = sensor.color_intrinsics$/;"	kind:variable	line:45
invalid_indices	../perception/tools/filter_images.py	/^    invalid_indices = np.setdiff1d(np.arange(point_cloud_filtered.num_points),$/;"	kind:variable	line:109
invalid_pixel_mask	../perception/perception/image.py	/^    def invalid_pixel_mask(self):$/;"	kind:member	line:1755
inverse	../autolab_core/autolab_core/rigid_transformations.py	/^    def inverse(self):$/;"	kind:member	line:1224
inverse	../autolab_core/autolab_core/rigid_transformations.py	/^    def inverse(self):$/;"	kind:member	line:456
inverse	../perception/perception/image.py	/^    def inverse(self):$/;"	kind:member	line:2282
inverse_matrix	../autolab_core/autolab_core/transformations.py	/^def inverse_matrix(matrix):$/;"	kind:function	line:1633
ip	../perception/tools/register_camera.py	/^            ip = dir_world.dot(cb_point_data_world)$/;"	kind:variable	line:272
ip	../perception/tools/register_camera.py	/^            ip = dir_world.dot(cb_point_data_world)$/;"	kind:variable	line:364
ir	../panda_autograsp/scripts/kinect_processing.py	/^        ir = frames["ir"]$/;"	kind:variable	line:126
ir_frame	../perception/perception/camera_sensor.py	/^    def ir_frame(self):$/;"	kind:member	line:149
ir_frame	../perception/perception/colorized_phoxi_sensor.py	/^    def ir_frame(self):$/;"	kind:member	line:76
ir_frame	../perception/perception/kinect2_sensor.py	/^    def ir_frame(self):$/;"	kind:member	line:166
ir_frame	../perception/perception/kinect2_sensor.py	/^    def ir_frame(self):$/;"	kind:member	line:663
ir_frame	../perception/perception/phoxi_sensor.py	/^    def ir_frame(self):$/;"	kind:member	line:103
ir_frame	../perception/perception/primesense_sensor.py	/^    def ir_frame(self):$/;"	kind:member	line:103
ir_img	../panda_autograsp/scripts/kinect_processing.py	/^        ir_img = cv2.imshow("ir", ir.asarray() \/ 65535.0)$/;"	kind:variable	line:144
ir_intr	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        ir_intr = sensor._device.getIrCameraParams()$/;"	kind:variable	line:129
ir_intr	../panda_autograsp/scripts/chessboard_calibration.py	/^        ir_intr = sensor._device.getIrCameraParams()$/;"	kind:variable	line:421
ir_intrinsics	../perception/perception/camera_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:161
ir_intrinsics	../perception/perception/colorized_phoxi_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:52
ir_intrinsics	../perception/perception/ensenso_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:96
ir_intrinsics	../perception/perception/kinect2_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:136
ir_intrinsics	../perception/perception/kinect2_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:463
ir_intrinsics	../perception/perception/kinect2_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:675
ir_intrinsics	../perception/perception/phoxi_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:79
ir_intrinsics	../perception/perception/primesense_sensor.py	/^    def ir_intrinsics(self):$/;"	kind:member	line:76
ir_intrinsics	../perception/tools/register_camera.py	/^            ir_intrinsics = sensor.ir_intrinsics$/;"	kind:variable	line:70
ir_intrinsics	../perception/tools/register_object.py	/^    ir_intrinsics = sensor.ir_intrinsics$/;"	kind:variable	line:51
ir_mtx	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        ir_mtx = [ir_intr.k1, ir_intr.k2, ir_intr.p1, ir_intr.p2, ir_intr.k3]$/;"	kind:variable	line:130
ir_mtx	../panda_autograsp/scripts/chessboard_calibration.py	/^        ir_mtx = [ir_intr.k1, ir_intr.k2, ir_intr.p1, ir_intr.p2, ir_intr.k3]$/;"	kind:variable	line:423
is_full	../autolab_core/autolab_core/tensor_dataset.py	/^    def is_full(self):$/;"	kind:member	line:89
is_positive_definite	../autolab_core/autolab_core/utils.py	/^def is_positive_definite(A):$/;"	kind:function	line:318
is_positive_semi_definite	../autolab_core/autolab_core/utils.py	/^def is_positive_semi_definite(A):$/;"	kind:function	line:342
is_py2	../gqcnn/gqcnn/utils/utils.py	/^def is_py2():$/;"	kind:function	line:48
is_recording	../perception/perception/video_recorder.py	/^    def is_recording(self):$/;"	kind:member	line:31
is_running	../perception/perception/camera_sensor.py	/^    def is_running(self):$/;"	kind:member	line:131
is_running	../perception/perception/colorized_phoxi_sensor.py	/^    def is_running(self):$/;"	kind:member	line:58
is_running	../perception/perception/ensenso_sensor.py	/^    def is_running(self):$/;"	kind:member	line:102
is_running	../perception/perception/kinect2_sensor.py	/^    def is_running(self):$/;"	kind:member	line:148
is_running	../perception/perception/kinect2_sensor.py	/^    def is_running(self):$/;"	kind:member	line:469
is_running	../perception/perception/kinect2_sensor.py	/^    def is_running(self):$/;"	kind:member	line:645
is_running	../perception/perception/phoxi_sensor.py	/^    def is_running(self):$/;"	kind:member	line:85
is_running	../perception/perception/primesense_sensor.py	/^    def is_running(self):$/;"	kind:member	line:349
is_running	../perception/perception/primesense_sensor.py	/^    def is_running(self):$/;"	kind:member	line:85
is_running	../perception/perception/realsense_sensor.py	/^    def is_running(self):$/;"	kind:member	line:139
is_running	../perception/perception/webcam_sensor.py	/^    def is_running(self):$/;"	kind:member	line:52
is_same_shape	../perception/perception/image.py	/^    def is_same_shape(self, other_im, check_channels=False):$/;"	kind:member	line:464
is_same_shape	../perception/perception/image.py	/^    def is_same_shape(self, other_im, check_channels=False):$/;"	kind:member	line:525
is_same_transform	../autolab_core/autolab_core/transformations.py	/^def is_same_transform(matrix0, matrix1):$/;"	kind:function	line:1665
is_started	../perception/perception/video_recorder.py	/^    def is_started(self):$/;"	kind:member	line:35
iteritems	../autolab_core/autolab_core/yaml_config.py	/^    def iteritems(self):$/;"	kind:member	line:66
j_coords	../autolab_core/autolab_core/points.py	/^    def j_coords(self):$/;"	kind:member	line:1016
json_numpy_obj_hook	../autolab_core/autolab_core/json_serialization.py	/^def json_numpy_obj_hook(dct):$/;"	kind:function	line:45
json_serialization.py	../autolab_core/autolab_core/json_serialization.py	1;"	kind:file	line:1
k	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        k = cv2.waitKey(delay=1)$/;"	kind:variable	line:181
k	../panda_autograsp/scripts/generate_arucoboard.py	/^        k = cv2.waitKey(100)$/;"	kind:variable	line:108
k	../perception/tools/register_camera.py	/^            k = 0$/;"	kind:variable	line:178
k_1	../panda_autograsp/scripts/chessboard_calibration.py	/^        k_1 = dist[0][0]  # First radial distortion coefficient$/;"	kind:variable	line:374
k_2	../panda_autograsp/scripts/chessboard_calibration.py	/^        k_2 = dist[0][1]  # Second ...$/;"	kind:variable	line:375
k_3	../panda_autograsp/scripts/chessboard_calibration.py	/^        k_3 = dist[0][4]  # Third ...$/;"	kind:variable	line:376
keras_resnet.py	../perception/tools/keras_resnet.py	1;"	kind:file	line:1
keras_vgg.py	../perception/tools/keras_vgg.py	1;"	kind:file	line:1
key	../panda_autograsp/scripts/chessboard_calibration.py	/^                key = cv2.waitKey(delay=1)$/;"	kind:variable	line:331
key	../panda_autograsp/scripts/chessboard_calibration.py	/^            key = cv2.waitKey(delay=1)$/;"	kind:variable	line:520
key	../panda_autograsp/scripts/kinect_processing.py	/^        key = cv2.waitKey(delay=1)$/;"	kind:variable	line:162
key	../perception/perception/features.py	/^    def key(self):$/;"	kind:member	line:73
key	../perception/tools/register_camera.py	/^                    key = cv2.waitKey(1) & 0xFF$/;"	kind:variable	line:150
keyboard_input	../autolab_core/autolab_core/utils.py	/^def keyboard_input(message, yesno=False):$/;"	kind:function	line:272
keypoint	../perception/perception/features.py	/^    def keypoint(self):$/;"	kind:member	line:46
keypoints	../perception/perception/features.py	/^    def keypoints(self):$/;"	kind:member	line:180
keys	../autolab_core/autolab_core/yaml_config.py	/^    def keys(self):$/;"	kind:member	line:31
keywords	../autolab_core/setup.py	/^    keywords = 'robotics grasping transformations',$/;"	kind:variable	line:31
keywords	../gqcnn/setup.py	/^    keywords="robotics grasping vision deep learning",$/;"	kind:variable	line:175
keywords	../panda_autograsp/setup.py	/^    keywords="robotics grasping vision deep learning franka gqcnn gpd",$/;"	kind:variable	line:248
keywords	../perception/setup.py	/^      keywords = 'robotics grasping vision perception',$/;"	kind:variable	line:34
keywords	../setup.py	/^    keywords="robotics grasping vision deep learning franka gqcnn gpd",$/;"	kind:variable	line:395
kinect2_sensor.py	../perception/perception/kinect2_sensor.py	1;"	kind:file	line:1
kinect2_sensor_bridge.py	../perception/tests/kinect2_sensor_bridge.py	1;"	kind:file	line:1
kinect_processing.py	../panda_autograsp/scripts/kinect_processing.py	1;"	kind:file	line:1
label	../perception/tools/keras_resnet.py	/^    label = resnet.top_prediction(im)$/;"	kind:variable	line:26
label	../perception/tools/keras_vgg.py	/^    label = vgg.top_prediction(im)$/;"	kind:variable	line:26
label	../perception/tools/predict_class_label.py	/^    label = cnn.top_prediction(im)$/;"	kind:variable	line:26
label_to_category	../perception/tools/keras_resnet.py	/^        label_to_category = eval(f.read())$/;"	kind:variable	line:21
label_to_category	../perception/tools/keras_vgg.py	/^        label_to_category = eval(f.read())$/;"	kind:variable	line:21
label_vectors	../autolab_core/autolab_core/learning_analysis.py	/^    def label_vectors(self):$/;"	kind:member	line:142
label_vectors	../autolab_core/autolab_core/learning_analysis.py	/^    def label_vectors(self):$/;"	kind:member	line:361
language	../autolab_core/docs/source/conf.py	/^language = None$/;"	kind:variable	line:75
language	../docs/source/conf.py	/^language = None$/;"	kind:variable	line:83
language	../gqcnn/docs/source/conf.py	/^language = None$/;"	kind:variable	line:78
language	../perception/docs/source/conf.py	/^language = None$/;"	kind:variable	line:75
latex_documents	../autolab_core/docs/source/conf.py	/^latex_documents = [$/;"	kind:variable	line:233
latex_documents	../gqcnn/docs/source/conf.py	/^latex_documents = [$/;"	kind:variable	line:235
latex_documents	../perception/docs/source/conf.py	/^latex_documents = [$/;"	kind:variable	line:234
latex_elements	../autolab_core/docs/source/conf.py	/^latex_elements = {$/;"	kind:variable	line:216
latex_elements	../gqcnn/docs/source/conf.py	/^latex_elements = {$/;"	kind:variable	line:218
latex_elements	../perception/docs/source/conf.py	/^latex_elements = {$/;"	kind:variable	line:217
learning_analysis.py	../autolab_core/autolab_core/learning_analysis.py	1;"	kind:file	line:1
license	../autolab_core/setup.py	/^    license = 'Apache Software License',$/;"	kind:variable	line:29
license	../gqcnn/setup.py	/^    license="Berkeley Copyright",$/;"	kind:variable	line:173
license	../panda_autograsp/setup.py	/^    license="Rick Staa Copyright",$/;"	kind:variable	line:246
license	../perception/setup.py	/^      license = 'Apache Software License',$/;"	kind:variable	line:32
license	../setup.py	/^    license="Rick Staa Copyright",$/;"	kind:variable	line:393
lineType	../panda_autograsp/scripts/chessboard_calibration.py	/^lineType = 1$/;"	kind:variable	line:68
linear_to_ij	../perception/perception/image.py	/^    def linear_to_ij(self, linear_inds):$/;"	kind:member	line:448
linear_trajectory_to	../autolab_core/autolab_core/rigid_transformations.py	/^    def linear_trajectory_to(self, target_tf, traj_len):$/;"	kind:member	line:318
list_files	../panda_autograsp/setup.py	/^def list_files(path=".", exclude=[], recursive=True, prepent_parent=False):$/;"	kind:function	line:84
list_files	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^def list_files(path=".", exclude=[], recursive=True, prepent_parent=False):$/;"	kind:function	line:202
list_watertight_meshes.py	../autolab_core/tools/list_watertight_meshes.py	1;"	kind:file	line:1
listener	../autolab_core/ros_nodes/rigid_transform_listener.py	/^    listener = tf2_ros.TransformListener(tfBuffer)$/;"	kind:variable	line:22
listener	../panda_autograsp/scripts/kinect_processing.py	/^    listener = SyncMultiFrameListener(FrameType.Color | FrameType.Ir | FrameType.Depth)$/;"	kind:variable	line:96
load	../autolab_core/autolab_core/csv_model.py	/^    def load(full_filename):$/;"	kind:member	line:379
load	../autolab_core/autolab_core/json_serialization.py	/^def load(*args, **kwargs):$/;"	kind:function	line:75
load	../autolab_core/autolab_core/learning_analysis.py	/^    def load(filename):$/;"	kind:member	line:224
load	../autolab_core/autolab_core/learning_analysis.py	/^    def load(filename):$/;"	kind:member	line:340
load	../autolab_core/autolab_core/rigid_transformations.py	/^    def load(filename):$/;"	kind:member	line:1007
load	../autolab_core/autolab_core/rigid_transformations.py	/^    def load(filename):$/;"	kind:member	line:1279
load	../autolab_core/autolab_core/tensor_dataset.py	/^    def load(filename, compressed=True, prealloc=None):$/;"	kind:member	line:179
load	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def load(save_dir):$/;"	kind:member	line:119
load	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def load(save_dir):$/;"	kind:member	line:197
load	../gqcnn/gqcnn/model/tf/fc_network_tf.py	/^    def load(model_dir, fc_config, log_file=None):$/;"	kind:member	line:86
load	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def load(model_dir, verbose=True, log_file=None):$/;"	kind:member	line:87
load	../perception/perception/camera_intrinsics.py	/^    def load(filename):$/;"	kind:member	line:450
load	../perception/perception/orthographic_intrinsics.py	/^    def load(filename):$/;"	kind:member	line:308
load_data	../autolab_core/autolab_core/points.py	/^    def load_data(filename):$/;"	kind:member	line:133
load_data	../perception/perception/image.py	/^    def load_data(filename):$/;"	kind:member	line:957
load_dir_path	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^load_dir_path = os.path.abspath($/;"	kind:variable	line:105
load_images	../perception/perception/kinect2_sensor.py	/^def load_images(cfg):$/;"	kind:function	line:791
log	../gqcnn/gqcnn/utils/train_stats_logger.py	/^    def log(self):$/;"	kind:member	line:64
log_file	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        log_file=os.path.abspath($/;"	kind:variable	line:89
log_file	../panda_autograsp/scripts/chessboard_calibration.py	/^        log_file=os.path.abspath($/;"	kind:variable	line:78
log_file	../panda_autograsp/scripts/generate_arucoboard.py	/^        log_file=os.path.abspath($/;"	kind:variable	line:55
log_file	../panda_autograsp/scripts/kinect_processing.py	/^        log_file=os.path.abspath($/;"	kind:variable	line:65
log_file	../panda_autograsp/scripts/plan_grasp.py	/^        log_file=os.path.abspath($/;"	kind:variable	line:51
log_trial_status	../gqcnn/gqcnn/search/utils.py	/^def log_trial_status(trials):$/;"	kind:function	line:204
logger	../gqcnn/examples/antipodal_grasp_sampling.py	/^logger = Logger.get_logger("examples\/antipodal_grasp_sampling.py")$/;"	kind:variable	line:47
logger	../gqcnn/examples/policy.py	/^logger = Logger.get_logger("examples\/policy.py")$/;"	kind:variable	line:57
logger	../gqcnn/examples/policy_ros.py	/^logger = Logger.get_logger("examples\/policy_ros.py")$/;"	kind:variable	line:55
logger	../gqcnn/examples/policy_with_image_proc.py	/^logger = Logger.get_logger("tools\/policy_with_image_proc.py")$/;"	kind:variable	line:57
logger	../gqcnn/gqcnn/utils/utils.py	/^logger = Logger.get_logger("gqcnn\/utils\/utils.py")$/;"	kind:variable	line:45
logger	../gqcnn/setup.py	/^logger = logging.getLogger("setup.py")$/;"	kind:variable	line:47
logger	../gqcnn/tools/analyze_gqcnn_performance.py	/^logger = Logger.get_logger("tools\/analyze_gqcnn_performance.py")$/;"	kind:variable	line:42
logger	../gqcnn/tools/finetune.py	/^logger = Logger.get_logger("tools\/finetune.py")$/;"	kind:variable	line:45
logger	../gqcnn/tools/hyperparam_search.py	/^logger = Logger.get_logger("tools\/hyperparam_search.py")$/;"	kind:variable	line:42
logger	../gqcnn/tools/plot_training_losses.py	/^logger = Logger.get_logger("tools\/plot_training_losses.py")$/;"	kind:variable	line:51
logger	../gqcnn/tools/run_policy.py	/^logger = Logger.get_logger("tools\/run_policy.py")$/;"	kind:variable	line:48
logger	../gqcnn/tools/train.py	/^logger = Logger.get_logger("tools\/train.py")$/;"	kind:variable	line:44
logger	../panda_autograsp/setup.py	/^logger = logging.getLogger(__name__)$/;"	kind:variable	line:46
logger	../perception/tools/capture_test_images.py	/^logger = Logger.get_logger('tools\/capture_test_images.py')$/;"	kind:variable	line:18
logger	../setup.py	/^logger = logging.getLogger(__name__)$/;"	kind:variable	line:73
logger.py	../autolab_core/autolab_core/logger.py	1;"	kind:file	line:1
loggers.py	../panda_autograsp/src/panda_autograsp/loggers.py	1;"	kind:file	line:1
long_description	../autolab_core/setup.py	/^    long_description = 'Core utilities for the Berkeley AutoLab. Includes rigid transformations, loggers, and 3D data wrappers.',$/;"	kind:variable	line:26
long_description	../panda_autograsp/setup.py	/^    long_description=readme,$/;"	kind:variable	line:242
long_description_content_type	../panda_autograsp/setup.py	/^    long_description_content_type="text\/markdown",$/;"	kind:variable	line:243
low_indices	../perception/tools/filter_images.py	/^    low_indices = np.where(point_cloud_world.data[2,:] < min_height)[0] $/;"	kind:variable	line:74
main	../perception/tests/kinect2_sensor_bridge.py	/^def main(args):$/;"	kind:function	line:25
main	../perception/tools/colorize_phoxi.py	/^def main():$/;"	kind:function	line:21
main	../perception/tools/test_ensenso.py	/^def main(args):$/;"	kind:function	line:14
main	../perception/tools/test_realsense.py	/^def main():$/;"	kind:function	line:17
make_split	../autolab_core/autolab_core/tensor_dataset.py	/^    def make_split(self, split_name, val_indices=None, train_pct=0.8, field_name=None):$/;"	kind:member	line:764
make_summary_table	../autolab_core/autolab_core/learning_analysis.py	/^    def make_summary_table(train_result, val_result, plot=True, save_dir=None, prepend="", save=False):$/;"	kind:member	line:236
man_pages	../autolab_core/docs/source/conf.py	/^man_pages = [$/;"	kind:variable	line:263
man_pages	../docs/source/conf.py	/^man_pages = [$/;"	kind:variable	line:282
man_pages	../gqcnn/docs/source/conf.py	/^man_pages = [(master_doc, "GQCNN", u"GQCNN Documentation", [author], 1)]$/;"	kind:variable	line:264
man_pages	../perception/docs/source/conf.py	/^man_pages = [$/;"	kind:variable	line:264
markerLength	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    markerLength=config_dict["MARKER_LENGTH"],$/;"	kind:variable	line:72
markerLength	../panda_autograsp/scripts/generate_arucoboard.py	/^        markerLength=MARKER_LENGTH,$/;"	kind:variable	line:93
markerLength	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    markerLength=ARUCO_CFG["MARKER_LENGTH"],$/;"	kind:variable	line:120
markerSeparation	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    markerSeparation=config_dict["MARKER_SEPARATION"],$/;"	kind:variable	line:73
markerSeparation	../panda_autograsp/scripts/generate_arucoboard.py	/^        markerSeparation=MARKER_SEPARATION,$/;"	kind:variable	line:94
markerSeparation	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    markerSeparation=ARUCO_CFG["MARKER_SEPARATION"],$/;"	kind:variable	line:121
marker_pose	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	/^marker_pose = PoseStamped()$/;"	kind:variable	line:14
markersX	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    markersX=config_dict["MARKERS_X"],$/;"	kind:variable	line:70
markersX	../panda_autograsp/scripts/generate_arucoboard.py	/^        markersX=MARKERS_X,$/;"	kind:variable	line:91
markersX	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    markersX=ARUCO_CFG["MARKERS_X"],$/;"	kind:variable	line:118
markersY	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    markersY=config_dict["MARKERS_Y"],$/;"	kind:variable	line:71
markersY	../panda_autograsp/scripts/generate_arucoboard.py	/^        markersY=MARKERS_Y,$/;"	kind:variable	line:92
markersY	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    markersY=ARUCO_CFG["MARKERS_Y"],$/;"	kind:variable	line:119
mask	../gqcnn/examples/policy_with_image_proc.py	/^    mask = np.zeros((camera_intr.height, camera_intr.width, 1), dtype=np.uint8)$/;"	kind:variable	line:140
mask_binary	../perception/perception/image.py	/^    def mask_binary(self, binary_im):$/;"	kind:member	line:1181
mask_binary	../perception/perception/image.py	/^    def mask_binary(self, binary_im):$/;"	kind:member	line:1774
mask_binary	../perception/perception/image.py	/^    def mask_binary(self, binary_im):$/;"	kind:member	line:2246
mask_binary	../perception/perception/image.py	/^    def mask_binary(self, binary_im):$/;"	kind:member	line:2909
mask_binary	../perception/perception/image.py	/^    def mask_binary(self, binary_im):$/;"	kind:member	line:3334
mask_by_ind	../perception/perception/image.py	/^    def mask_by_ind(self, inds):$/;"	kind:member	line:485
mask_by_linear_ind	../perception/perception/image.py	/^    def mask_by_linear_ind(self, linear_inds):$/;"	kind:member	line:507
master_doc	../autolab_core/docs/source/conf.py	/^master_doc = 'index'$/;"	kind:variable	line:54
master_doc	../docs/source/conf.py	/^master_doc = "index"$/;"	kind:variable	line:76
master_doc	../gqcnn/docs/source/conf.py	/^master_doc = "index"$/;"	kind:variable	line:57
master_doc	../moveit_tutorials/conf.py	/^master_doc = 'index'$/;"	kind:variable	line:9
master_doc	../perception/docs/source/conf.py	/^master_doc = 'index'$/;"	kind:variable	line:54
match	../perception/perception/feature_matcher.py	/^    def match(self, source_obj, target_obj):$/;"	kind:member	line:119
match	../perception/perception/feature_matcher.py	/^    def match(self, source_obj_features, target_obj_features):$/;"	kind:member	line:126
match	../perception/perception/feature_matcher.py	/^    def match(self, source_points, target_points, source_normals, target_normals):$/;"	kind:member	line:190
matrix	../autolab_core/autolab_core/rigid_transformations.py	/^    def matrix(self):$/;"	kind:member	line:1130
matrix	../autolab_core/autolab_core/rigid_transformations.py	/^    def matrix(self):$/;"	kind:member	line:240
matrix	../autolab_core/autolab_core/transformations.py	/^    def matrix(self):$/;"	kind:member	line:1467
max_angle	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def max_angle(self):$/;"	kind:member	line:648
max_height	../perception/tools/filter_images.py	/^max_height = 0.15$/;"	kind:variable	line:22
max_num_objects	../perception/tools/capture_dataset.py	/^    max_num_objects = config['max_num_objects']$/;"	kind:variable	line:181
max_pt	../autolab_core/autolab_core/primitives.py	/^    def max_pt(self):$/;"	kind:member	line:93
mean	../autolab_core/autolab_core/points.py	/^    def mean(self):$/;"	kind:member	line:591
mean_dist	../perception/tools/register_camera.py	/^                    mean_dist = np.mean(dists[ind])$/;"	kind:variable	line:210
mean_est_robot_point	../perception/tools/register_camera.py	/^                mean_est_robot_point = np.mean(est_robot_points_world.data, axis=1).reshape(3,1)$/;"	kind:variable	line:236
mean_est_robot_point	../perception/tools/register_camera.py	/^            mean_est_robot_point = np.mean(est_robot_points_world.data, axis=1).reshape(3,1)$/;"	kind:variable	line:173
mean_fixed_robot_point	../perception/tools/register_camera.py	/^                mean_fixed_robot_point = np.mean(fixed_robot_points_world.data, axis=1).reshape(3,1)$/;"	kind:variable	line:239
mean_num_objects	../perception/tools/capture_dataset.py	/^    mean_num_objects = config['mean_num_objects']$/;"	kind:variable	line:179
mean_true_robot_point	../perception/tools/register_camera.py	/^            mean_true_robot_point = np.mean(true_robot_points_world.data, axis=1).reshape(3,1)$/;"	kind:variable	line:172
median_depth_img	../perception/perception/camera_sensor.py	/^    def median_depth_img(self, num_img=1):$/;"	kind:member	line:224
median_depth_img	../perception/perception/colorized_phoxi_sensor.py	/^    def median_depth_img(self, num_img=1, fill_depth=0.0):$/;"	kind:member	line:122
median_depth_img	../perception/perception/ensenso_sensor.py	/^    def median_depth_img(self, num_img=1, fill_depth=0.0):$/;"	kind:member	line:163
median_depth_img	../perception/perception/kinect2_sensor.py	/^    def median_depth_img(self, num_img=1):$/;"	kind:member	line:289
median_depth_img	../perception/perception/kinect2_sensor.py	/^    def median_depth_img(self, num_img=1):$/;"	kind:member	line:742
median_depth_img	../perception/perception/kinect2_sensor.py	/^    def median_depth_img(self, num_img=1, fill_depth=0.0):$/;"	kind:member	line:546
median_depth_img	../perception/perception/phoxi_sensor.py	/^    def median_depth_img(self, num_img=1, fill_depth=0.0):$/;"	kind:member	line:178
median_depth_img	../perception/perception/primesense_sensor.py	/^    def median_depth_img(self, num_img=1, fill_depth=0.0):$/;"	kind:member	line:218
median_depth_img	../perception/perception/primesense_sensor.py	/^    def median_depth_img(self, num_img=1, fill_depth=0.0):$/;"	kind:member	line:387
median_images	../perception/perception/image.py	/^    def median_images(images):$/;"	kind:member	line:548
mesh	../autolab_core/tools/list_watertight_meshes.py	/^        mesh = trimesh.load_mesh(obj_filename)$/;"	kind:variable	line:42
mesh	../perception/tools/register_object.py	/^        mesh = mesh_file.read()$/;"	kind:variable	line:75
mesh_file	../perception/tools/register_object.py	/^        mesh_file = ObjFile(os.path.join(object_path, '{0}.obj'.format(args.object_name)))$/;"	kind:variable	line:74
mesh_filename	../perception/tools/capture_dataset.py	/^        mesh_filename = obj_config['mesh_filename']$/;"	kind:variable	line:206
message	../perception/tools/capture_dataset.py	/^        message = 'Please place %d objects:\\n' %(num_objects)$/;"	kind:variable	line:296
message	../perception/tools/capture_test_images.py	/^            message = 'Hit ENTER when ready.'$/;"	kind:variable	line:79
metadata	../autolab_core/autolab_core/tensor_dataset.py	/^    def metadata(self):$/;"	kind:member	line:352
metadata	../gqcnn/gqcnn/grasping/actions.py	/^    def metadata(self):$/;"	kind:member	line:72
metadata_filename	../autolab_core/autolab_core/tensor_dataset.py	/^    def metadata_filename(self):$/;"	kind:member	line:356
metadata_filename	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    metadata_filename = os.path.join(dataset_dir, 'metadata.json')$/;"	kind:variable	line:69
min_depth_img	../perception/perception/primesense_sensor.py	/^    def min_depth_img(self, num_img=1):$/;"	kind:member	line:241
min_depth_img	../perception/perception/primesense_sensor.py	/^    def min_depth_img(self, num_img=1):$/;"	kind:member	line:406
min_height	../perception/tools/filter_images.py	/^min_height = 0.001$/;"	kind:variable	line:21
min_images	../perception/perception/image.py	/^    def min_images(images):$/;"	kind:member	line:572
min_inliers	../perception/tools/register_camera.py	/^            min_inliers = int(num_poses * 0.6)$/;"	kind:variable	line:182
min_num_objects	../perception/tools/capture_dataset.py	/^    min_num_objects = config['min_num_objects']$/;"	kind:variable	line:180
min_pt	../autolab_core/autolab_core/primitives.py	/^    def min_pt(self):$/;"	kind:member	line:87
mispredicted_indices	../autolab_core/autolab_core/learning_analysis.py	/^    def mispredicted_indices(self):$/;"	kind:member	line:125
mkdir_safe	../autolab_core/autolab_core/utils.py	/^def mkdir_safe(path):$/;"	kind:function	line:48
mod_logger	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^mod_logger = Logger.get_logger(__name__)$/;"	kind:variable	line:58
model_config	../gqcnn/examples/policy.py	/^    model_config = json.load(open(os.path.join(model_path, "config.json"),$/;"	kind:variable	line:131
model_config	../gqcnn/ros_nodes/grasp_planner_node.py	/^    model_config = json.load(open(os.path.join(model_dir, "config.json"), "r"))$/;"	kind:variable	line:368
model_config	../panda_autograsp/nodes/grasp_planner_server.py	/^    model_config = json.load(open(os.path.join(model_dir, "config.json"), "r"))$/;"	kind:variable	line:161
model_dir	../gqcnn/examples/policy.py	/^        model_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:126
model_dir	../gqcnn/examples/policy.py	/^    model_dir = args.model_dir$/;"	kind:variable	line:98
model_dir	../gqcnn/examples/policy_with_image_proc.py	/^    model_dir = args.model_dir$/;"	kind:variable	line:93
model_dir	../gqcnn/ros_nodes/grasp_planner_node.py	/^    model_dir = os.path.join(model_dir, model_name)$/;"	kind:variable	line:367
model_dir	../gqcnn/ros_nodes/grasp_planner_node.py	/^    model_dir = rospy.get_param("~model_dir")$/;"	kind:variable	line:363
model_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^        model_dir = [os.path.join(model_dir[0], model) for model in models]$/;"	kind:variable	line:89
model_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^        model_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:79
model_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^    model_dir = [model_dir]$/;"	kind:variable	line:84
model_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^    model_dir = args.model_dir$/;"	kind:variable	line:75
model_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^    model_dir = os.path.join(model_dir, model_name)$/;"	kind:variable	line:81
model_dir	../gqcnn/tools/finetune.py	/^        model_dir = os.path.join(os.getcwd(), model_dir)$/;"	kind:variable	line:132
model_dir	../gqcnn/tools/finetune.py	/^        model_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:125
model_dir	../gqcnn/tools/finetune.py	/^    model_dir = args.model_dir$/;"	kind:variable	line:107
model_dir	../gqcnn/tools/finetune.py	/^    model_dir = os.path.join(model_dir, base_model_name)$/;"	kind:variable	line:139
model_dir	../panda_autograsp/nodes/grasp_planner_server.py	/^        model_dir = os.path.abspath(os.path.join(MODELS_PATH, model_name))$/;"	kind:variable	line:101
model_dir	../panda_autograsp/nodes/grasp_planner_server.py	/^        model_dir = rospy.get_param("~model_dir")$/;"	kind:variable	line:99
model_dir	../panda_autograsp/nodes/grasp_planner_server.py	/^    model_dir = os.path.join(MODELS_PATH, model_name)$/;"	kind:variable	line:114
model_dir	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^    model_dir = os.path.abspath(os.path.join(model_output, model))$/;"	kind:variable	line:106
model_dir	../perception/tools/analyze_cnn_classification.py	/^    model_dir = args.model_dir$/;"	kind:variable	line:225
model_dir	../perception/tools/predict_class_label.py	/^    model_dir = sys.argv[1]$/;"	kind:variable	line:16
model_download_url	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^                        model_download_url = [$/;"	kind:variable	line:130
model_name	../gqcnn/examples/policy.py	/^    model_name = args.model_name$/;"	kind:variable	line:94
model_name	../gqcnn/ros_nodes/grasp_planner_node.py	/^    model_name = rospy.get_param("~model_name")$/;"	kind:variable	line:362
model_name	../gqcnn/tools/analyze_gqcnn_performance.py	/^    model_name = args.model_name$/;"	kind:variable	line:71
model_name	../panda_autograsp/nodes/grasp_planner_server.py	/^        model_name = DEFAULT_MODEL$/;"	kind:variable	line:105
model_name	../panda_autograsp/nodes/grasp_planner_server.py	/^        model_name = DEFAULT_MODEL$/;"	kind:variable	line:97
model_name	../panda_autograsp/nodes/grasp_planner_server.py	/^        model_name = rospy.get_param("~model_name")$/;"	kind:variable	line:95
model_path	../gqcnn/examples/policy.py	/^    model_path = os.path.join(model_dir, model_name)$/;"	kind:variable	line:128
model_type	../perception/tools/predict_class_label.py	/^    model_type = sys.argv[2]$/;"	kind:variable	line:17
models	../gqcnn/tools/analyze_gqcnn_performance.py	/^        models = os.listdir(model_dir[0])$/;"	kind:variable	line:88
models_datasets_mismatch_msg	../gqcnn/tools/hyperparam_search.py	/^        models_datasets_mismatch_msg = ("Must have same number of base models"$/;"	kind:variable	line:98
most_free_pixel	../perception/perception/image.py	/^    def most_free_pixel(self):$/;"	kind:member	line:2684
move_group	../panda_autograsp/nodes/moveit_planner_server.py	/^        move_group="panda_arm",$/;"	kind:variable	line:65
move_group_gripper	../panda_autograsp/nodes/moveit_planner_server.py	/^        move_group_gripper="hand",$/;"	kind:variable	line:66
move_to_start.py	../franka_ros/franka_example_controllers/scripts/move_to_start.py	1;"	kind:file	line:1
moveit.py	../panda_autograsp/src/panda_autograsp/functions/moveit.py	1;"	kind:file	line:1
moveit_add_scene_collision_objects	../panda_autograsp/nodes/moveit_planner_server.py	/^        moveit_add_scene_collision_objects = True$/;"	kind:variable	line:60
moveit_add_scene_collision_objects	../panda_autograsp/nodes/moveit_planner_server.py	/^        moveit_add_scene_collision_objects = rospy.get_param($/;"	kind:variable	line:56
moveit_collision_objects.py	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	1;"	kind:file	line:1
moveit_planner_server.py	../panda_autograsp/nodes/moveit_planner_server.py	1;"	kind:file	line:1
moveit_planner_server_ros.py	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	1;"	kind:file	line:1
moveit_random_planner_client.py	../panda_autograsp/nodes/moveit_random_planner_client.py	1;"	kind:file	line:1
mse	../autolab_core/autolab_core/learning_analysis.py	/^    def mse(self):$/;"	kind:member	line:322
msg	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^            msg = "Model name is invalid. Please check the name and try again."$/;"	kind:variable	line:119
msg	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^            msg = "Model unzip failed."$/;"	kind:variable	line:176
msg	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^            msg = ($/;"	kind:variable	line:136
msg	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^            msg = ($/;"	kind:variable	line:154
msg	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^        msg = "Creating model folder in panda_autograsp root directory."$/;"	kind:variable	line:102
msg	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^        msg = model + " was already present and thus not downloaded."$/;"	kind:variable	line:197
msg	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^        msg = model + " was downloaded successfully."$/;"	kind:variable	line:193
msg_filter_callback	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def msg_filter_callback($/;"	kind:member	line:527
mtx	../panda_autograsp/scripts/chessboard_calibration.py	/^                    mtx=color_mtx,$/;"	kind:variable	line:529
n	../perception/tools/compute_normal_cloud_im.py	/^            n = normal_cloud_im[i,j]$/;"	kind:variable	line:41
n	../perception/tools/primesense_viewer.py	/^    n = 15$/;"	kind:variable	line:24
n2	../perception/tools/compute_normal_cloud_im.py	/^            n2 = normal_cloud_im_s[i,j]$/;"	kind:variable	line:42
name	../autolab_core/autolab_core/data_stream_recorder.py	/^    def name(self):$/;"	kind:member	line:186
name	../autolab_core/setup.py	/^    name='autolab_core',$/;"	kind:variable	line:23
name	../gqcnn/setup.py	/^    name="gqcnn",$/;"	kind:variable	line:167
name	../gqcnn/tools/finetune.py	/^                                         name=name)$/;"	kind:variable	line:172
name	../gqcnn/tools/finetune.py	/^    name = args.name$/;"	kind:variable	line:108
name	../gqcnn/tools/train.py	/^                                         name=name)$/;"	kind:variable	line:151
name	../gqcnn/tools/train.py	/^    name = args.name$/;"	kind:variable	line:97
name	../panda_autograsp/setup.py	/^    name="panda_autograsp",$/;"	kind:variable	line:239
name	../setup.py	/^    name="panda_autograsp_ws",$/;"	kind:variable	line:388
namespace	../gqcnn/examples/policy_ros.py	/^    namespace = args.namespace$/;"	kind:variable	line:91
nan_pixels	../perception/perception/image.py	/^    def nan_pixels(self):$/;"	kind:member	line:840
napoleon_include_init_with_doc	../autolab_core/docs/source/conf.py	/^napoleon_include_init_with_doc = True$/;"	kind:variable	line:40
napoleon_include_init_with_doc	../docs/source/conf.py	/^napoleon_include_init_with_doc = True$/;"	kind:variable	line:52
napoleon_include_init_with_doc	../gqcnn/docs/source/conf.py	/^napoleon_include_init_with_doc = True$/;"	kind:variable	line:43
napoleon_include_init_with_doc	../perception/docs/source/conf.py	/^napoleon_include_init_with_doc = True$/;"	kind:variable	line:40
napoleon_include_special_with_doc	../autolab_core/docs/source/conf.py	/^napoleon_include_special_with_doc = True$/;"	kind:variable	line:39
napoleon_include_special_with_doc	../docs/source/conf.py	/^napoleon_include_special_with_doc = True$/;"	kind:variable	line:51
napoleon_include_special_with_doc	../gqcnn/docs/source/conf.py	/^napoleon_include_special_with_doc = True$/;"	kind:variable	line:42
napoleon_include_special_with_doc	../perception/docs/source/conf.py	/^napoleon_include_special_with_doc = True$/;"	kind:variable	line:39
nargs	../gqcnn/tools/hyperparam_search.py	/^                        nargs="+",$/;"	kind:variable	line:49
nargs	../gqcnn/tools/hyperparam_search.py	/^                        nargs="+",$/;"	kind:variable	line:53
nargs	../gqcnn/tools/hyperparam_search.py	/^                        nargs="+",$/;"	kind:variable	line:57
nargs	../gqcnn/tools/hyperparam_search.py	/^                        nargs="+",$/;"	kind:variable	line:64
nargs	../gqcnn/tools/hyperparam_search.py	/^                        nargs="+",$/;"	kind:variable	line:76
nargs	../gqcnn/tools/hyperparam_search.py	/^                        nargs="+",$/;"	kind:variable	line:80
network_tf.py	../gqcnn/gqcnn/model/tf/network_tf.py	1;"	kind:file	line:1
new_filename	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^            new_filename = os.path.join(tensor_dir, f)$/;"	kind:variable	line:84
new_val_indices	../autolab_core/tools/shuffle_tensor_dataset.py	/^        new_val_indices = []$/;"	kind:variable	line:61
next	../autolab_core/autolab_core/csv_model.py	/^    def next(self):$/;"	kind:member	line:358
next	../autolab_core/autolab_core/tensor_dataset.py	/^    def next(self):$/;"	kind:member	line:114
next	../autolab_core/autolab_core/tensor_dataset.py	/^    def next(self):$/;"	kind:member	line:614
next	../autolab_core/autolab_core/transformations.py	/^    def next(self, acceleration=0.0):$/;"	kind:member	line:1462
next	../autolab_core/autolab_core/yaml_config.py	/^    next = __next__  # For Python 2.$/;"	kind:variable	line:163
next	../perception/perception/feature_matcher.py	/^    def next(self):$/;"	kind:member	line:54
next	../perception/perception/feature_matcher.py	/^    def next(self):$/;"	kind:member	line:95
noise_mask	../perception/tools/filter_images.py	/^    noise_mask = depth_im_filtered.to_binary()$/;"	kind:variable	line:180
nonzero_data	../perception/perception/image.py	/^    def nonzero_data(self):$/;"	kind:member	line:864
nonzero_hsv_data	../perception/perception/image.py	/^    def nonzero_hsv_data(self):$/;"	kind:member	line:1349
nonzero_indices	../autolab_core/autolab_core/points.py	/^    def nonzero_indices(self):$/;"	kind:member	line:680
nonzero_pixels	../perception/perception/image.py	/^    def nonzero_pixels(self):$/;"	kind:member	line:816
norm	../autolab_core/autolab_core/dual_quaternion.py	/^    def norm(self):$/;"	kind:member	line:100
norm_final_val_error	../gqcnn/tools/plot_training_losses.py	/^        norm_final_val_error = val_errors[-1] \/ pct_pos_val$/;"	kind:variable	line:105
norm_final_val_error	../gqcnn/tools/plot_training_losses.py	/^    norm_final_val_error = val_errors[-1] \/ val_errors[0]$/;"	kind:variable	line:103
norm_train_errors	../gqcnn/tools/plot_training_losses.py	/^    norm_train_errors = train_errors \/ init_val_error$/;"	kind:variable	line:101
norm_val_errors	../gqcnn/tools/plot_training_losses.py	/^    norm_val_errors = val_errors \/ init_val_error$/;"	kind:variable	line:102
normal	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def normal(self):$/;"	kind:member	line:191
normal	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def normal(self, value):$/;"	kind:member	line:196
normal	../perception/perception/features.py	/^    def normal(self):$/;"	kind:member	line:50
normal_cloud_im	../perception/perception/image.py	/^    def normal_cloud_im(self, ksize=3):$/;"	kind:member	line:3552
normal_cloud_im	../perception/tools/compute_normal_cloud_im.py	/^    normal_cloud_im = point_cloud_im.normal_cloud_im(ksize=KSIZE)$/;"	kind:variable	line:31
normalized	../autolab_core/autolab_core/dual_quaternion.py	/^    def normalized(self):$/;"	kind:member	line:112
normals	../autolab_core/autolab_core/points.py	/^    def normals(self):$/;"	kind:member	line:1182
normals	../perception/perception/features.py	/^    def normals(self):$/;"	kind:member	line:185
not_enough_splits_msg	../gqcnn/tools/hyperparam_search.py	/^            not_enough_splits_msg = ("Can't have fewer splits that"$/;"	kind:variable	line:110
num_adjacent	../perception/perception/image.py	/^    def num_adjacent(self, i, j):$/;"	kind:member	line:2725
num_categories	../autolab_core/autolab_core/learning_analysis.py	/^    def num_categories(self):$/;"	kind:member	line:109
num_categories	../autolab_core/autolab_core/learning_analysis.py	/^    def num_categories(self):$/;"	kind:member	line:357
num_channels	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def num_channels(self):$/;"	kind:member	line:604
num_clusters	../gqcnn/examples/policy_with_image_proc.py	/^    num_clusters = len(cluster_indices)$/;"	kind:variable	line:167
num_clusters	../perception/tools/filter_images.py	/^    num_clusters = len(cluster_indices)$/;"	kind:variable	line:123
num_datapoints	../autolab_core/autolab_core/learning_analysis.py	/^    def num_datapoints(self):$/;"	kind:member	line:105
num_datapoints	../autolab_core/autolab_core/learning_analysis.py	/^    def num_datapoints(self):$/;"	kind:member	line:326
num_datapoints	../autolab_core/autolab_core/tensor_dataset.py	/^    def num_datapoints(self):$/;"	kind:member	line:364
num_datapoints	../autolab_core/autolab_core/tensor_dataset.py	/^    def num_datapoints(self):$/;"	kind:member	line:67
num_datapoints	../autolab_core/tools/subsample_tensor_dataset.py	/^    num_datapoints = args.num_datapoints$/;"	kind:variable	line:47
num_datapoints	../autolab_core/tools/subsample_tensor_dataset.py	/^    num_datapoints = min(num_datapoints, dataset.num_datapoints)$/;"	kind:variable	line:52
num_devices	../panda_autograsp/scripts/kinect_processing.py	/^    num_devices = fn.enumerateDevices()$/;"	kind:variable	line:90
num_false_neg	../autolab_core/autolab_core/learning_analysis.py	/^    def num_false_neg(self):$/;"	kind:member	line:431
num_false_pos	../autolab_core/autolab_core/learning_analysis.py	/^    def num_false_pos(self):$/;"	kind:member	line:427
num_features	../perception/perception/features.py	/^    def num_features(self):$/;"	kind:member	line:166
num_grasp_samples	../gqcnn/examples/antipodal_grasp_sampling.py	/^    num_grasp_samples = config["num_grasp_samples"]$/;"	kind:variable	line:64
num_images	../perception/tools/capture_dataset.py	/^    num_images = args.num_images$/;"	kind:variable	line:137
num_inliers	../perception/tools/register_camera.py	/^                num_inliers = inliers.shape[0]$/;"	kind:variable	line:196
num_matches	../perception/perception/feature_matcher.py	/^    def num_matches(self):$/;"	kind:member	line:47
num_objects	../perception/tools/capture_dataset.py	/^            num_objects = min(max(num_objs_rv.rvs(size=1)[0] + 1, min_num_objects), num_test)$/;"	kind:variable	line:292
num_objects	../perception/tools/capture_dataset.py	/^            num_objects = min(max(num_objs_rv.rvs(size=1)[0] + 1, min_num_objects), num_train)$/;"	kind:variable	line:289
num_objects	../perception/tools/capture_dataset.py	/^    num_objects = len(objects)$/;"	kind:variable	line:165
num_objs_rv	../perception/tools/capture_dataset.py	/^    num_objs_rv = ss.poisson(mean_num_objects-1)$/;"	kind:variable	line:182
num_pixels	../autolab_core/autolab_core/primitives.py	/^    def num_pixels(self):$/;"	kind:member	line:142
num_plot	../gqcnn/examples/policy.py	/^            num_plot = 2$/;"	kind:variable	line:217
num_plot	../gqcnn/examples/policy.py	/^        num_plot = 1$/;"	kind:variable	line:215
num_plot	../gqcnn/examples/policy_with_image_proc.py	/^        num_plot = 3$/;"	kind:variable	line:194
num_plots	../perception/tools/capture_test_images.py	/^                num_plots = 3 if workspace is not None else 2$/;"	kind:variable	line:120
num_points	../autolab_core/autolab_core/points.py	/^    def num_points(self):$/;"	kind:member	line:1188
num_points	../autolab_core/autolab_core/points.py	/^    def num_points(self):$/;"	kind:member	line:94
num_points	../gqcnn/examples/policy_with_image_proc.py	/^        num_points = len(indices)$/;"	kind:variable	line:174
num_points	../perception/tools/filter_images.py	/^        num_points = len(indices)$/;"	kind:variable	line:129
num_poses	../perception/tools/register_camera.py	/^            num_poses = len(robot_poses)$/;"	kind:variable	line:180
num_pts_x	../perception/tools/register_camera.py	/^            num_pts_x = config['grid_x']$/;"	kind:variable	line:93
num_pts_y	../perception/tools/register_camera.py	/^            num_pts_y = config['grid_y']$/;"	kind:variable	line:94
num_rows	../autolab_core/autolab_core/csv_model.py	/^    def num_rows(self):$/;"	kind:member	line:88
num_segments	../perception/perception/image.py	/^    def num_segments(self):$/;"	kind:member	line:3271
num_tensors	../autolab_core/autolab_core/tensor_dataset.py	/^    def num_tensors(self):$/;"	kind:member	line:360
num_test	../perception/tools/capture_dataset.py	/^    num_test = num_objects - num_train$/;"	kind:variable	line:167
num_train	../perception/tools/capture_dataset.py	/^    num_train = int(np.ceil(train_pct * num_objects))$/;"	kind:variable	line:166
num_train_images	../perception/tools/capture_dataset.py	/^    num_train_images = int(np.ceil(train_pct * num_images))$/;"	kind:variable	line:173
num_trials_to_schedule	../gqcnn/gqcnn/search/resource_manager.py	/^    def num_trials_to_schedule(self, num_pending_trials):$/;"	kind:member	line:144
num_true_neg	../autolab_core/autolab_core/learning_analysis.py	/^    def num_true_neg(self):$/;"	kind:member	line:423
num_true_pos	../autolab_core/autolab_core/learning_analysis.py	/^    def num_true_pos(self):$/;"	kind:member	line:419
num_watertight	../autolab_core/tools/list_watertight_meshes.py	/^    num_watertight = 0$/;"	kind:variable	line:39
obj_cb_transform_file_path	../perception/tools/register_object.py	/^    obj_cb_transform_file_path = os.path.join(object_path, 'T_cb_{0}.tf'.format(args.object_name))$/;"	kind:variable	line:36
obj_filenames	../autolab_core/tools/list_watertight_meshes.py	/^    obj_filenames = utils.filenames(data_dir, tag='.obj')$/;"	kind:variable	line:40
obj_id	../autolab_core/tools/aggregate_tensor_datasets.py	/^    obj_id = 0$/;"	kind:variable	line:82
obj_ids	../autolab_core/tools/aggregate_tensor_datasets.py	/^    obj_ids = utils.reverse_dictionary(obj_ids)$/;"	kind:variable	line:122
obj_ids	../autolab_core/tools/aggregate_tensor_datasets.py	/^    obj_ids = {'unknown': 0}$/;"	kind:variable	line:83
obj_mat_props	../perception/tools/capture_dataset.py	/^        obj_mat_props = MaterialProperties(smooth=True,$/;"	kind:variable	line:210
obj_mesh	../perception/tools/capture_dataset.py	/^        obj_mesh = trimesh.load_mesh(mesh_filename)$/;"	kind:variable	line:208
obj_names	../perception/tools/capture_dataset.py	/^            obj_names = [objects[i] for i in np.random.choice(test_indices, size=num_objects, replace=False)]$/;"	kind:variable	line:293
obj_names	../perception/tools/capture_dataset.py	/^            obj_names = [objects[i] for i in np.random.choice(train_indices, size=num_objects, replace=False)]$/;"	kind:variable	line:290
obj_pose	../perception/tools/capture_dataset.py	/^        obj_pose = RigidTransform.load(pose_filename)$/;"	kind:variable	line:209
obj_segmask	../gqcnn/examples/policy_with_image_proc.py	/^    obj_segmask = SegmentationImage(obj_segmask_data.astype(np.uint8))$/;"	kind:variable	line:185
obj_segmask	../gqcnn/examples/policy_with_image_proc.py	/^    obj_segmask = obj_segmask.mask_binary(segmask)$/;"	kind:variable	line:186
obj_segmask_data	../gqcnn/examples/policy_with_image_proc.py	/^    obj_segmask_data = np.zeros(depth_im.shape)$/;"	kind:variable	line:169
object_path	../perception/tools/register_object.py	/^    object_path = os.path.join(config['objects_dir'], args.object_name)$/;"	kind:variable	line:35
object_render.py	../perception/perception/object_render.py	1;"	kind:file	line:1
objects	../perception/tools/capture_dataset.py	/^    objects = config['objects']$/;"	kind:variable	line:164
objp	../panda_autograsp/scripts/chessboard_calibration.py	/^    objp = np.zeros((N_COLMNS * N_ROWS, 3), np.float32)$/;"	kind:variable	line:130
objp	../perception/tools/register_webcam.py	/^            objp = np.zeros((nx*ny,3), np.float32)$/;"	kind:variable	line:62
objpoints	../panda_autograsp/scripts/chessboard_calibration.py	/^    objpoints = []  # 3d point in real world space$/;"	kind:variable	line:136
open	../autolab_core/autolab_core/points.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:1023
open	../autolab_core/autolab_core/points.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:1101
open	../autolab_core/autolab_core/points.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:375
open	../autolab_core/autolab_core/points.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:456
open	../autolab_core/autolab_core/points.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:825
open	../autolab_core/autolab_core/points.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:950
open	../autolab_core/autolab_core/tensor_dataset.py	/^    def open(dataset_dir, access_mode=READ_ONLY_ACCESS):$/;"	kind:member	line:716
open	../perception/perception/feature_extractors.py	/^    def open(self):$/;"	kind:member	line:43
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:1460
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:1910
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:2016
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:2133
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:2784
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:3373
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:3587
open	../perception/perception/image.py	/^    def open(filename, frame='unspecified'):$/;"	kind:member	line:3696
open_gripper_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def open_gripper_service(self, req):$/;"	kind:member	line:708
open_session	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def open_session(self):$/;"	kind:member	line:555
open_session	../perception/perception/cnn.py	/^    def open_session(self):$/;"	kind:member	line:141
opencv_camera_sensor.py	../perception/perception/opencv_camera_sensor.py	1;"	kind:file	line:1
option_spec	../moveit_tutorials/_scripts/tutorialformatter.py	/^    option_spec = dict(shell=flag, prompt=flag, nostderr=flag,$/;"	kind:variable	line:86
orientation	../gqcnn/gqcnn/grasping/grasp.py	/^    def orientation(self):$/;"	kind:member	line:544
original_action	../gqcnn/tools/run_policy.py	/^    original_action = ParallelJawGrasp.load(action_path)$/;"	kind:variable	line:96
orthogonal_basis	../autolab_core/autolab_core/points.py	/^    def orthogonal_basis(self):$/;"	kind:member	line:428
orthogonalization_matrix	../autolab_core/autolab_core/transformations.py	/^def orthogonalization_matrix(lengths, angles):$/;"	kind:function	line:838
orthographic_intrinsics.py	../perception/perception/orthographic_intrinsics.py	1;"	kind:file	line:1
out	../perception/tools/keras_resnet.py	/^    out = resnet.predict(im)$/;"	kind:variable	line:25
out	../perception/tools/keras_vgg.py	/^    out = vgg.predict(im)$/;"	kind:variable	line:25
out	../perception/tools/predict_class_label.py	/^    out = cnn.predict(im)$/;"	kind:variable	line:25
out_config_filename	../autolab_core/tools/aggregate_tensor_datasets.py	/^    out_config_filename = os.path.join(output_dataset_name, 'merge_config.yaml')$/;"	kind:variable	line:78
out_dataset	../autolab_core/tools/shuffle_tensor_dataset.py	/^    out_dataset = TensorDataset(output_path, dataset.config)$/;"	kind:variable	line:48
out_dataset	../autolab_core/tools/subsample_tensor_dataset.py	/^    out_dataset = TensorDataset(output_path, dataset.config)$/;"	kind:variable	line:50
out_f	../autolab_core/tools/list_watertight_meshes.py	/^    out_f = open(out_filename, 'w')$/;"	kind:variable	line:37
out_filename	../autolab_core/tools/list_watertight_meshes.py	/^    out_filename = os.path.join(data_dir, 'watertight_listing.txt')$/;"	kind:variable	line:36
output	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def output(self):$/;"	kind:member	line:628
output_dataset	../autolab_core/tools/aggregate_tensor_datasets.py	/^    output_dataset = TensorDataset(output_dataset_name, tensor_config)$/;"	kind:variable	line:75
output_dataset_name	../autolab_core/tools/aggregate_tensor_datasets.py	/^    output_dataset_name = cfg['output_dataset']$/;"	kind:variable	line:51
output_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^        output_dir = os.path.join(os.getcwd(), output_dir)$/;"	kind:variable	line:102
output_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^        output_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:93
output_dir	../gqcnn/tools/analyze_gqcnn_performance.py	/^    output_dir = args.output_dir$/;"	kind:variable	line:72
output_dir	../gqcnn/tools/finetune.py	/^        output_dir = os.path.join(os.getcwd(), output_dir)$/;"	kind:variable	line:134
output_dir	../gqcnn/tools/finetune.py	/^        output_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:114
output_dir	../gqcnn/tools/finetune.py	/^        output_dir = os.path.join(output_dir, unique_name)$/;"	kind:variable	line:157
output_dir	../gqcnn/tools/finetune.py	/^    output_dir = args.output_dir$/;"	kind:variable	line:103
output_dir	../gqcnn/tools/hyperparam_search.py	/^                         output_dir=output_dir,$/;"	kind:variable	line:124
output_dir	../gqcnn/tools/hyperparam_search.py	/^    output_dir = args.output_dir$/;"	kind:variable	line:89
output_dir	../gqcnn/tools/run_policy.py	/^    output_dir = args.output_dir$/;"	kind:variable	line:71
output_dir	../gqcnn/tools/train.py	/^        output_dir = os.path.join(os.getcwd(), output_dir)$/;"	kind:variable	line:116
output_dir	../gqcnn/tools/train.py	/^        output_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)),$/;"	kind:variable	line:103
output_dir	../gqcnn/tools/train.py	/^        output_dir = os.path.join(output_dir, unique_name)$/;"	kind:variable	line:136
output_dir	../gqcnn/tools/train.py	/^    output_dir = args.output_dir$/;"	kind:variable	line:93
output_dir	../perception/tools/capture_dataset.py	/^    output_dir = args.output_dir$/;"	kind:variable	line:136
output_dir	../perception/tools/capture_test_images.py	/^    output_dir = args.output_dir$/;"	kind:variable	line:27
output_dir	../perception/tools/register_camera.py	/^        output_dir = os.path.join(config['calib_dir'], sensor_frame)$/;"	kind:variable	line:250
output_dir	../perception/tools/register_webcam.py	/^        output_dir = os.path.join(config['calib_dir'], sensor_frame)$/;"	kind:variable	line:89
output_filename	../perception/tools/register_object.py	/^    output_filename = os.path.join(output_path, '{0}_to_world.tf'.format(T_world_obj.from_frame))$/;"	kind:variable	line:64
output_path	../autolab_core/tools/compute_dataset_statistics.py	/^        output_path = os.path.join(dataset_path, 'stats')$/;"	kind:variable	line:171
output_path	../autolab_core/tools/compute_dataset_statistics.py	/^    output_path = args.output_path$/;"	kind:variable	line:165
output_path	../autolab_core/tools/shuffle_tensor_dataset.py	/^    output_path = args.output_path$/;"	kind:variable	line:45
output_path	../autolab_core/tools/subsample_tensor_dataset.py	/^    output_path = args.output_path$/;"	kind:variable	line:46
output_path	../perception/tools/register_object.py	/^    output_path = os.path.join(config['calib_dir'], T_world_obj.from_frame)$/;"	kind:variable	line:60
p	../perception/tools/compute_normal_cloud_im.py	/^            p = point_cloud_im[i,j]$/;"	kind:variable	line:40
p	../perception/tools/register_camera.py	/^                p = ir_intrinsics.deproject_pixel(depth,$/;"	kind:variable	line:158
p_1	../panda_autograsp/scripts/chessboard_calibration.py	/^        p_1 = dist[0][2]  # First tangential distortion coefficient$/;"	kind:variable	line:377
p_2	../panda_autograsp/scripts/chessboard_calibration.py	/^        p_2 = dist[0][3]  # Second ..$/;"	kind:variable	line:378
package_dir	../panda_autograsp/setup.py	/^    package_dir={"": "src"},$/;"	kind:variable	line:256
packages	../autolab_core/setup.py	/^    packages = ['autolab_core'],$/;"	kind:variable	line:42
packages	../gqcnn/setup.py	/^    packages=find_packages(),$/;"	kind:variable	line:185
packages	../panda_autograsp/setup.py	/^    packages=find_packages(where="src"),$/;"	kind:variable	line:257
packages	../perception/setup.py	/^      packages=['perception'],$/;"	kind:variable	line:45
packages	../setup.py	/^    packages=find_packages(),$/;"	kind:variable	line:403
packet_modes	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^packet_modes = {}$/;"	kind:variable	line:65
panda_autograsp_cli	../panda_autograsp/nodes/panda_autograsp_cli.py	/^    panda_autograsp_cli = PandaAutograspCLI()$/;"	kind:variable	line:676
panda_autograsp_cli.py	../panda_autograsp/nodes/panda_autograsp_cli.py	1;"	kind:file	line:1
panda_autograsp_server.py	../panda_autograsp/nodes/panda_autograsp_server.py	1;"	kind:file	line:1
panda_autograsp_server_ros.py	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	1;"	kind:file	line:1
parameters	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            parameters=ARUCO_PARAMETERS,$/;"	kind:variable	line:145
parse_master_train_config	../gqcnn/gqcnn/search/utils.py	/^def parse_master_train_config(train_config):$/;"	kind:function	line:93
parser	../autolab_core/tools/aggregate_tensor_datasets.py	/^    parser = argparse.ArgumentParser(description='Merges a set of tensor datasets')$/;"	kind:variable	line:43
parser	../autolab_core/tools/compute_dataset_statistics.py	/^    parser = argparse.ArgumentParser(description='Compute statistics of select fields of a tensor dataset')$/;"	kind:variable	line:158
parser	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    parser = argparse.ArgumentParser(description='Convert a legacy training dataset to TensorDataset (saves in-place)')$/;"	kind:variable	line:20
parser	../autolab_core/tools/shuffle_tensor_dataset.py	/^    parser = argparse.ArgumentParser(description='Subsamples a dataset')$/;"	kind:variable	line:40
parser	../autolab_core/tools/split_dataset.py	/^    parser = argparse.ArgumentParser(description='Split a training TensorDataset based on an attribute')$/;"	kind:variable	line:43
parser	../autolab_core/tools/subsample_tensor_dataset.py	/^    parser = argparse.ArgumentParser(description='Subsamples a dataset')$/;"	kind:variable	line:40
parser	../gqcnn/examples/antipodal_grasp_sampling.py	/^    parser = argparse.ArgumentParser(description=($/;"	kind:variable	line:51
parser	../gqcnn/examples/policy.py	/^    parser = argparse.ArgumentParser($/;"	kind:variable	line:61
parser	../gqcnn/examples/policy_ros.py	/^    parser = argparse.ArgumentParser($/;"	kind:variable	line:59
parser	../gqcnn/examples/policy_with_image_proc.py	/^    parser = argparse.ArgumentParser($/;"	kind:variable	line:61
parser	../gqcnn/tools/analyze_gqcnn_performance.py	/^    parser = argparse.ArgumentParser($/;"	kind:variable	line:46
parser	../gqcnn/tools/finetune.py	/^    parser = argparse.ArgumentParser(description=($/;"	kind:variable	line:49
parser	../gqcnn/tools/hyperparam_search.py	/^    parser = argparse.ArgumentParser($/;"	kind:variable	line:46
parser	../gqcnn/tools/run_policy.py	/^    parser = argparse.ArgumentParser($/;"	kind:variable	line:52
parser	../gqcnn/tools/train.py	/^    parser = argparse.ArgumentParser($/;"	kind:variable	line:48
parser	../perception/tools/analyze_cnn_classification.py	/^    parser = argparse.ArgumentParser(description='Fine-tune a Classification CNN trained on ImageNet on a custom image dataset using TensorFlow')$/;"	kind:variable	line:220
parser	../perception/tools/capture_dataset.py	/^    parser = argparse.ArgumentParser(description='Capture a dataset of RGB-D images from a set of sensors')$/;"	kind:variable	line:131
parser	../perception/tools/capture_test_images.py	/^    parser = argparse.ArgumentParser(description='Capture a set of RGB-D images from a set of sensors')$/;"	kind:variable	line:22
parser	../perception/tools/filter_images.py	/^    parser = argparse.ArgumentParser(description='Filter a set of images')$/;"	kind:variable	line:35
parser	../perception/tools/finetune_classification_cnn.py	/^    parser = argparse.ArgumentParser(description='Fine-tune a Classification CNN trained on ImageNet on a custom image dataset using TensorFlow')$/;"	kind:variable	line:209
parser	../perception/tools/register_camera.py	/^    parser = argparse.ArgumentParser(description='Register a camera to a robot')$/;"	kind:variable	line:42
parser	../perception/tools/register_ensenso.py	/^    parser = argparse.ArgumentParser(description='Register a camera to a robot')$/;"	kind:variable	line:154
parser	../perception/tools/register_object.py	/^    parser = argparse.ArgumentParser()$/;"	kind:variable	line:24
parser	../perception/tools/register_webcam.py	/^    parser = argparse.ArgumentParser(description='Register a webcam to the robot')$/;"	kind:variable	line:22
path_planning_service	../panda_autograsp/nodes/moveit_planner_server.py	/^    path_planning_service = MoveitPlannerServer($/;"	kind:variable	line:63
path_to_images	../perception/perception/camera_sensor.py	/^    def path_to_images(self):$/;"	kind:member	line:124
path_to_images	../perception/perception/kinect2_sensor.py	/^    def path_to_images(self):$/;"	kind:member	line:638
pause	../autolab_core/autolab_core/data_stream_syncer.py	/^    def pause(self):$/;"	kind:member	line:133
pc_cam	../perception/tools/register_object.py	/^        pc_cam = ir_intrinsics.deproject(depth_im)$/;"	kind:variable	line:71
pc_world	../perception/tools/register_object.py	/^        pc_world = T_world_cam * pc_cam$/;"	kind:variable	line:72
pcl_cloud	../gqcnn/examples/policy_with_image_proc.py	/^    pcl_cloud = pcl.PointCloud(point_cloud.data.T.astype(np.float32))$/;"	kind:variable	line:157
pcl_cloud	../perception/tools/filter_images.py	/^    pcl_cloud = pcl.PointCloud(point_cloud_masked.data.T.astype(np.float32))$/;"	kind:variable	line:113
pcl_start	../perception/tools/filter_images.py	/^    pcl_start = time.time()$/;"	kind:variable	line:102
pcl_stop	../perception/tools/filter_images.py	/^    pcl_stop = time.time()$/;"	kind:variable	line:145
pct_pos_val	../gqcnn/tools/plot_training_losses.py	/^        pct_pos_val = 100.0 * np.load(pct_pos_val_filename)$/;"	kind:variable	line:70
pct_pos_val	../gqcnn/tools/plot_training_losses.py	/^    pct_pos_val = float(val_errors[0])$/;"	kind:variable	line:68
pct_pos_val_filename	../gqcnn/tools/plot_training_losses.py	/^    pct_pos_val_filename = os.path.join(result_dir, GQCNNFilenames.PCT_POS_VAL)$/;"	kind:variable	line:60
pct_pred_neg	../autolab_core/autolab_core/learning_analysis.py	/^    def pct_pred_neg(self):$/;"	kind:member	line:447
pct_pred_pos	../autolab_core/autolab_core/learning_analysis.py	/^    def pct_pred_pos(self):$/;"	kind:member	line:443
pct_true_neg	../autolab_core/autolab_core/learning_analysis.py	/^    def pct_true_neg(self):$/;"	kind:member	line:439
pct_true_pos	../autolab_core/autolab_core/learning_analysis.py	/^    def pct_true_pos(self):$/;"	kind:member	line:435
pearson_correlation	../autolab_core/autolab_core/learning_analysis.py	/^    def pearson_correlation(self):$/;"	kind:member	line:195
phi_coef	../autolab_core/autolab_core/learning_analysis.py	/^    def phi_coef(self):$/;"	kind:member	line:399
phi_coef_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def phi_coef_curve(self, delta_tau=0.01):$/;"	kind:member	line:627
phoxi_sensor.py	../perception/perception/phoxi_sensor.py	1;"	kind:file	line:1
pipeline	../panda_autograsp/scripts/kinect_processing.py	/^        pipeline = CpuPacketPipeline()$/;"	kind:variable	line:86
pipeline	../panda_autograsp/scripts/kinect_processing.py	/^        pipeline = OpenCLPacketPipeline()$/;"	kind:variable	line:82
pixels_farther_than	../perception/perception/image.py	/^    def pixels_farther_than(self, depth_im, filter_equal_depth=False):$/;"	kind:member	line:1795
pixelwise_or	../perception/perception/image.py	/^    def pixelwise_or(self, binary_im):$/;"	kind:member	line:2264
place	../autolab_core/autolab_core/transformations.py	/^    def place(self, center, radius):$/;"	kind:member	line:1407
plan_cartesian_path_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def plan_cartesian_path_service(self, req):$/;"	kind:member	line:404
plan_exists	../panda_autograsp/src/panda_autograsp/functions/moveit.py	/^def plan_exists(plan):$/;"	kind:function	line:71
plan_grasp	../gqcnn/examples/policy_ros.py	/^    plan_grasp = rospy.ServiceProxy("%s\/grasp_planner" % (namespace),$/;"	kind:variable	line:111
plan_grasp	../gqcnn/ros_nodes/grasp_planner_node.py	/^    def plan_grasp(self, req):$/;"	kind:member	line:148
plan_grasp	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def plan_grasp(self):$/;"	kind:member	line:404
plan_grasp	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    def plan_grasp(self, req):$/;"	kind:member	line:158
plan_grasp.py	../panda_autograsp/scripts/plan_grasp.py	1;"	kind:file	line:1
plan_grasp_bb	../gqcnn/ros_nodes/grasp_planner_node.py	/^    def plan_grasp_bb(self, req):$/;"	kind:member	line:159
plan_grasp_bb	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def plan_grasp_bb(self, bounding_box=None):$/;"	kind:member	line:416
plan_grasp_bb	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    def plan_grasp_bb(self, req):$/;"	kind:member	line:173
plan_grasp_segmask	../gqcnn/examples/policy_ros.py	/^    plan_grasp_segmask = rospy.ServiceProxy($/;"	kind:variable	line:113
plan_grasp_segmask	../gqcnn/ros_nodes/grasp_planner_node.py	/^    def plan_grasp_segmask(self, req):$/;"	kind:member	line:173
plan_grasp_segmask	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def plan_grasp_segmask(self, segmask):$/;"	kind:member	line:437
plan_grasp_segmask	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    def plan_grasp_segmask(self, req):$/;"	kind:member	line:190
plan_grasp_service	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def plan_grasp_service(self, req):$/;"	kind:member	line:608
plan_gripper_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def plan_gripper_service(self, req):$/;"	kind:member	line:621
plan_place_service	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def plan_place_service(self, req):$/;"	kind:member	line:667
plan_random_cartesian_path_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def plan_random_cartesian_path_service(self, req):$/;"	kind:member	line:499
plan_random_joint_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def plan_random_joint_service(self, req):$/;"	kind:member	line:466
plan_random_pose_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def plan_random_pose_service(self, req):$/;"	kind:member	line:433
plan_to_joint_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def plan_to_joint_service(self, req):$/;"	kind:member	line:327
plan_to_point_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def plan_to_point_service(self, req):$/;"	kind:member	line:358
plan_to_random_joint_srv	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        plan_to_random_joint_srv = rospy.ServiceProxy($/;"	kind:variable	line:68
plan_to_random_path_srv	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        plan_to_random_path_srv = rospy.ServiceProxy($/;"	kind:variable	line:86
plan_to_random_pose_srv	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        plan_to_random_pose_srv = rospy.ServiceProxy($/;"	kind:variable	line:50
plane_height	../perception/perception/orthographic_intrinsics.py	/^    def plane_height(self):$/;"	kind:member	line:61
plane_width	../perception/perception/orthographic_intrinsics.py	/^    def plane_width(self):$/;"	kind:member	line:67
planner	../panda_autograsp/nodes/moveit_planner_server.py	/^        planner="TRRTkConfigDefault",$/;"	kind:variable	line:68
plot_training_losses.py	../gqcnn/tools/plot_training_losses.py	1;"	kind:file	line:1
point_cloud	../gqcnn/examples/policy_with_image_proc.py	/^        point_cloud = camera_intr.deproject(depth_im)$/;"	kind:variable	line:204
point_cloud	../gqcnn/examples/policy_with_image_proc.py	/^    point_cloud = camera_intr.deproject(depth_im)$/;"	kind:variable	line:155
point_cloud	../perception/tools/primesense_viewer.py	/^    point_cloud = camera_intr.deproject(depth_im)$/;"	kind:variable	line:37
point_cloud_cam	../perception/tools/capture_test_images.py	/^                point_cloud_cam = camera_intr.deproject(depth)$/;"	kind:variable	line:88
point_cloud_cam	../perception/tools/filter_images.py	/^    point_cloud_cam = T_camera_world.inverse() * point_cloud_filtered$/;"	kind:variable	line:176
point_cloud_cam	../perception/tools/filter_images.py	/^    point_cloud_cam = small_camera_intr.deproject(small_depth_im)$/;"	kind:variable	line:65
point_cloud_filtered	../perception/tools/filter_images.py	/^    point_cloud_filtered = PointCloud(all_points, frame='world')        $/;"	kind:variable	line:144
point_cloud_filtered	../perception/tools/filter_images.py	/^    point_cloud_filtered = copy.deepcopy(point_cloud_world)$/;"	kind:variable	line:69
point_cloud_im	../perception/tools/compute_normal_cloud_im.py	/^    point_cloud_im = camera_intr.deproject_to_image(depth_im)$/;"	kind:variable	line:30
point_cloud_world	../perception/tools/capture_test_images.py	/^                point_cloud_world = T_camera_world * point_cloud_cam$/;"	kind:variable	line:90
point_cloud_world	../perception/tools/filter_images.py	/^    point_cloud_world = T_camera_world * point_cloud_cam$/;"	kind:variable	line:67
point_normal_cloud	../perception/perception/detector.py	/^    def point_normal_cloud(self):$/;"	kind:member	line:94
point_normal_cloud	../perception/perception/image.py	/^    def point_normal_cloud(self, camera_intr):$/;"	kind:member	line:1887
point_registration.py	../perception/perception/point_registration.py	1;"	kind:file	line:1
points	../autolab_core/autolab_core/points.py	/^    def points(self):$/;"	kind:member	line:1176
points	../gqcnn/examples/policy_with_image_proc.py	/^        points = np.zeros([3, num_points])$/;"	kind:variable	line:175
points	../perception/tools/compute_normal_cloud_im.py	/^                points = np.array([p, p + alpha*n2])$/;"	kind:variable	line:47
points	../perception/tools/compute_normal_cloud_im.py	/^                points = np.array([p, p + alpha*n])$/;"	kind:variable	line:44
points	../perception/tools/filter_images.py	/^        points = np.zeros([3,num_points])$/;"	kind:variable	line:130
points.py	../autolab_core/autolab_core/points.py	1;"	kind:file	line:1
points_world	../perception/tools/register_camera.py	/^                points_world = T_camera_world * ir_intrinsics.deproject(depth_im)$/;"	kind:variable	line:231
points_world	../perception/tools/register_camera.py	/^                points_world = T_camera_world * ir_intrinsics.deproject(depth_im)$/;"	kind:variable	line:314
policies	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def policies(self):$/;"	kind:member	line:1543
policy	../gqcnn/examples/policy.py	/^            policy = CrossEntropyRobustGraspingPolicy(policy_config)$/;"	kind:variable	line:254
policy	../gqcnn/examples/policy.py	/^            policy = FullyConvolutionalGraspingPolicyParallelJaw(policy_config)$/;"	kind:variable	line:242
policy	../gqcnn/examples/policy.py	/^            policy = FullyConvolutionalGraspingPolicySuction(policy_config)$/;"	kind:variable	line:240
policy	../gqcnn/examples/policy.py	/^            policy = RobustGraspingPolicy(policy_config)$/;"	kind:variable	line:252
policy	../gqcnn/examples/policy_with_image_proc.py	/^        policy = CrossEntropyRobustGraspingPolicy(policy_config)$/;"	kind:variable	line:226
policy	../gqcnn/examples/policy_with_image_proc.py	/^        policy = RobustGraspingPolicy(policy_config)$/;"	kind:variable	line:224
policy	../gqcnn/tools/run_policy.py	/^    policy = CrossEntropyRobustGraspingPolicy(policy_config)$/;"	kind:variable	line:99
policy.py	../gqcnn/examples/policy.py	1;"	kind:file	line:1
policy.py	../gqcnn/gqcnn/grasping/policy/policy.py	1;"	kind:file	line:1
policy_cfg	../gqcnn/ros_nodes/grasp_planner_node.py	/^    policy_cfg = cfg["policy"]$/;"	kind:variable	line:400
policy_cfg	../panda_autograsp/nodes/grasp_planner_server.py	/^    policy_cfg = cfg["policy"]$/;"	kind:variable	line:243
policy_config	../gqcnn/examples/policy.py	/^    policy_config = config["policy"]$/;"	kind:variable	line:179
policy_config	../gqcnn/examples/policy_with_image_proc.py	/^    policy_config = config["policy"]$/;"	kind:variable	line:116
policy_config	../gqcnn/tools/run_policy.py	/^    policy_config = config["policy"]$/;"	kind:variable	line:90
policy_exceptions.py	../gqcnn/gqcnn/utils/policy_exceptions.py	1;"	kind:file	line:1
policy_ros.py	../gqcnn/examples/policy_ros.py	1;"	kind:file	line:1
policy_start	../gqcnn/examples/policy.py	/^    policy_start = time.time()$/;"	kind:variable	line:259
policy_start	../gqcnn/examples/policy_with_image_proc.py	/^    policy_start = time.time()$/;"	kind:variable	line:227
policy_start	../gqcnn/tools/run_policy.py	/^    policy_start = time.time()$/;"	kind:variable	line:130
policy_type	../gqcnn/examples/policy.py	/^            policy_type = policy_config["type"]$/;"	kind:variable	line:250
policy_type	../gqcnn/examples/policy.py	/^        policy_type = "cem"$/;"	kind:variable	line:248
policy_type	../gqcnn/examples/policy_with_image_proc.py	/^        policy_type = policy_config["type"]$/;"	kind:variable	line:222
policy_type	../gqcnn/examples/policy_with_image_proc.py	/^    policy_type = "cem"$/;"	kind:variable	line:220
policy_with_image_proc.py	../gqcnn/examples/policy_with_image_proc.py	1;"	kind:file	line:1
pose	../gqcnn/gqcnn/grasping/grasp.py	/^    def pose(self):$/;"	kind:member	line:395
pose	../gqcnn/gqcnn/grasping/grasp.py	/^    def pose(self):$/;"	kind:member	line:498
pose	../gqcnn/gqcnn/grasping/grasp.py	/^    def pose(self, grasp_approach_dir=None):$/;"	kind:member	line:185
pose	../perception/perception/features.py	/^    def pose(self):$/;"	kind:member	line:81
pose_Calib_method	../panda_autograsp/nodes/panda_autograsp_server.py	/^        pose_Calib_method = ""$/;"	kind:variable	line:47
pose_Calib_method	../panda_autograsp/nodes/panda_autograsp_server.py	/^        pose_Calib_method = rospy.get_param("~calib_type")$/;"	kind:variable	line:45
pose_dim	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def pose_dim(self):$/;"	kind:member	line:608
pose_dim	../gqcnn/gqcnn/utils/utils.py	/^def pose_dim(gripper_mode):$/;"	kind:function	line:77
pose_filename	../perception/tools/capture_dataset.py	/^        pose_filename = obj_config['pose_filename']$/;"	kind:variable	line:207
pose_filename	../perception/tools/register_camera.py	/^        pose_filename = os.path.join(output_dir, '%s_to_world.tf' %(sensor_frame))$/;"	kind:variable	line:253
pose_filename	../perception/tools/register_webcam.py	/^        pose_filename = os.path.join(output_dir, '%s_to_world.tf' %(sensor_frame))$/;"	kind:variable	line:92
pose_msg	../autolab_core/autolab_core/rigid_transformations.py	/^    def pose_msg(self):$/;"	kind:member	line:269
pose_msg_stamped_2_matrix	../panda_autograsp/src/panda_autograsp/functions/conversions.py	/^def pose_msg_stamped_2_matrix(pose_msg):$/;"	kind:function	line:55
pose_pub	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	/^pose_pub = None$/;"	kind:variable	line:16
pose_reference_frame	../panda_autograsp/nodes/moveit_planner_server.py	/^        pose_reference_frame="panda_link0",$/;"	kind:variable	line:67
position	../autolab_core/autolab_core/rigid_transformations.py	/^    def position(self):$/;"	kind:member	line:152
position	../autolab_core/autolab_core/rigid_transformations.py	/^    def position(self, position):$/;"	kind:member	line:159
position_limits	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	/^position_limits = [[-0.6, 0.6], [-0.6, 0.6], [0.05, 0.9]]$/;"	kind:variable	line:18
precision	../autolab_core/autolab_core/learning_analysis.py	/^    def precision(self):$/;"	kind:member	line:375
precision	../autolab_core/autolab_core/learning_analysis.py	/^    def precision(self):$/;"	kind:member	line:93
precision_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def precision_curve(self, delta_tau=0.01):$/;"	kind:member	line:543
precision_pct_pred_pos_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def precision_pct_pred_pos_curve(self, interval=False, delta_tau=0.001):$/;"	kind:member	line:655
precision_recall_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def precision_recall_curve(self, plot=False, line_width=2, font_size=15, color='b', style='-', label='', marker=None):$/;"	kind:member	line:151
precision_recall_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def precision_recall_curve(self, plot=False, line_width=2, font_size=15, color='b', style='-', label='', marker=None):$/;"	kind:member	line:494
predict	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def predict(self, image_arr, pose_arr, verbose=False):$/;"	kind:member	line:918
predict	../perception/perception/cnn.py	/^    def predict(self, image_arr, featurize=False):$/;"	kind:member	line:154
predict_class_label.py	../perception/tools/predict_class_label.py	1;"	kind:file	line:1
predictions	../autolab_core/autolab_core/learning_analysis.py	/^    def predictions(self):$/;"	kind:member	line:113
predictions	../autolab_core/autolab_core/learning_analysis.py	/^    def predictions(self):$/;"	kind:member	line:371
preprocess_images	../perception/tools/capture_dataset.py	/^def preprocess_images(raw_color_im,$/;"	kind:function	line:31
pretty_str_time	../autolab_core/autolab_core/experiment_logger.py	/^    def pretty_str_time(dt):$/;"	kind:member	line:221
pretty_str_time	../autolab_core/autolab_core/utils.py	/^def pretty_str_time(dt):$/;"	kind:function	line:163
primesense_sensor.py	../perception/perception/primesense_sensor.py	1;"	kind:file	line:1
primesense_viewer.py	../perception/tools/primesense_viewer.py	1;"	kind:file	line:1
primitives.py	../autolab_core/autolab_core/primitives.py	1;"	kind:file	line:1
print_dataset_size.py	../autolab_core/tools/print_dataset_size.py	1;"	kind:file	line:1
print_urdf	../iai_kinect2/kinect2_calibration/scripts/convert_calib_pose_to_urdf_format.py	/^def print_urdf(xyz, rpy):$/;"	kind:function	line:34
priority_list	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def priority_list(self):$/;"	kind:member	line:1566
processFeedback	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	/^def processFeedback(feedback):$/;"	kind:function	line:44
proj_matrix	../perception/perception/camera_intrinsics.py	/^    def proj_matrix(self):$/;"	kind:member	line:124
proj_matrix	../perception/perception/orthographic_intrinsics.py	/^    def proj_matrix(self):$/;"	kind:member	line:91
project	../autolab_core/docs/source/conf.py	/^project = u'autolab_core'$/;"	kind:variable	line:57
project	../docs/source/conf.py	/^project = "panda_autograsp"$/;"	kind:variable	line:25
project	../gqcnn/docs/source/conf.py	/^project = u"GQCNN"$/;"	kind:variable	line:60
project	../gqcnn/gqcnn/grasping/actions.py	/^    def project(self, camera_intr, T_camera_world):$/;"	kind:member	line:145
project	../gqcnn/gqcnn/grasping/actions.py	/^    def project(self, camera_intr, T_camera_world):$/;"	kind:member	line:170
project	../gqcnn/gqcnn/grasping/actions.py	/^    def project(self, camera_intr, T_camera_world):$/;"	kind:member	line:95
project	../gqcnn/gqcnn/grasping/actions.py	/^    def project(self, camera_intr, T_camera_world, gripper_width=0.05):$/;"	kind:member	line:108
project	../moveit_tutorials/conf.py	/^project = u'moveit_tutorials'$/;"	kind:variable	line:14
project	../perception/docs/source/conf.py	/^project = u'perception'$/;"	kind:variable	line:57
project	../perception/perception/camera_intrinsics.py	/^    def project(self, point_cloud, round_px=True):$/;"	kind:member	line:245
project	../perception/perception/orthographic_intrinsics.py	/^    def project(self, point_cloud, round_px=True):$/;"	kind:member	line:103
project_start	../perception/tools/filter_images.py	/^    project_start = time.time()$/;"	kind:variable	line:175
project_to_image	../perception/perception/camera_intrinsics.py	/^    def project_to_image(self, point_cloud, round_px=True):$/;"	kind:member	line:286
project_to_image	../perception/perception/orthographic_intrinsics.py	/^    def project_to_image(self, point_cloud, round_px=True):$/;"	kind:member	line:144
projection_from_matrix	../autolab_core/autolab_core/transformations.py	/^def projection_from_matrix(matrix, pseudo=False):$/;"	kind:function	line:499
projection_matrix	../autolab_core/autolab_core/transformations.py	/^def projection_matrix(point, normal, direction=None,$/;"	kind:function	line:437
prompt_result	../panda_autograsp/nodes/grasp_planner_server.py	/^            prompt_result = input("Do you want to download this model now? [Y\/n] ")$/;"	kind:variable	line:122
prune_contours	../perception/perception/image.py	/^    def prune_contours(self, area_thresh=1000.0, dist_thresh=20,$/;"	kind:member	line:2294
pt_color	../perception/tools/register_camera.py	/^pt_color = (255,0,0)$/;"	kind:variable	line:31
pt_radius	../perception/tools/register_camera.py	/^pt_radius = 2$/;"	kind:variable	line:30
publish_to_ros	../autolab_core/autolab_core/rigid_transformations.py	/^    def publish_to_ros(self, mode='transform', service_name='rigid_transforms\/rigid_transform_publisher', namespace=None):$/;"	kind:member	line:523
publish_transform	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^                publish_transform = publish_transform_frame$/;"	kind:variable	line:59
publish_transform	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^                publish_transform = publish_transform_transform$/;"	kind:variable	line:61
publish_transform_frame	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    publish_transform_frame = lambda msg: publisher.publish(tf2_msgs.msg.TFMessage([msg]))$/;"	kind:variable	line:51
publish_transform_transform	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    publish_transform_transform = broadcaster.sendTransform$/;"	kind:variable	line:53
publisher	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    publisher = rospy.Publisher("\/tf", tf2_msgs.msg.TFMessage, queue_size=1)$/;"	kind:variable	line:50
publisherCallback	../franka_ros/franka_example_controllers/scripts/interactive_marker.py	/^def publisherCallback(msg, link_name):$/;"	kind:function	line:21
pygments_style	../autolab_core/docs/source/conf.py	/^pygments_style = 'sphinx'$/;"	kind:variable	line:103
pygments_style	../docs/source/conf.py	/^pygments_style = "sphinx"$/;"	kind:variable	line:112
pygments_style	../gqcnn/docs/source/conf.py	/^pygments_style = "sphinx"$/;"	kind:variable	line:106
pygments_style	../moveit_tutorials/conf.py	/^pygments_style = 'sphinx'$/;"	kind:variable	line:26
pygments_style	../perception/docs/source/conf.py	/^pygments_style = 'sphinx'$/;"	kind:variable	line:103
q_value	../gqcnn/gqcnn/grasping/actions.py	/^    def q_value(self):$/;"	kind:member	line:64
qd	../autolab_core/autolab_core/dual_quaternion.py	/^    def qd(self):$/;"	kind:member	line:74
qd	../autolab_core/autolab_core/dual_quaternion.py	/^    def qd(self, qd_wxyz):$/;"	kind:member	line:81
qr	../autolab_core/autolab_core/dual_quaternion.py	/^    def qr(self):$/;"	kind:member	line:61
qr	../autolab_core/autolab_core/dual_quaternion.py	/^    def qr(self, qr_wxyz):$/;"	kind:member	line:68
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, images, depths, params=None):$/;"	kind:member	line:1273
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params):$/;"	kind:member	line:1028
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params):$/;"	kind:member	line:1183
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:152
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:273
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:372
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:515
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:616
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:65
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:686
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:767
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:863
quality	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality(self, state, actions, params=None):$/;"	kind:member	line:89
quality_function	../gqcnn/gqcnn/grasping/grasp_quality_function.py	/^    def quality_function(metric_type, config):$/;"	kind:member	line:1281
quaternion	../autolab_core/autolab_core/rigid_transformations.py	/^    def quaternion(self):$/;"	kind:member	line:199
quaternion_about_axis	../autolab_core/autolab_core/transformations.py	/^def quaternion_about_axis(angle, axis):$/;"	kind:function	line:1157
quaternion_conjugate	../autolab_core/autolab_core/transformations.py	/^def quaternion_conjugate(quaternion):$/;"	kind:function	line:1245
quaternion_from_axis_angle	../autolab_core/autolab_core/rigid_transformations.py	/^    def quaternion_from_axis_angle(v):$/;"	kind:member	line:719
quaternion_from_euler	../autolab_core/autolab_core/transformations.py	/^def quaternion_from_euler(ai, aj, ak, axes='sxyz'):$/;"	kind:function	line:1100
quaternion_from_matrix	../autolab_core/autolab_core/transformations.py	/^def quaternion_from_matrix(matrix):$/;"	kind:function	line:1196
quaternion_inverse	../autolab_core/autolab_core/transformations.py	/^def quaternion_inverse(quaternion):$/;"	kind:function	line:1258
quaternion_matrix	../autolab_core/autolab_core/transformations.py	/^def quaternion_matrix(quaternion):$/;"	kind:function	line:1174
quaternion_multiply	../autolab_core/autolab_core/transformations.py	/^def quaternion_multiply(quaternion1, quaternion0):$/;"	kind:function	line:1228
quaternion_slerp	../autolab_core/autolab_core/transformations.py	/^def quaternion_slerp(quat0, quat1, fraction, spin=0, shortestpath=True):$/;"	kind:function	line:1270
query_im	../perception/perception/detector.py	/^    def query_im(self):$/;"	kind:member	line:62
r	../gqcnn/examples/policy_with_image_proc.py	/^    r = np.array([165, 165, 370, 370])$/;"	kind:variable	line:142
r	../perception/ros_nodes/image_buffer.py	/^        r = rospy.Rate(0.1)$/;"	kind:variable	line:103
r_data	../perception/perception/image.py	/^    def r_data(self):$/;"	kind:member	line:1062
random	../gqcnn/examples/policy_with_image_proc.py	/^                     random=True,$/;"	kind:variable	line:208
random_quaternion	../autolab_core/autolab_core/transformations.py	/^def random_quaternion(rand=None):$/;"	kind:function	line:1311
random_rotation	../autolab_core/autolab_core/rigid_transformations.py	/^    def random_rotation():$/;"	kind:member	line:903
random_rotation_matrix	../autolab_core/autolab_core/transformations.py	/^def random_rotation_matrix(rand=None):$/;"	kind:function	line:1341
random_translation	../autolab_core/autolab_core/rigid_transformations.py	/^    def random_translation():$/;"	kind:member	line:916
random_variables.py	../autolab_core/autolab_core/random_variables.py	1;"	kind:file	line:1
random_vector	../autolab_core/autolab_core/transformations.py	/^def random_vector(size):$/;"	kind:function	line:1618
rate_keeper	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    rate_keeper = rospy.Rate(10)$/;"	kind:variable	line:55
raw_color_im	../perception/tools/capture_dataset.py	/^            raw_color_im = raw_color_im.resize(im_rescale_factor)$/;"	kind:variable	line:318
raw_color_im_filename	../perception/tools/capture_dataset.py	/^                raw_color_im_filename = os.path.join(raw_dir, 'raw_color_%d.png' %(k))$/;"	kind:variable	line:369
raw_data	../perception/perception/image.py	/^    def raw_data(self):$/;"	kind:member	line:199
raw_depth_im	../perception/tools/capture_dataset.py	/^            raw_depth_im = raw_depth_im.resize(im_rescale_factor,$/;"	kind:variable	line:319
raw_depth_im_filename	../perception/tools/capture_dataset.py	/^                raw_depth_im_filename = os.path.join(raw_dir, 'raw_depth_%d.npy' %(k))$/;"	kind:variable	line:374
raw_dir	../perception/tools/capture_dataset.py	/^                raw_dir = os.path.join(sensor_dir, 'raw')$/;"	kind:variable	line:367
raw_dir	../perception/tools/capture_dataset.py	/^            raw_dir = os.path.join(sensor_dir, 'raw')$/;"	kind:variable	line:269
raw_train_errors	../gqcnn/tools/plot_training_losses.py	/^    raw_train_errors = np.load(train_errors_filename)$/;"	kind:variable	line:64
raw_train_iters	../gqcnn/tools/plot_training_losses.py	/^    raw_train_iters = np.load(train_iters_filename)$/;"	kind:variable	line:66
raw_train_losses	../gqcnn/tools/plot_training_losses.py	/^    raw_train_losses = np.load(train_losses_filename)$/;"	kind:variable	line:71
read_calib_pose	../iai_kinect2/kinect2_calibration/scripts/convert_calib_pose_to_urdf_format.py	/^def read_calib_pose(fname):$/;"	kind:function	line:11
read_images	../gqcnn/ros_nodes/grasp_planner_node.py	/^    def read_images(self, req):$/;"	kind:member	line:92
read_images	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def read_images(self, skip_registration=False):$/;"	kind:member	line:362
read_images	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner_ros.py	/^    def read_images(self, req):$/;"	kind:member	line:95
read_pose_data	../gqcnn/gqcnn/utils/utils.py	/^def read_pose_data(pose_arr, gripper_mode):$/;"	kind:function	line:107
read_start	../perception/tools/primesense_viewer.py	/^        read_start = time.time()$/;"	kind:variable	line:28
read_stop	../perception/tools/primesense_viewer.py	/^        read_stop = time.time()$/;"	kind:variable	line:30
readme	../panda_autograsp/setup.py	/^    readme = f.read()$/;"	kind:variable	line:235
realsense_sensor.py	../perception/perception/realsense_sensor.py	1;"	kind:file	line:1
recall	../autolab_core/autolab_core/learning_analysis.py	/^    def recall(self):$/;"	kind:member	line:381
recall	../autolab_core/autolab_core/learning_analysis.py	/^    def recall(self):$/;"	kind:member	line:99
recall_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def recall_curve(self, delta_tau=0.01):$/;"	kind:member	line:571
reconfigure_root	../autolab_core/autolab_core/logger.py	/^    def reconfigure_root():$/;"	kind:member	line:63
reconfigure_root	../panda_autograsp/src/panda_autograsp/loggers.py	/^    def reconfigure_root():$/;"	kind:member	line:165
recorder	../perception/tools/test_video_recorder.py	/^    recorder = VideoRecorder(sensor)$/;"	kind:variable	line:20
rectangle_bgr	../panda_autograsp/scripts/chessboard_calibration.py	/^rectangle_bgr = (255, 255, 255)$/;"	kind:variable	line:69
recursive_load	../autolab_core/autolab_core/yaml_config.py	/^        def recursive_load(matchobj, path):$/;"	kind:function	line:91
red	../autolab_core/autolab_core/points.py	/^    def red(self):$/;"	kind:member	line:1080
reduce_shape	../gqcnn/gqcnn/utils/utils.py	/^def reduce_shape(shape):$/;"	kind:function	line:153
reference_frame	../perception/perception/features.py	/^    def reference_frame(self):$/;"	kind:member	line:42
reference_frames	../perception/perception/features.py	/^    def reference_frames(self):$/;"	kind:member	line:175
reflection_from_matrix	../autolab_core/autolab_core/transformations.py	/^def reflection_from_matrix(matrix):$/;"	kind:function	line:246
reflection_matrix	../autolab_core/autolab_core/transformations.py	/^def reflection_matrix(point, normal):$/;"	kind:function	line:220
reg_cfg	../perception/tools/register_webcam.py	/^        reg_cfg = sensor_data['registration_config'].copy()$/;"	kind:variable	line:34
reg_img	../panda_autograsp/scripts/kinect_processing.py	/^        reg_img = cv2.imshow("registered", registered.asarray(np.uint8))$/;"	kind:variable	line:149
reg_result	../perception/tools/register_camera.py	/^            reg_result = CameraChessboardRegistration.register(sensor, registration_config)$/;"	kind:variable	line:74
reg_result	../perception/tools/register_object.py	/^    reg_result = CameraChessboardRegistration.register(sensor, config['chessboard_registration'])$/;"	kind:variable	line:55
register	../perception/perception/chessboard_registration.py	/^    def register(sensor, config):$/;"	kind:member	line:35
register	../perception/perception/point_registration.py	/^    def register(self, source_point_cloud, target_point_cloud,$/;"	kind:member	line:32
register	../perception/perception/point_registration.py	/^    def register(self, source_point_cloud, target_point_cloud,$/;"	kind:member	line:85
register_2d	../perception/perception/point_registration.py	/^    def register_2d(self, source_point_cloud, target_point_cloud,$/;"	kind:member	line:242
register_camera.py	../perception/tools/register_camera.py	1;"	kind:file	line:1
register_ensenso	../perception/tools/register_ensenso.py	/^def register_ensenso(config):$/;"	kind:function	line:26
register_ensenso.py	../perception/tools/register_ensenso.py	1;"	kind:file	line:1
register_object.py	../perception/tools/register_object.py	1;"	kind:file	line:1
register_webcam.py	../perception/tools/register_webcam.py	1;"	kind:file	line:1
registered	../panda_autograsp/scripts/kinect_processing.py	/^    registered = Frame(512, 424, 4)$/;"	kind:variable	line:112
registration	../panda_autograsp/scripts/kinect_processing.py	/^    registration = Registration($/;"	kind:variable	line:106
registration_config	../perception/tools/register_camera.py	/^        registration_config = sensor_data['registration_config'].copy()$/;"	kind:variable	line:59
rejectedCorners	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            rejectedCorners=rejectedImgPoints,$/;"	kind:variable	line:157
relative_site_packages	../panda_autograsp/setup.py	/^relative_site_packages = get_python_lib().split(sys.prefix + os.sep)[1]$/;"	kind:variable	line:28
release	../autolab_core/docs/source/conf.py	/^release = __version__$/;"	kind:variable	line:68
release	../docs/source/conf.py	/^release = "0.0.6"$/;"	kind:variable	line:31
release	../gqcnn/docs/source/conf.py	/^release = u"1.1.0"$/;"	kind:variable	line:71
release	../moveit_tutorials/conf.py	/^release = 'Kinetic'$/;"	kind:variable	line:23
release	../perception/docs/source/conf.py	/^release = __version__$/;"	kind:variable	line:68
remove_dirs	../autolab_core/autolab_core/experiment_logger.py	/^    def remove_dirs(self, dirs):$/;"	kind:member	line:174
remove_infinite_points	../autolab_core/autolab_core/points.py	/^    def remove_infinite_points(self):$/;"	kind:member	line:701
remove_nan_normals	../autolab_core/autolab_core/points.py	/^    def remove_nan_normals(self):$/;"	kind:member	line:939
remove_zero_normals	../autolab_core/autolab_core/points.py	/^    def remove_zero_normals(self):$/;"	kind:member	line:929
remove_zero_points	../autolab_core/autolab_core/points.py	/^    def remove_zero_points(self):$/;"	kind:member	line:1209
remove_zero_points	../autolab_core/autolab_core/points.py	/^    def remove_zero_points(self):$/;"	kind:member	line:691
replace_zeros	../perception/perception/image.py	/^    def replace_zeros(self, val, zero_thresh=0.0):$/;"	kind:member	line:875
req	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^        def req():$/;"	kind:function	line:452
req	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^        def req():$/;"	kind:function	line:485
req	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^        def req():$/;"	kind:function	line:528
required_arguments	../moveit_tutorials/_scripts/tutorialformatter.py	/^    required_arguments = 1$/;"	kind:variable	line:84
requirements	../autolab_core/setup.py	/^requirements = [$/;"	kind:variable	line:7
requirements	../gqcnn/setup.py	/^requirements = [$/;"	kind:variable	line:143
requirements	../panda_autograsp/setup.py	/^requirements = [$/;"	kind:variable	line:35
requirements	../perception/setup.py	/^requirements = [$/;"	kind:variable	line:7
requirements	../setup.py	/^    requirements = [$/;"	kind:variable	line:377
requirements	../setup.py	/^    requirements = [$/;"	kind:variable	line:47
requirements	../setup.py	/^    requirements = [$/;"	kind:variable	line:60
rescale_factor	../perception/tools/capture_test_images.py	/^        rescale_factor = config['rescale_factor']$/;"	kind:variable	line:40
rescale_factor	../perception/tools/capture_test_images.py	/^    rescale_factor = 1.0$/;"	kind:variable	line:38
rescale_factor	../perception/tools/filter_images.py	/^rescale_factor = 0.5$/;"	kind:variable	line:23
reset	../autolab_core/autolab_core/tensor_dataset.py	/^    def reset(self):$/;"	kind:member	line:117
reset	../perception/perception/camera_sensor.py	/^    def reset(self):$/;"	kind:member	line:31
reset_time	../autolab_core/autolab_core/data_stream_syncer.py	/^    def reset_time(self):$/;"	kind:member	line:143
resize	../perception/perception/camera_intrinsics.py	/^    def resize(self, scale):$/;"	kind:member	line:214
resize	../perception/perception/image.py	/^    def resize(self, size, interp):$/;"	kind:member	line:275
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:1113
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:1611
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:1993
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:2099
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:2224
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:2929
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:3181
resize	../perception/perception/image.py	/^    def resize(self, size, interp='bilinear'):$/;"	kind:member	line:3670
resize	../perception/perception/image.py	/^    def resize(self, size, interp='nearest'):$/;"	kind:member	line:3355
resize	../perception/perception/image.py	/^    def resize(self, size, interp='nearest'):$/;"	kind:member	line:3436
resize_factor	../perception/tools/register_webcam.py	/^            resize_factor = reg_cfg['color_image_rescale_factor']$/;"	kind:variable	line:49
resized_color_im	../perception/tools/register_webcam.py	/^            resized_color_im = img.resize(resize_factor)$/;"	kind:variable	line:54
resnet	../perception/tools/keras_resnet.py	/^    resnet = ResNet50(weights_filename=DEFAULT_RESNET50_WEIGHTS)$/;"	kind:variable	line:24
resource_manager.py	../gqcnn/gqcnn/search/resource_manager.py	1;"	kind:file	line:1
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                            response = yes_or_no($/;"	kind:variable	line:179
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                            response = yes_or_no($/;"	kind:variable	line:212
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                            response = yes_or_no($/;"	kind:variable	line:245
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                    response = yes_or_no("Do you want execute the plan?")$/;"	kind:variable	line:173
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                    response = yes_or_no("Do you want execute the plan?")$/;"	kind:variable	line:206
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                    response = yes_or_no("Do you want execute the plan?")$/;"	kind:variable	line:239
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        response = yes_or_no("Do you want to plan to a random joint position ?")$/;"	kind:variable	line:189
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        response = yes_or_no("Do you want to plan to a random path?")$/;"	kind:variable	line:222
response	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        response = yes_or_no("Do you want to plan to a random pose?")$/;"	kind:variable	line:156
result	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                        result = execute_plan_srv()$/;"	kind:variable	line:175
result	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                        result = execute_plan_srv()$/;"	kind:variable	line:208
result	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                        result = execute_plan_srv()$/;"	kind:variable	line:241
result	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                result = plan_to_random_joint_srv()$/;"	kind:variable	line:195
result	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                result = plan_to_random_path_srv(n_waypoints=4)$/;"	kind:variable	line:228
result	../panda_autograsp/nodes/moveit_random_planner_client.py	/^                result = plan_to_random_pose_srv()$/;"	kind:variable	line:162
result_dir	../gqcnn/tools/plot_training_losses.py	/^    result_dir = sys.argv[1]$/;"	kind:variable	line:54
resume	../autolab_core/autolab_core/data_stream_syncer.py	/^    def resume(self, reset_time=False):$/;"	kind:member	line:138
reverse_dictionary	../autolab_core/autolab_core/utils.py	/^def reverse_dictionary(d):$/;"	kind:function	line:146
rgb2bgr	../perception/perception/image.py	/^    def rgb2bgr(self):$/;"	kind:member	line:1084
rgbd_im	../gqcnn/examples/antipodal_grasp_sampling.py	/^    rgbd_im = RgbdImage.from_color_and_depth(color_im, depth_im)$/;"	kind:variable	line:84
rgbd_im	../gqcnn/examples/policy.py	/^    rgbd_im = RgbdImage.from_color_and_depth(color_im, depth_im)$/;"	kind:variable	line:226
rgbd_im	../gqcnn/examples/policy_with_image_proc.py	/^    rgbd_im = RgbdImage.from_color_and_depth(color_im, depth_im)$/;"	kind:variable	line:216
rgbd_sensors.py	../perception/perception/rgbd_sensors.py	1;"	kind:file	line:1
rigid_transform_from_ros	../autolab_core/autolab_core/rigid_transformations.py	/^    def rigid_transform_from_ros(from_frame, to_frame, service_name='rigid_transforms\/rigid_transform_listener', namespace=None):$/;"	kind:member	line:661
rigid_transform_listener.py	../autolab_core/ros_nodes/rigid_transform_listener.py	1;"	kind:file	line:1
rigid_transform_publisher.py	../autolab_core/ros_nodes/rigid_transform_publisher.py	1;"	kind:file	line:1
rigid_transformations.py	../autolab_core/autolab_core/rigid_transformations.py	1;"	kind:file	line:1
robot	../perception/tools/register_camera.py	/^                robot = UniversalRobot()$/;"	kind:variable	line:277
robot	../perception/tools/register_camera.py	/^                robot = y.right$/;"	kind:variable	line:282
robot_description	../panda_autograsp/nodes/moveit_planner_server.py	/^        robot_description="robot_description",$/;"	kind:variable	line:64
robot_points_camera	../perception/tools/register_camera.py	/^            robot_points_camera = []$/;"	kind:variable	line:126
robot_poses	../perception/tools/register_camera.py	/^            robot_poses = []$/;"	kind:variable	line:102
robot_type	../perception/tools/register_camera.py	/^                robot_type = config['robot_type']$/;"	kind:variable	line:265
robot_type	../perception/tools/register_camera.py	/^            robot_type = 'yumi'$/;"	kind:variable	line:263
roc_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def roc_curve(self, plot=False, line_width=2, font_size=15, color='b', style='-', label=''):$/;"	kind:member	line:163
roc_curve	../autolab_core/autolab_core/learning_analysis.py	/^    def roc_curve(self, plot=False, line_width=2, font_size=15, color='b', style='-', label=''):$/;"	kind:member	line:505
root_logger	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    root_logger = Logger.get_logger($/;"	kind:variable	line:88
root_logger	../panda_autograsp/scripts/chessboard_calibration.py	/^    root_logger = Logger.get_logger($/;"	kind:variable	line:77
root_logger	../panda_autograsp/scripts/generate_arucoboard.py	/^    root_logger = Logger.get_logger($/;"	kind:variable	line:54
root_logger	../panda_autograsp/scripts/kinect_processing.py	/^    root_logger = Logger.get_logger($/;"	kind:variable	line:64
root_logger	../panda_autograsp/scripts/plan_grasp.py	/^    root_logger = Logger.get_logger($/;"	kind:variable	line:50
ros_distro	../moveit_tutorials/conf.py	/^ros_distro = 'melodic'$/;"	kind:variable	line:52
ros_q_to_core_q	../autolab_core/autolab_core/rigid_transformations.py	/^    def ros_q_to_core_q(q_ros):$/;"	kind:member	line:603
rosmsg	../perception/perception/camera_intrinsics.py	/^    def rosmsg(self):$/;"	kind:member	line:142
rosmsg	../perception/perception/image.py	/^    def rosmsg(self):$/;"	kind:member	line:241
rotation	../autolab_core/autolab_core/rigid_transformations.py	/^    def rotation(self):$/;"	kind:member	line:114
rotation	../autolab_core/autolab_core/rigid_transformations.py	/^    def rotation(self, rotation):$/;"	kind:member	line:120
rotation_and_translation_from_matrix	../autolab_core/autolab_core/rigid_transformations.py	/^    def rotation_and_translation_from_matrix(matrix):$/;"	kind:member	line:786
rotation_from_axes	../autolab_core/autolab_core/rigid_transformations.py	/^    def rotation_from_axes(x_axis, y_axis, z_axis):$/;"	kind:member	line:927
rotation_from_axis_and_origin	../autolab_core/autolab_core/rigid_transformations.py	/^    def rotation_from_axis_and_origin(axis, origin, angle, to_frame='world'):$/;"	kind:member	line:812
rotation_from_axis_angle	../autolab_core/autolab_core/rigid_transformations.py	/^    def rotation_from_axis_angle(v):$/;"	kind:member	line:744
rotation_from_matrix	../autolab_core/autolab_core/transformations.py	/^def rotation_from_matrix(matrix):$/;"	kind:function	line:319
rotation_from_quaternion	../autolab_core/autolab_core/rigid_transformations.py	/^    def rotation_from_quaternion(q_wxyz):$/;"	kind:member	line:700
rotation_matrix	../autolab_core/autolab_core/transformations.py	/^def rotation_matrix(angle, direction, point=None):$/;"	kind:function	line:275
run	../autolab_core/autolab_core/data_stream_recorder.py	/^    def run(self):$/;"	kind:member	line:84
run	../autolab_core/autolab_core/data_stream_syncer.py	/^    def run(self):$/;"	kind:member	line:28
run	../gqcnn/setup.py	/^    def run(self):$/;"	kind:member	line:123
run	../gqcnn/setup.py	/^    def run(self):$/;"	kind:member	line:88
run	../moveit_tutorials/_scripts/tutorialformatter.py	/^    def run(self):$/;"	kind:member	line:126
run	../panda_autograsp/setup.py	/^    def run(self):$/;"	kind:member	line:153
run	../panda_autograsp/setup.py	/^    def run(self):$/;"	kind:member	line:196
run	../setup.py	/^    def run(self):$/;"	kind:member	line:282
run	../setup.py	/^    def run(self):$/;"	kind:member	line:325
run_policy.py	../gqcnn/tools/run_policy.py	1;"	kind:file	line:1
rvecs	../panda_autograsp/scripts/chessboard_calibration.py	/^                    rvecs=rvecs,$/;"	kind:variable	line:531
rvs	../autolab_core/autolab_core/random_variables.py	/^    def rvs(self, size=1, iteration=1):$/;"	kind:member	line:54
s	../autolab_core/ros_nodes/rigid_transform_listener.py	/^    s = rospy.Service('rigid_transform_listener', RigidTransformListener, handle_request)$/;"	kind:variable	line:33
s	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    s = rospy.Service('rigid_transform_publisher', RigidTransformPublisher, handle_request)$/;"	kind:variable	line:48
s	../panda_autograsp/scripts/chessboard_calibration.py	/^        s = color_mtx[1, 0]  # skew$/;"	kind:variable	line:371
s	../perception/ros_nodes/image_buffer.py	/^    s = rospy.Service('stream_image_buffer', ImageBuffer, handle_request)$/;"	kind:variable	line:100
sample	../autolab_core/autolab_core/random_variables.py	/^    def sample(self, size=1):$/;"	kind:member	line:137
sample	../autolab_core/autolab_core/random_variables.py	/^    def sample(self, size=1):$/;"	kind:member	line:172
sample	../autolab_core/autolab_core/random_variables.py	/^    def sample(self, size=1):$/;"	kind:member	line:258
sample	../autolab_core/autolab_core/random_variables.py	/^    def sample(self, size=1):$/;"	kind:member	line:38
sample	../autolab_core/autolab_core/random_variables.py	/^    def sample(self, size=1):$/;"	kind:member	line:98
sample	../autolab_core/autolab_core/random_variables.py	/^    def sample(self, size=None):$/;"	kind:member	line:190
sample	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def sample(self,$/;"	kind:member	line:94
sample_config	../gqcnn/examples/antipodal_grasp_sampling.py	/^    sample_config = config["sampling"]$/;"	kind:variable	line:68
sample_size	../perception/tools/register_camera.py	/^            sample_size = int(num_poses * 0.3)$/;"	kind:variable	line:181
sampler	../gqcnn/gqcnn/grasping/image_grasp_sampler.py	/^    def sampler(sampler_type, config):$/;"	kind:member	line:1068
satisfies_constraints	../gqcnn/gqcnn/grasping/constraint_fn.py	/^    def satisfies_constraints(self, grasp):$/;"	kind:member	line:64
satisfies_constraints	../gqcnn/gqcnn/grasping/constraint_fn.py	/^    def satisfies_constraints(self, grasp):$/;"	kind:member	line:93
save	../autolab_core/autolab_core/learning_analysis.py	/^    def save(self, filename):$/;"	kind:member	line:213
save	../autolab_core/autolab_core/learning_analysis.py	/^    def save(self, filename):$/;"	kind:member	line:329
save	../autolab_core/autolab_core/points.py	/^    def save(self, filename):$/;"	kind:member	line:112
save	../autolab_core/autolab_core/rigid_transformations.py	/^    def save(self, filename):$/;"	kind:member	line:1239
save	../autolab_core/autolab_core/rigid_transformations.py	/^    def save(self, filename):$/;"	kind:member	line:470
save	../autolab_core/autolab_core/tensor_dataset.py	/^    def save(self, filename, compressed=True):$/;"	kind:member	line:159
save	../autolab_core/autolab_core/yaml_config.py	/^    def save(self, filename):$/;"	kind:member	line:71
save	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def save(self, save_dir):$/;"	kind:member	line:178
save	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def save(self, save_dir):$/;"	kind:member	line:92
save	../perception/perception/camera_intrinsics.py	/^    def save(self, filename):$/;"	kind:member	line:426
save	../perception/perception/image.py	/^    def save(self, filename):$/;"	kind:member	line:887
save	../perception/perception/image.py	/^    def save(self, filename, normalize=False, min_depth=MIN_DEPTH, max_depth=MAX_DEPTH, twobyte=False):$/;"	kind:member	line:1581
save	../perception/perception/orthographic_intrinsics.py	/^    def save(self, filename):$/;"	kind:member	line:285
save_data	../autolab_core/autolab_core/data_stream_recorder.py	/^    def save_data(self, path, cb=_NULL, concat=True):$/;"	kind:member	line:204
save_datetime	../gqcnn/tools/finetune.py	/^    save_datetime = args.save_datetime$/;"	kind:variable	line:109
save_datetime	../gqcnn/tools/train.py	/^    save_datetime = args.save_datetime$/;"	kind:variable	line:98
save_dir	../perception/tools/capture_test_images.py	/^        save_dir = os.path.join(output_dir, sensor_name)$/;"	kind:variable	line:55
save_raw	../perception/tools/capture_dataset.py	/^    save_raw = config['save_raw']$/;"	kind:variable	line:185
savefig	../perception/perception/image.py	/^    def savefig(self, output_path, title, dpi=400, format='png', cmap=None):$/;"	kind:member	line:921
scale	../autolab_core/autolab_core/rigid_transformations.py	/^    def scale(self):$/;"	kind:member	line:1121
scale	../autolab_core/autolab_core/rigid_transformations.py	/^    def scale(self, scale):$/;"	kind:member	line:1126
scale	../gqcnn/examples/policy_with_image_proc.py	/^                     scale=0.001)$/;"	kind:variable	line:210
scale	../gqcnn/tools/run_policy.py	/^                    scale=policy_config["vis"]["grasp_scale"],$/;"	kind:variable	line:142
scale	../gqcnn/tools/run_policy.py	/^                    scale=policy_config["vis"]["grasp_scale"],$/;"	kind:variable	line:153
scale	../perception/tools/filter_images.py	/^                         scale=0.001,$/;"	kind:variable	line:155
scale	../perception/tools/filter_images.py	/^                     scale=0.001,$/;"	kind:variable	line:169
scale	../perception/tools/filter_images.py	/^                     scale=0.001,$/;"	kind:variable	line:93
scale	../perception/tools/filter_images.py	/^                     scale=0.001,$/;"	kind:variable	line:97
scale_from_matrix	../autolab_core/autolab_core/transformations.py	/^def scale_from_matrix(matrix):$/;"	kind:function	line:396
scale_matrix	../autolab_core/autolab_core/transformations.py	/^def scale_matrix(factor, origin=None, direction=None):$/;"	kind:function	line:359
scene	../perception/tools/capture_dataset.py	/^        scene = Scene()$/;"	kind:variable	line:242
scene_obj	../perception/tools/capture_dataset.py	/^        scene_obj = SceneObject(obj_mesh, obj_pose, obj_mat_props)$/;"	kind:variable	line:212
screen_img	../panda_autograsp/scripts/aruco_pose_estimation.py	/^            screen_img = aruco.drawDetectedMarkers(screen_img, corners, ids)$/;"	kind:variable	line:166
screen_img	../panda_autograsp/scripts/aruco_pose_estimation.py	/^        screen_img = cv2.cvtColor(copy.copy(color_im.data), cv2.COLOR_RGB2BGR)$/;"	kind:variable	line:139
screen_img	../panda_autograsp/scripts/chessboard_calibration.py	/^                    screen_img = cv2.cvtColor($/;"	kind:variable	line:181
screen_img	../panda_autograsp/scripts/chessboard_calibration.py	/^                    screen_img = cv2.cvtColor($/;"	kind:variable	line:255
screen_img	../panda_autograsp/scripts/chessboard_calibration.py	/^            screen_img = draw_axis(screen_img, corners2, imgpts)$/;"	kind:variable	line:516
screen_img	../panda_autograsp/scripts/chessboard_calibration.py	/^        screen_img = cv2.cvtColor(copy.copy(color_im.data), cv2.COLOR_RGB2BGR)$/;"	kind:variable	line:459
script_logger	../panda_autograsp/scripts/aruco_pose_estimation.py	/^script_logger = Logger.get_logger("aruco_pose_estimation.py")$/;"	kind:variable	line:33
script_logger	../panda_autograsp/scripts/chessboard_calibration.py	/^script_logger = Logger.get_logger("chessboard_calibration.py")$/;"	kind:variable	line:34
script_logger	../panda_autograsp/scripts/generate_arucoboard.py	/^script_logger = Logger.get_logger("generate_arucoboard.py")$/;"	kind:variable	line:34
script_logger	../panda_autograsp/scripts/kinect_processing.py	/^script_logger = Logger.get_logger("kinect_processing.py")$/;"	kind:variable	line:33
script_logger	../panda_autograsp/scripts/plan_grasp.py	/^script_logger = Logger.get_logger("plan_grasp.py")$/;"	kind:variable	line:27
search	../gqcnn/gqcnn/search/search.py	/^    def search(self):$/;"	kind:member	line:142
search	../gqcnn/tools/hyperparam_search.py	/^    search = GQCNNSearch(analysis_config,$/;"	kind:variable	line:120
search.py	../gqcnn/gqcnn/search/search.py	1;"	kind:file	line:1
search_name	../gqcnn/tools/hyperparam_search.py	/^                         search_name=search_name,$/;"	kind:variable	line:125
search_name	../gqcnn/tools/hyperparam_search.py	/^    search_name = args.search_name$/;"	kind:variable	line:90
seed	../gqcnn/examples/antipodal_grasp_sampling.py	/^                                  seed=100,$/;"	kind:variable	line:93
seed	../gqcnn/tools/finetune.py	/^    seed = args.seed$/;"	kind:variable	line:105
seed	../gqcnn/tools/run_policy.py	/^    seed = args.seed$/;"	kind:variable	line:72
seed	../gqcnn/tools/train.py	/^    seed = args.seed$/;"	kind:variable	line:95
seg_point_cloud	../perception/tools/filter_images.py	/^        seg_point_cloud = PointCloud(points, frame='world')$/;"	kind:variable	line:140
seg_point_cloud_cam	../perception/tools/capture_test_images.py	/^                seg_point_cloud_cam = T_camera_world.inverse() * seg_point_cloud_world$/;"	kind:variable	line:96
segmask	../gqcnn/examples/antipodal_grasp_sampling.py	/^                                  segmask=None,$/;"	kind:variable	line:92
segmask	../gqcnn/examples/policy.py	/^        segmask = BinaryImage.open(segmask_filename)$/;"	kind:variable	line:202
segmask	../gqcnn/examples/policy.py	/^        segmask = segmask.mask_binary(valid_px_mask)$/;"	kind:variable	line:207
segmask	../gqcnn/examples/policy.py	/^        segmask = valid_px_mask$/;"	kind:variable	line:205
segmask	../gqcnn/examples/policy.py	/^    segmask = None$/;"	kind:variable	line:200
segmask	../gqcnn/examples/policy_ros.py	/^        segmask = BinaryImage.open(segmask_filename, frame=camera_intr.frame)$/;"	kind:variable	line:128
segmask	../gqcnn/examples/policy_with_image_proc.py	/^        segmask = BinaryImage.open(segmask_filename)$/;"	kind:variable	line:147
segmask	../gqcnn/examples/policy_with_image_proc.py	/^        segmask = segmask.mask_binary(valid_px_mask)$/;"	kind:variable	line:152
segmask	../gqcnn/examples/policy_with_image_proc.py	/^        segmask = valid_px_mask$/;"	kind:variable	line:150
segmask	../gqcnn/examples/policy_with_image_proc.py	/^    segmask = BinaryImage(mask)$/;"	kind:variable	line:145
segmask	../perception/tools/capture_test_images.py	/^                    segmask = segmask.resize(rescale_factor, interp='nearest')$/;"	kind:variable	line:102
segmask	../perception/tools/capture_test_images.py	/^                segmask = depth_im_seg.to_binary()$/;"	kind:variable	line:98
segmask_filename	../gqcnn/examples/policy.py	/^        segmask_filename = os.path.join($/;"	kind:variable	line:116
segmask_filename	../gqcnn/examples/policy.py	/^    segmask_filename = args.segmask$/;"	kind:variable	line:96
segmask_filename	../gqcnn/examples/policy_ros.py	/^    segmask_filename = args.segmask$/;"	kind:variable	line:88
segmask_filename	../gqcnn/examples/policy_with_image_proc.py	/^    segmask_filename = args.segmask$/;"	kind:variable	line:90
segmask_filename	../perception/tools/capture_dataset.py	/^                segmask_filename = os.path.join(raw_dir, 'segmask_%d.png' %(k))$/;"	kind:variable	line:379
segment	../gqcnn/examples/policy_with_image_proc.py	/^        segment = PointCloud(points, frame=camera_intr.frame)$/;"	kind:variable	line:182
segment_kmeans	../perception/perception/image.py	/^    def segment_kmeans(self, rgb_weight, num_clusters, hue_weight=0.0):$/;"	kind:member	line:1361
segment_mask	../perception/perception/image.py	/^    def segment_mask(self, segnum):$/;"	kind:member	line:3317
segments	../perception/tools/filter_images.py	/^    segments = []$/;"	kind:variable	line:125
select	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def select(self, grasps, q_value):$/;"	kind:member	line:547
select	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def select(self, grasps, q_values):$/;"	kind:member	line:776
sensor	../gqcnn/examples/antipodal_grasp_sampling.py	/^    sensor = RgbdSensorFactory.sensor(sensor_type, config["sensor"])$/;"	kind:variable	line:76
sensor	../panda_autograsp/scripts/aruco_pose_estimation.py	/^    sensor = Kinect2Sensor()$/;"	kind:variable	line:114
sensor	../panda_autograsp/scripts/chessboard_calibration.py	/^    sensor = Kinect2Sensor()$/;"	kind:variable	line:102
sensor	../perception/perception/kinect2_sensor.py	/^    def sensor(sensor_type, cfg):$/;"	kind:member	line:767
sensor	../perception/perception/rgbd_sensors.py	/^    def sensor(sensor_type, cfg):$/;"	kind:member	line:11
sensor	../perception/tools/capture_dataset.py	/^        sensor = RgbdSensorFactory.sensor(sensor_type, sensor_config)$/;"	kind:variable	line:232
sensor	../perception/tools/capture_test_images.py	/^        sensor = RgbdSensorFactory.sensor(sensor_type, sensor_config)$/;"	kind:variable	line:69
sensor	../perception/tools/filter_images.py	/^    sensor = VirtualSensor(image_dir)$/;"	kind:variable	line:43
sensor	../perception/tools/primesense_viewer.py	/^    sensor = PrimesenseSensor()$/;"	kind:variable	line:18
sensor	../perception/tools/register_camera.py	/^            sensor = RgbdSensorFactory.sensor(sensor_type, sensor_config)$/;"	kind:variable	line:67
sensor	../perception/tools/register_object.py	/^    sensor = RgbdSensorFactory.sensor(sensor_type, sensor_config)$/;"	kind:variable	line:48
sensor	../perception/tools/register_webcam.py	/^            sensor = RgbdSensorFactory.sensor(sensor_type, sensor_config)$/;"	kind:variable	line:42
sensor	../perception/tools/test_video_recorder.py	/^    sensor = WebcamSensor(device_id=0)$/;"	kind:variable	line:18
sensor_config	../perception/tools/register_camera.py	/^        sensor_config = sensor_data['sensor_config']$/;"	kind:variable	line:58
sensor_config	../perception/tools/register_object.py	/^    sensor_config = config['sensor']$/;"	kind:variable	line:33
sensor_config	../perception/tools/register_webcam.py	/^        sensor_config = sensor_data['sensor_config']$/;"	kind:variable	line:33
sensor_configs	../perception/tools/capture_dataset.py	/^    sensor_configs = config['sensors']$/;"	kind:variable	line:158
sensor_dataset_filename	../perception/tools/capture_dataset.py	/^        sensor_dataset_filename = os.path.join(output_dir, sensor_name)$/;"	kind:variable	line:262
sensor_dir	../perception/tools/capture_dataset.py	/^                sensor_dir = os.path.join(output_dir, sensor_name)$/;"	kind:variable	line:366
sensor_dir	../perception/tools/capture_dataset.py	/^            sensor_dir = os.path.join(output_dir, sensor_name)$/;"	kind:variable	line:268
sensor_frame	../gqcnn/examples/antipodal_grasp_sampling.py	/^    sensor_frame = config["sensor"]["frame"]$/;"	kind:variable	line:63
sensor_frame	../perception/tools/capture_dataset.py	/^        sensor_frame = sensor_config['frame']$/;"	kind:variable	line:224
sensor_frame	../perception/tools/capture_test_images.py	/^        sensor_frame = sensor_config['frame']$/;"	kind:variable	line:61
sensor_frame	../perception/tools/register_object.py	/^    sensor_frame = config['sensor']['frame_name']$/;"	kind:variable	line:31
sensor_frame_group	../panda_autograsp/cfg/CalibFrames.cfg	/^sensor_frame_group = gen.add_group("sensor_frame", type="tab")$/;"	kind:variable	line:23
sensor_pose	../perception/tools/capture_dataset.py	/^            sensor_pose = sensor_poses[sensor_name]$/;"	kind:variable	line:307
sensor_poses	../perception/tools/capture_dataset.py	/^    sensor_poses = {}$/;"	kind:variable	line:218
sensor_type	../gqcnn/examples/antipodal_grasp_sampling.py	/^    sensor_type = config["sensor"]["type"]$/;"	kind:variable	line:62
sensor_type	../perception/tools/capture_dataset.py	/^        sensor_type = sensor_config['type']$/;"	kind:variable	line:223
sensor_type	../perception/tools/capture_test_images.py	/^        sensor_type = sensor_config['type']$/;"	kind:variable	line:60
sensor_type	../perception/tools/register_camera.py	/^            sensor_type = sensor_config['type']$/;"	kind:variable	line:64
sensor_type	../perception/tools/register_object.py	/^    sensor_type = config['sensor']['type']$/;"	kind:variable	line:32
sensor_type	../perception/tools/register_object.py	/^    sensor_type = sensor_config['type']$/;"	kind:variable	line:46
sensor_type	../perception/tools/register_webcam.py	/^            sensor_type = sensor_config['type']$/;"	kind:variable	line:39
sensors	../perception/tools/capture_dataset.py	/^    sensors = {}$/;"	kind:variable	line:217
serial	../panda_autograsp/scripts/kinect_processing.py	/^    serial = fn.getDeviceSerialNumber(0)$/;"	kind:variable	line:94
sess	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def sess(self):$/;"	kind:member	line:640
setUpClass	../autolab_core/tests/test_dataset.py	/^    def setUpClass(cls):$/;"	kind:member	line:79
set_base_network	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_base_network(self, model_dir):$/;"	kind:member	line:283
set_batch_size	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_batch_size(self, batch_size):$/;"	kind:member	line:686
set_constraint_fn	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def set_constraint_fn(self, constraint_fn):$/;"	kind:member	line:1549
set_constraint_fn	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def set_constraint_fn(self, constraint_fn):$/;"	kind:member	line:367
set_cuda_visible_devices	../gqcnn/gqcnn/utils/utils.py	/^def set_cuda_visible_devices(gpu_list):$/;"	kind:function	line:52
set_datapoint	../autolab_core/autolab_core/tensor_dataset.py	/^    def set_datapoint(self, ind, datapoint):$/;"	kind:member	line:147
set_gripper_closed_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def set_gripper_closed_service(self, req):$/;"	kind:member	line:821
set_gripper_open_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def set_gripper_open_service(self, req):$/;"	kind:member	line:782
set_gripper_width_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def set_gripper_width_service(self, req):$/;"	kind:member	line:860
set_im_depth_sub_mean	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_im_depth_sub_mean(self, im_depth_sub_mean):$/;"	kind:member	line:781
set_im_depth_sub_std	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_im_depth_sub_std(self, im_depth_sub_std):$/;"	kind:member	line:792
set_im_mean	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_im_mean(self, im_mean):$/;"	kind:member	line:696
set_im_std	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_im_std(self, im_std):$/;"	kind:member	line:716
set_nested_key	../gqcnn/gqcnn/search/utils.py	/^def set_nested_key(cfg, key, val):$/;"	kind:function	line:79
set_pose_mean	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_pose_mean(self, pose_mean):$/;"	kind:member	line:738
set_pose_std	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def set_pose_std(self, pose_std):$/;"	kind:member	line:759
set_sensor_pose_service	../panda_autograsp/src/panda_autograsp/tf2_broadcaster_ros.py	/^    def set_sensor_pose_service(self, sensor_pose):$/;"	kind:member	line:144
set_words	../autolab_core/autolab_core/completer.py	/^    def set_words(self, words):$/;"	kind:member	line:81
setaxes	../autolab_core/autolab_core/transformations.py	/^    def setaxes(self, *axes):$/;"	kind:member	line:1420
setconstrain	../autolab_core/autolab_core/transformations.py	/^    def setconstrain(self, constrain):$/;"	kind:member	line:1427
setup	../moveit_tutorials/_scripts/tutorialformatter.py	/^def setup(app):$/;"	kind:function	line:199
setup.py	../autolab_core/setup.py	1;"	kind:file	line:1
setup.py	../gqcnn/setup.py	1;"	kind:file	line:1
setup.py	../panda_autograsp/setup.py	1;"	kind:file	line:1
setup.py	../perception/setup.py	1;"	kind:file	line:1
setup.py	../setup.py	1;"	kind:file	line:1
shape	../autolab_core/autolab_core/points.py	/^    def shape(self):$/;"	kind:member	line:67
shape	../autolab_core/autolab_core/tensor_dataset.py	/^    def shape(self):$/;"	kind:member	line:63
shape	../perception/perception/image.py	/^    def shape(self):$/;"	kind:member	line:161
shear_from_matrix	../autolab_core/autolab_core/transformations.py	/^def shear_from_matrix(matrix):$/;"	kind:function	line:655
shear_matrix	../autolab_core/autolab_core/transformations.py	/^def shear_matrix(angle, direction, point, normal):$/;"	kind:function	line:624
show	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def show(self, filename=None, dpi=100):$/;"	kind:member	line:419
show_axis	../gqcnn/tools/run_policy.py	/^                    show_axis=True,$/;"	kind:variable	line:144
show_axis	../gqcnn/tools/run_policy.py	/^                    show_axis=True,$/;"	kind:variable	line:155
show_center	../gqcnn/tools/run_policy.py	/^                    show_center=False,$/;"	kind:variable	line:143
show_center	../gqcnn/tools/run_policy.py	/^                    show_center=False,$/;"	kind:variable	line:154
show_framerate	../perception/ros_nodes/image_buffer.py	/^    show_framerate = rospy.get_param('~show_framerate', True)$/;"	kind:variable	line:39
shuffle_tensor_dataset.py	../autolab_core/tools/shuffle_tensor_dataset.py	1;"	kind:file	line:1
shutdown_msg	../panda_autograsp/nodes/grasp_planner_server.py	/^                    shutdown_msg = ($/;"	kind:variable	line:128
shutdown_msg	../panda_autograsp/nodes/grasp_planner_server.py	/^                    shutdown_msg = ($/;"	kind:variable	line:146
shutdown_msg	../panda_autograsp/nodes/grasp_planner_server.py	/^                shutdown_msg = ($/;"	kind:variable	line:137
shutdown_msg	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        shutdown_msg = "Shutting down %s node because %s service connection failed." % ($/;"	kind:variable	line:111
shutdown_msg	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        shutdown_msg = "Shutting down %s node because %s service connection failed." % ($/;"	kind:variable	line:128
shutdown_msg	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        shutdown_msg = "Shutting down %s node because %s service connection failed." % ($/;"	kind:variable	line:58
shutdown_msg	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        shutdown_msg = "Shutting down %s node because %s service connection failed." % ($/;"	kind:variable	line:76
shutdown_msg	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        shutdown_msg = "Shutting down %s node because %s service connection failed." % ($/;"	kind:variable	line:94
size	../autolab_core/autolab_core/tensor_dataset.py	/^    def size(self):$/;"	kind:member	line:59
size	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def size(self):$/;"	kind:member	line:89
size	../panda_autograsp/src/panda_autograsp/moveit_collision_objects.py	/^    def size(self, value):$/;"	kind:member	line:94
skew	../autolab_core/autolab_core/utils.py	/^def skew(xi):$/;"	kind:function	line:104
skew	../perception/perception/camera_intrinsics.py	/^    def skew(self):$/;"	kind:member	line:106
small_camera_intr	../perception/tools/filter_images.py	/^    small_camera_intr = camera_intr.resize(rescale_factor)$/;"	kind:variable	line:61
small_depth_im	../perception/tools/filter_images.py	/^    small_depth_im = depth_im.resize(rescale_factor, interp='nearest')$/;"	kind:variable	line:60
solution	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^        solution = [$/;"	kind:variable	line:115
sort_keys	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^              sort_keys=True)$/;"	kind:variable	line:67
sort_keys	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^              sort_keys=True)$/;"	kind:variable	line:73
sorted_values	../autolab_core/autolab_core/learning_analysis.py	/^    def sorted_values(self):$/;"	kind:member	line:458
source_normals	../perception/perception/feature_matcher.py	/^    def source_normals(self):$/;"	kind:member	line:84
source_points	../perception/perception/feature_matcher.py	/^    def source_points(self):$/;"	kind:member	line:39
source_suffix	../autolab_core/docs/source/conf.py	/^source_suffix = '.rst'$/;"	kind:variable	line:48
source_suffix	../docs/source/conf.py	/^source_suffix = ".rst"$/;"	kind:variable	line:73
source_suffix	../gqcnn/docs/source/conf.py	/^source_suffix = ".rst"$/;"	kind:variable	line:51
source_suffix	../moveit_tutorials/conf.py	/^source_suffix = '.rst'$/;"	kind:variable	line:12
source_suffix	../perception/docs/source/conf.py	/^source_suffix = '.rst'$/;"	kind:variable	line:48
spearman_correlation	../autolab_core/autolab_core/learning_analysis.py	/^    def spearman_correlation(self):$/;"	kind:member	line:202
spearman_pvalue	../autolab_core/autolab_core/learning_analysis.py	/^    def spearman_pvalue(self):$/;"	kind:member	line:208
sph2cart	../autolab_core/autolab_core/utils.py	/^def sph2cart(r, az, elev):$/;"	kind:function	line:205
sph_coords_to_pose	../autolab_core/autolab_core/rigid_transformations.py	/^    def sph_coords_to_pose(theta, psi):$/;"	kind:member	line:951
split	../autolab_core/autolab_core/tensor_dataset.py	/^    def split(self, split_name):$/;"	kind:member	line:736
split	../perception/tools/capture_dataset.py	/^            split = TRAIN_ID$/;"	kind:variable	line:287
split	../perception/tools/capture_dataset.py	/^        split = TEST_ID$/;"	kind:variable	line:284
split_dataset.py	../autolab_core/tools/split_dataset.py	1;"	kind:file	line:1
split_dir	../autolab_core/autolab_core/tensor_dataset.py	/^    def split_dir(self):$/;"	kind:member	line:404
split_metadata_filename	../autolab_core/autolab_core/tensor_dataset.py	/^    def split_metadata_filename(self, split_name):$/;"	kind:member	line:443
split_name	../autolab_core/tools/split_dataset.py	/^    split_name = args.split_name$/;"	kind:variable	line:54
split_name	../gqcnn/tools/finetune.py	/^    split_name = args.split_name$/;"	kind:variable	line:102
split_name	../gqcnn/tools/train.py	/^    split_name = args.split_name$/;"	kind:variable	line:92
split_names	../autolab_core/autolab_core/tensor_dataset.py	/^    def split_names(self):$/;"	kind:member	line:409
split_names	../gqcnn/tools/hyperparam_search.py	/^    split_names = args.split_names$/;"	kind:variable	line:88
split_points	../autolab_core/autolab_core/points.py	/^    def split_points(self, point_cloud):$/;"	kind:member	line:502
sqrt_ceil	../autolab_core/autolab_core/utils.py	/^def sqrt_ceil(n):$/;"	kind:function	line:303
start	../autolab_core/autolab_core/data_stream_syncer.py	/^    def start(self):$/;"	kind:member	line:118
start	../panda_autograsp/nodes/panda_autograsp_cli.py	/^    def start(self):$/;"	kind:member	line:332
start	../panda_autograsp/src/panda_autograsp/grasp_planners/gqcnn_grasp_planner.py	/^    def start(self):$/;"	kind:member	line:337
start	../perception/perception/camera_sensor.py	/^    def start(self):$/;"	kind:member	line:167
start	../perception/perception/camera_sensor.py	/^    def start(self):$/;"	kind:member	line:20
start	../perception/perception/colorized_phoxi_sensor.py	/^    def start(self):$/;"	kind:member	line:81
start	../perception/perception/ensenso_sensor.py	/^    def start(self):$/;"	kind:member	line:113
start	../perception/perception/kinect2_sensor.py	/^    def start(self):$/;"	kind:member	line:171
start	../perception/perception/kinect2_sensor.py	/^    def start(self):$/;"	kind:member	line:480
start	../perception/perception/kinect2_sensor.py	/^    def start(self):$/;"	kind:member	line:681
start	../perception/perception/opencv_camera_sensor.py	/^    def start(self):$/;"	kind:member	line:18
start	../perception/perception/phoxi_sensor.py	/^    def start(self):$/;"	kind:member	line:108
start	../perception/perception/primesense_sensor.py	/^    def start(self):$/;"	kind:member	line:108
start	../perception/perception/primesense_sensor.py	/^    def start(self):$/;"	kind:member	line:303
start	../perception/perception/realsense_sensor.py	/^    def start(self):$/;"	kind:member	line:156
start	../perception/perception/video_recorder.py	/^    def start(self):$/;"	kind:member	line:38
start	../perception/perception/webcam_sensor.py	/^    def start(self):$/;"	kind:member	line:69
start	../perception/perception/weight_sensor.py	/^    def start(self):$/;"	kind:member	line:35
start_recording	../perception/perception/video_recorder.py	/^    def start_recording(self, output_file, overwrite=True):$/;"	kind:member	line:41
start_time	../gqcnn/tools/finetune.py	/^    start_time = time.time()$/;"	kind:variable	line:165
start_time	../gqcnn/tools/train.py	/^    start_time = time.time()$/;"	kind:variable	line:144
state	../gqcnn/examples/policy.py	/^    state = RgbdImageState(rgbd_im, camera_intr, segmask=segmask)$/;"	kind:variable	line:227
state	../gqcnn/examples/policy_with_image_proc.py	/^    state = RgbdImageState(rgbd_im, camera_intr, segmask=segmask)$/;"	kind:variable	line:217
state	../gqcnn/tools/run_policy.py	/^    state = RgbdImageState.load(state_path)$/;"	kind:variable	line:95
state_path	../gqcnn/tools/run_policy.py	/^    state_path = os.path.join(test_case_path, "state")$/;"	kind:variable	line:93
stop	../autolab_core/autolab_core/data_stream_syncer.py	/^    def stop(self):$/;"	kind:member	line:123
stop	../perception/perception/camera_sensor.py	/^    def stop(self):$/;"	kind:member	line:176
stop	../perception/perception/camera_sensor.py	/^    def stop(self):$/;"	kind:member	line:26
stop	../perception/perception/colorized_phoxi_sensor.py	/^    def stop(self):$/;"	kind:member	line:93
stop	../perception/perception/ensenso_sensor.py	/^    def stop(self):$/;"	kind:member	line:124
stop	../perception/perception/kinect2_sensor.py	/^    def stop(self):$/;"	kind:member	line:246
stop	../perception/perception/kinect2_sensor.py	/^    def stop(self):$/;"	kind:member	line:503
stop	../perception/perception/kinect2_sensor.py	/^    def stop(self):$/;"	kind:member	line:690
stop	../perception/perception/opencv_camera_sensor.py	/^    def stop(self):$/;"	kind:member	line:32
stop	../perception/perception/phoxi_sensor.py	/^    def stop(self):$/;"	kind:member	line:128
stop	../perception/perception/primesense_sensor.py	/^    def stop(self):$/;"	kind:member	line:142
stop	../perception/perception/primesense_sensor.py	/^    def stop(self):$/;"	kind:member	line:307
stop	../perception/perception/realsense_sensor.py	/^    def stop(self):$/;"	kind:member	line:179
stop	../perception/perception/video_recorder.py	/^    def stop(self):$/;"	kind:member	line:67
stop	../perception/perception/webcam_sensor.py	/^    def stop(self):$/;"	kind:member	line:89
stop	../perception/perception/weight_sensor.py	/^    def stop(self):$/;"	kind:member	line:44
stop_recording	../perception/perception/video_recorder.py	/^    def stop_recording(self):$/;"	kind:member	line:60
stream_to_buffer	../perception/ros_nodes/image_buffer.py	/^        stream_to_buffer = rospy.get_namespace() + stream_to_buffer$/;"	kind:variable	line:43
stream_to_buffer	../perception/ros_nodes/image_buffer.py	/^    stream_to_buffer = instream$/;"	kind:variable	line:41
stride	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def stride(self):$/;"	kind:member	line:652
sub_mods	../setup.py	/^    sub_mods = get_git_submods()$/;"	kind:variable	line:383
subpolicy	../gqcnn/gqcnn/grasping/policy/policy.py	/^    def subpolicy(self, name):$/;"	kind:member	line:1546
subsample	../autolab_core/autolab_core/points.py	/^    def subsample(self, rate):$/;"	kind:member	line:905
subsample	../autolab_core/autolab_core/points.py	/^    def subsample(self, rate, random=False):$/;"	kind:member	line:602
subsample	../gqcnn/examples/policy_with_image_proc.py	/^                     subsample=3,$/;"	kind:variable	line:207
subsample	../perception/tools/compute_normal_cloud_im.py	/^    subsample = 20$/;"	kind:variable	line:37
subsample	../perception/tools/filter_images.py	/^                         subsample=5)$/;"	kind:variable	line:157
subsample	../perception/tools/filter_images.py	/^                     subsample=10)$/;"	kind:variable	line:95
subsample	../perception/tools/filter_images.py	/^                     subsample=10)$/;"	kind:variable	line:99
subsample	../perception/tools/filter_images.py	/^                     subsample=5)$/;"	kind:variable	line:171
subsample_tensor_dataset.py	../autolab_core/tools/subsample_tensor_dataset.py	1;"	kind:file	line:1
superimposition_matrix	../autolab_core/autolab_core/transformations.py	/^def superimposition_matrix(v0, v1, scaling=False, usesvd=True):$/;"	kind:function	line:866
swap_channels	../perception/perception/image.py	/^    def swap_channels(self, channel_swap):$/;"	kind:member	line:1089
t	../perception/perception/orthographic_intrinsics.py	/^    def t(self):$/;"	kind:member	line:82
t_gripper_world	../perception/tools/register_camera.py	/^            t_gripper_world = np.array([target_pt_world.x + config['gripper_offset_x'],$/;"	kind:variable	line:299
t_gripper_world	../perception/tools/register_camera.py	/^            t_gripper_world = np.array([target_pt_world.x + config['gripper_offset_x'],$/;"	kind:variable	line:342
t_gripper_world	../perception/tools/register_camera.py	/^            t_gripper_world = np.array([target_pt_world.x + config['gripper_offset_x'],$/;"	kind:variable	line:369
t_robot_world	../perception/tools/register_camera.py	/^                    t_robot_world = np.array([x, y, gripper_height])$/;"	kind:variable	line:112
tag	../autolab_core/tools/aggregate_tensor_datasets.py	/^                                              tag='dataset_')$/;"	kind:variable	line:62
tare	../perception/perception/weight_sensor.py	/^    def tare(self):$/;"	kind:member	line:85
target_ind	../perception/tools/register_camera.py	/^            target_ind = np.where(ip == np.max(ip))[0]$/;"	kind:variable	line:287
target_ind	../perception/tools/register_camera.py	/^            target_ind = np.where(ip == np.max(ip))[0]$/;"	kind:variable	line:365
target_ind	../perception/tools/register_camera.py	/^            target_ind = np.where(ip == np.min(ip))[0]$/;"	kind:variable	line:338
target_normals	../perception/perception/feature_matcher.py	/^    def target_normals(self):$/;"	kind:member	line:88
target_points	../perception/perception/feature_matcher.py	/^    def target_points(self):$/;"	kind:member	line:43
target_pt_world	../perception/tools/register_camera.py	/^            target_pt_world = cb_points_world[target_ind[0]]$/;"	kind:variable	line:288
target_pt_world	../perception/tools/register_camera.py	/^            target_pt_world = cb_points_world[target_ind[0]]$/;"	kind:variable	line:339
target_pt_world	../perception/tools/register_camera.py	/^            target_pt_world = cb_points_world[target_ind[0]]$/;"	kind:variable	line:366
templates_path	../autolab_core/docs/source/conf.py	/^templates_path = ['_templates']$/;"	kind:variable	line:43
templates_path	../docs/source/conf.py	/^templates_path = ["_templates"]$/;"	kind:variable	line:68
templates_path	../gqcnn/docs/source/conf.py	/^templates_path = ["_templates"]$/;"	kind:variable	line:46
templates_path	../perception/docs/source/conf.py	/^templates_path = ['_templates']$/;"	kind:variable	line:43
tensor	../autolab_core/autolab_core/tensor_dataset.py	/^    def tensor(self, field_name, tensor_ind):$/;"	kind:member	line:569
tensor_config	../autolab_core/tools/aggregate_tensor_datasets.py	/^    tensor_config = copy.deepcopy(dataset.config)$/;"	kind:variable	line:67
tensor_config	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    tensor_config = {$/;"	kind:variable	line:58
tensor_dataset.py	../autolab_core/autolab_core/tensor_dataset.py	1;"	kind:file	line:1
tensor_dir	../autolab_core/autolab_core/tensor_dataset.py	/^    def tensor_dir(self):$/;"	kind:member	line:399
tensor_dir	../autolab_core/tools/aggregate_tensor_datasets.py	/^        tensor_dir = os.path.join(dataset_name, 'tensors')$/;"	kind:variable	line:57
tensor_dir	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^    tensor_dir = os.path.join(dataset_dir, 'tensors')$/;"	kind:variable	line:75
tensor_index	../autolab_core/autolab_core/tensor_dataset.py	/^    def tensor_index(self, datapoint_index):$/;"	kind:member	line:421
tensor_indices	../autolab_core/autolab_core/tensor_dataset.py	/^    def tensor_indices(self):$/;"	kind:member	line:394
tensorboard_port	../gqcnn/tools/finetune.py	/^    tensorboard_port = args.tensorboard_port$/;"	kind:variable	line:104
tensorboard_port	../gqcnn/tools/train.py	/^    tensorboard_port = args.tensorboard_port$/;"	kind:variable	line:94
tensors	../autolab_core/autolab_core/tensor_dataset.py	/^    def tensors(self):$/;"	kind:member	line:389
test	../panda_autograsp/scripts/test_clear_octomap.py	/^    test = rospy.ServiceProxy('\/clear_octomap', Empty)$/;"	kind:variable	line:51
test_bad_inits	../autolab_core/tests/test_rigid_transform.py	/^    def test_bad_inits(self):$/;"	kind:member	line:25
test_bad_transformation	../autolab_core/tests/test_rigid_transform.py	/^    def test_bad_transformation(self, num_points=10):$/;"	kind:member	line:147
test_binary_init	../perception/tests/test_image.py	/^    def test_binary_init(self):$/;"	kind:member	line:68
test_case_path	../gqcnn/tools/run_policy.py	/^    test_case_path = args.test_case_path$/;"	kind:variable	line:69
test_clear_octomap.py	../panda_autograsp/scripts/test_clear_octomap.py	1;"	kind:file	line:1
test_color_init	../perception/tests/test_image.py	/^    def test_color_init(self):$/;"	kind:member	line:13
test_composition	../autolab_core/tests/test_rigid_transform.py	/^    def test_composition(self):$/;"	kind:member	line:87
test_dataset.py	../autolab_core/tests/test_dataset.py	1;"	kind:file	line:1
test_depth_init	../perception/tests/test_image.py	/^    def test_depth_init(self):$/;"	kind:member	line:40
test_ensenso.py	../perception/tools/test_ensenso.py	1;"	kind:file	line:1
test_grayscale_init	../perception/tests/test_image.py	/^    def test_grayscale_init(self):$/;"	kind:member	line:96
test_image.py	../perception/tests/test_image.py	1;"	kind:file	line:1
test_indexing	../perception/tests/test_image.py	/^    def test_indexing(self, height=50, width=100):$/;"	kind:member	line:255
test_indices	../perception/tools/capture_dataset.py	/^    test_indices = all_indices[num_train:]$/;"	kind:variable	line:171
test_init	../autolab_core/tests/test_rigid_transform.py	/^    def test_init(self):$/;"	kind:member	line:16
test_inits	../autolab_core/tests/test_points.py	/^    def test_inits(self, num_points=10):$/;"	kind:member	line:15
test_inverse	../autolab_core/tests/test_rigid_transform.py	/^    def test_inverse(self):$/;"	kind:member	line:71
test_io	../perception/tests/test_image.py	/^    def test_io(self, height=50, width=100):$/;"	kind:member	line:384
test_mask_by_ind	../perception/tests/test_image.py	/^    def test_mask_by_ind(self):$/;"	kind:member	line:247
test_multi_tensor_read_write	../autolab_core/tests/test_dataset.py	/^    def test_multi_tensor_read_write(self):$/;"	kind:member	line:178
test_nc_init	../perception/tests/test_image.py	/^    def test_nc_init(self):$/;"	kind:member	line:177
test_pc_init	../perception/tests/test_image.py	/^    def test_pc_init(self):$/;"	kind:member	line:150
test_point_cloud_transformation	../autolab_core/tests/test_rigid_transform.py	/^    def test_point_cloud_transformation(self, num_points=10):$/;"	kind:member	line:128
test_point_transformation	../autolab_core/tests/test_rigid_transform.py	/^    def test_point_transformation(self):$/;"	kind:member	line:109
test_points.py	../autolab_core/tests/test_points.py	1;"	kind:file	line:1
test_realsense.py	../perception/tools/test_realsense.py	1;"	kind:file	line:1
test_registration	../perception/tests/test_registration.py	/^    def test_registration(self):$/;"	kind:member	line:18
test_registration.py	../perception/tests/test_registration.py	1;"	kind:file	line:1
test_resize	../perception/tests/test_image.py	/^    def test_resize(self):$/;"	kind:member	line:214
test_rigid_transform.py	../autolab_core/tests/test_rigid_transform.py	1;"	kind:file	line:1
test_segment_init	../perception/tests/test_image.py	/^    def test_segment_init(self):$/;"	kind:member	line:123
test_shape_comp	../perception/tests/test_image.py	/^    def test_shape_comp(self):$/;"	kind:member	line:236
test_similarity_transformation	../autolab_core/tests/test_rigid_transform.py	/^    def test_similarity_transformation(self):$/;"	kind:member	line:181
test_single_read_write	../autolab_core/tests/test_dataset.py	/^    def test_single_read_write(self):$/;"	kind:member	line:83
test_suite	../autolab_core/tests/test_dataset.py	/^    test_suite = TestSuite()$/;"	kind:variable	line:305
test_suite	../perception/tests/test_registration.py	/^    test_suite = unittest.TestSuite()$/;"	kind:variable	line:64
test_transform	../perception/tests/test_image.py	/^    def test_transform(self):$/;"	kind:member	line:228
test_video_recorder.py	../perception/tools/test_video_recorder.py	1;"	kind:file	line:1
test_weight_sensor.py	../perception/tools/test_weight_sensor.py	1;"	kind:file	line:1
texinfo_documents	../autolab_core/docs/source/conf.py	/^texinfo_documents = [$/;"	kind:variable	line:277
texinfo_documents	../docs/source/conf.py	/^texinfo_documents = [$/;"	kind:variable	line:295
texinfo_documents	../gqcnn/docs/source/conf.py	/^texinfo_documents = [$/;"	kind:variable	line:274
texinfo_documents	../perception/docs/source/conf.py	/^texinfo_documents = [$/;"	kind:variable	line:278
text_height	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_height = 160$/;"	kind:variable	line:189
text_height	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_height = 160$/;"	kind:variable	line:263
text_height	../panda_autograsp/scripts/chessboard_calibration.py	/^        text_height = 100$/;"	kind:variable	line:465
text_offset_x	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_offset_x = 10$/;"	kind:variable	line:186
text_offset_x	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_offset_x = 10$/;"	kind:variable	line:260
text_offset_x	../panda_autograsp/scripts/chessboard_calibration.py	/^        text_offset_x = 10$/;"	kind:variable	line:462
text_offset_y	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_offset_y = 910$/;"	kind:variable	line:187
text_offset_y	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_offset_y = 910$/;"	kind:variable	line:261
text_offset_y	../panda_autograsp/scripts/chessboard_calibration.py	/^        text_offset_y = 970$/;"	kind:variable	line:463
text_width	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_width = 550$/;"	kind:variable	line:188
text_width	../panda_autograsp/scripts/chessboard_calibration.py	/^                    text_width = 550$/;"	kind:variable	line:262
text_width	../panda_autograsp/scripts/chessboard_calibration.py	/^        text_width = 630$/;"	kind:variable	line:464
tf2_broadcaster.py	../panda_autograsp/nodes/tf2_broadcaster.py	1;"	kind:file	line:1
tf2_broadcaster_callback	../panda_autograsp/src/panda_autograsp/tf2_broadcaster_ros.py	/^    def tf2_broadcaster_callback(self, event=None):$/;"	kind:member	line:311
tf2_broadcaster_ros.py	../panda_autograsp/src/panda_autograsp/tf2_broadcaster_ros.py	1;"	kind:file	line:1
tfBuffer	../autolab_core/ros_nodes/rigid_transform_listener.py	/^    tfBuffer = tf2_ros.Buffer()$/;"	kind:variable	line:21
tf_filename	../gqcnn/examples/antipodal_grasp_sampling.py	/^    tf_filename = "%s_to_world.tf" % (sensor_frame)$/;"	kind:variable	line:71
tf_filename	../perception/tools/capture_dataset.py	/^        tf_filename = '%s_to_world.tf' %(sensor_frame)$/;"	kind:variable	line:227
tf_filename	../perception/tools/capture_test_images.py	/^        tf_filename = '%s_to_world.tf' %(sensor_frame)$/;"	kind:variable	line:64
tf_graph	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def tf_graph(self):$/;"	kind:member	line:636
threshold	../perception/perception/image.py	/^    def threshold(self, front_thresh=0.0, rear_thresh=100.0):$/;"	kind:member	line:1633
threshold_gradients	../perception/perception/image.py	/^    def threshold_gradients(self, grad_thresh):$/;"	kind:member	line:1655
threshold_gradients_pctile	../perception/perception/image.py	/^    def threshold_gradients_pctile(self, thresh_pctile, min_mag=0.0):$/;"	kind:member	line:1680
thumbnail	../gqcnn/examples/policy_ros.py	/^        thumbnail = DepthImage(cv_bridge.imgmsg_to_cv2($/;"	kind:variable	line:156
time_str	../panda_autograsp/scripts/chessboard_calibration.py	/^            time_str = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")$/;"	kind:variable	line:429
time_str	../panda_autograsp/scripts/chessboard_calibration.py	/^    time_str = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")$/;"	kind:variable	line:117
time_str	../panda_autograsp/scripts/generate_arucoboard.py	/^    time_str = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")$/;"	kind:variable	line:122
time_str	../panda_autograsp/scripts/kinect_processing.py	/^            time_str = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")$/;"	kind:variable	line:170
timeout_option	../gqcnn/gqcnn/utils/enums.py	/^    timeout_option = tf.RunOptions(timeout_in_ms=1000000)$/;"	kind:variable	line:44
to_binary	../perception/perception/image.py	/^    def to_binary(self, threshold=0.0):$/;"	kind:member	line:1437
to_binary	../perception/perception/image.py	/^    def to_binary(self, threshold=0.0):$/;"	kind:member	line:1842
to_color	../perception/perception/image.py	/^    def to_color(self):$/;"	kind:member	line:2121
to_color	../perception/perception/image.py	/^    def to_color(self):$/;"	kind:member	line:2769
to_color	../perception/perception/image.py	/^    def to_color(self, normalize=False):$/;"	kind:member	line:1861
to_distance_im	../perception/perception/image.py	/^    def to_distance_im(self):$/;"	kind:member	line:2674
to_float	../perception/perception/image.py	/^    def to_float(self):$/;"	kind:member	line:1877
to_frame	../autolab_core/autolab_core/rigid_transformations.py	/^    def to_frame(self):$/;"	kind:member	line:181
to_frame	../autolab_core/autolab_core/rigid_transformations.py	/^    def to_frame(self, to_frame):$/;"	kind:member	line:187
to_frame	../perception/tools/register_camera.py	/^                                                   to_frame='world')$/;"	kind:variable	line:116
to_frame	../perception/tools/register_camera.py	/^                                                  to_frame='world')$/;"	kind:variable	line:219
to_frame	../perception/tools/register_camera.py	/^                                             to_frame='cb')$/;"	kind:variable	line:305
to_frame	../perception/tools/register_camera.py	/^                                             to_frame='cb')$/;"	kind:variable	line:348
to_frame	../perception/tools/register_camera.py	/^                                             to_frame='cb')$/;"	kind:variable	line:375
to_frame	../perception/tools/register_camera.py	/^                                        to_frame=T_cb_world.to_frame)$/;"	kind:variable	line:224
to_grayscale	../perception/perception/image.py	/^    def to_grayscale(self):$/;"	kind:member	line:1448
to_grayscale_depth	../perception/perception/image.py	/^    def to_grayscale_depth(self):$/;"	kind:member	line:3011
to_mesh	../perception/perception/image.py	/^    def to_mesh(self, dist_thresh=0.01):$/;"	kind:member	line:3466
to_normal_cloud	../perception/perception/image.py	/^    def to_normal_cloud(self):$/;"	kind:member	line:3680
to_point_cloud	../perception/perception/image.py	/^    def to_point_cloud(self):$/;"	kind:member	line:3537
to_publish	../autolab_core/ros_nodes/rigid_transform_publisher.py	/^    to_publish = {}$/;"	kind:variable	line:19
to_sdf	../perception/perception/image.py	/^    def to_sdf(self):$/;"	kind:member	line:2752
todo_include_todos	../autolab_core/docs/source/conf.py	/^todo_include_todos = False$/;"	kind:variable	line:112
todo_include_todos	../docs/source/conf.py	/^todo_include_todos = False$/;"	kind:variable	line:121
todo_include_todos	../gqcnn/docs/source/conf.py	/^todo_include_todos = False$/;"	kind:variable	line:115
todo_include_todos	../perception/docs/source/conf.py	/^todo_include_todos = False$/;"	kind:variable	line:112
top_k_error_rate	../autolab_core/autolab_core/learning_analysis.py	/^    def top_k_error_rate(self, k):$/;"	kind:member	line:367
top_k_error_rate	../autolab_core/autolab_core/learning_analysis.py	/^    def top_k_error_rate(self, k):$/;"	kind:member	line:75
top_k_predictions	../autolab_core/autolab_core/learning_analysis.py	/^    def top_k_predictions(self, k):$/;"	kind:member	line:116
top_k_predictions	../autolab_core/autolab_core/learning_analysis.py	/^    def top_k_predictions(self, k):$/;"	kind:member	line:364
tot_error	../panda_autograsp/scripts/chessboard_calibration.py	/^        tot_error = 0$/;"	kind:variable	line:390
total_weight	../perception/perception/weight_sensor.py	/^    def total_weight(self):$/;"	kind:member	line:53
tpr	../autolab_core/autolab_core/learning_analysis.py	/^    def tpr(self):$/;"	kind:member	line:385
train	../gqcnn/gqcnn/training/tf/trainer_tf.py	/^    def train(self):$/;"	kind:member	line:233
train	../perception/tools/capture_dataset.py	/^            train = 1$/;"	kind:variable	line:286
train	../perception/tools/capture_dataset.py	/^        train = 0$/;"	kind:variable	line:283
train.py	../gqcnn/tools/train.py	1;"	kind:file	line:1
train_config	../gqcnn/tools/finetune.py	/^    train_config = YamlConfig(config_filename)$/;"	kind:variable	line:145
train_config	../gqcnn/tools/train.py	/^    train_config = YamlConfig(config_filename)$/;"	kind:variable	line:124
train_configs	../gqcnn/tools/hyperparam_search.py	/^    train_configs = [YamlConfig(cfg) for cfg in train_configs]$/;"	kind:variable	line:117
train_configs	../gqcnn/tools/hyperparam_search.py	/^    train_configs = args.train_configs$/;"	kind:variable	line:86
train_errors	../gqcnn/tools/plot_training_losses.py	/^    train_errors = []$/;"	kind:variable	line:83
train_errors	../gqcnn/tools/plot_training_losses.py	/^    train_errors = np.array(train_errors)$/;"	kind:variable	line:93
train_errors_filename	../gqcnn/tools/plot_training_losses.py	/^    train_errors_filename = os.path.join(result_dir,$/;"	kind:variable	line:55
train_image_indices	../perception/tools/capture_dataset.py	/^    train_image_indices = all_image_indices[:num_train_images]$/;"	kind:variable	line:176
train_indices	../perception/tools/capture_dataset.py	/^    train_indices = all_indices[:num_train]$/;"	kind:variable	line:170
train_indices_filename	../autolab_core/autolab_core/tensor_dataset.py	/^    def train_indices_filename(self, split_name):$/;"	kind:member	line:435
train_iters	../gqcnn/tools/plot_training_losses.py	/^    train_iters = []$/;"	kind:variable	line:85
train_iters	../gqcnn/tools/plot_training_losses.py	/^    train_iters = np.array(train_iters)$/;"	kind:variable	line:95
train_iters_filename	../gqcnn/tools/plot_training_losses.py	/^    train_iters_filename = os.path.join(result_dir, GQCNNFilenames.TRAIN_ITERS)$/;"	kind:variable	line:58
train_losses	../gqcnn/tools/plot_training_losses.py	/^    train_losses = []$/;"	kind:variable	line:84
train_losses	../gqcnn/tools/plot_training_losses.py	/^    train_losses = np.array(train_losses)$/;"	kind:variable	line:94
train_losses_filename	../gqcnn/tools/plot_training_losses.py	/^    train_losses_filename = os.path.join(result_dir, GQCNNFilenames.TRAIN_LOSS)$/;"	kind:variable	line:61
train_pct	../autolab_core/tools/split_dataset.py	/^    train_pct = args.train_pct$/;"	kind:variable	line:55
train_pct	../perception/tools/capture_dataset.py	/^    train_pct = config['train_pct']$/;"	kind:variable	line:163
train_stats_logger.py	../gqcnn/gqcnn/utils/train_stats_logger.py	1;"	kind:file	line:1
trainer	../gqcnn/tools/finetune.py	/^    trainer = get_gqcnn_trainer(backend)(gqcnn,$/;"	kind:variable	line:167
trainer	../gqcnn/tools/train.py	/^    trainer = get_gqcnn_trainer(backend)(gqcnn,$/;"	kind:variable	line:146
trainer_tf.py	../gqcnn/gqcnn/training/tf/trainer_tf.py	1;"	kind:file	line:1
training_status	../gqcnn/gqcnn/search/trial.py	/^    def training_status(self):$/;"	kind:member	line:166
transform	../perception/perception/image.py	/^    def transform(self, translation, theta, method='opencv'):$/;"	kind:member	line:2987
transform	../perception/perception/image.py	/^    def transform(self, translation, theta, method='opencv'):$/;"	kind:member	line:348
transform_from_dual_quaternion	../autolab_core/autolab_core/rigid_transformations.py	/^    def transform_from_dual_quaternion(dq, from_frame='unassigned', to_frame='world'):$/;"	kind:member	line:760
transform_stamped_2_matrix	../panda_autograsp/src/panda_autograsp/functions/conversions.py	/^def transform_stamped_2_matrix(transform_stamped):$/;"	kind:function	line:24
transformations.py	../autolab_core/autolab_core/transformations.py	1;"	kind:file	line:1
translation	../autolab_core/autolab_core/rigid_transformations.py	/^    def translation(self):$/;"	kind:member	line:136
translation	../autolab_core/autolab_core/rigid_transformations.py	/^    def translation(self, translation):$/;"	kind:member	line:143
translation	../perception/tools/register_camera.py	/^                                                   translation=t_robot_world,$/;"	kind:variable	line:114
translation	../perception/tools/register_camera.py	/^                                             translation=t_gripper_world,$/;"	kind:variable	line:303
translation	../perception/tools/register_camera.py	/^                                             translation=t_gripper_world,$/;"	kind:variable	line:346
translation	../perception/tools/register_camera.py	/^                                             translation=t_gripper_world,$/;"	kind:variable	line:373
translation	../perception/tools/register_camera.py	/^                                        translation=T_cb_world.translation,$/;"	kind:variable	line:222
translation_from_matrix	../autolab_core/autolab_core/transformations.py	/^def translation_from_matrix(matrix):$/;"	kind:function	line:208
translation_matrix	../autolab_core/autolab_core/transformations.py	/^def translation_matrix(direction):$/;"	kind:function	line:195
tree	../gqcnn/examples/policy_with_image_proc.py	/^    tree = pcl_cloud.make_kdtree()$/;"	kind:variable	line:158
tree	../perception/tools/filter_images.py	/^    tree = pcl_cloud.make_kdtree()$/;"	kind:variable	line:114
trial.py	../gqcnn/gqcnn/search/trial.py	1;"	kind:file	line:1
true_negative_indices	../autolab_core/autolab_core/learning_analysis.py	/^    def true_negative_indices(self):$/;"	kind:member	line:411
true_positive_indices	../autolab_core/autolab_core/learning_analysis.py	/^    def true_positive_indices(self):$/;"	kind:member	line:403
true_robot_points_world	../perception/tools/register_camera.py	/^                true_robot_points_world = PointCloud(np.array([T.translation for T in robot_poses]).T,$/;"	kind:variable	line:232
true_robot_points_world	../perception/tools/register_camera.py	/^            true_robot_points_world = PointCloud(np.array([T.translation for T in robot_poses]).T,$/;"	kind:variable	line:168
tutorialformatter.py	../moveit_tutorials/_scripts/tutorialformatter.py	1;"	kind:file	line:1
tvecs	../panda_autograsp/scripts/chessboard_calibration.py	/^                    tvecs=tvecs,$/;"	kind:variable	line:532
type	../gqcnn/examples/antipodal_grasp_sampling.py	/^                        type=str,$/;"	kind:variable	line:54
type	../gqcnn/examples/policy.py	/^                        type=str,$/;"	kind:variable	line:64
type	../gqcnn/examples/policy.py	/^                        type=str,$/;"	kind:variable	line:73
type	../gqcnn/examples/policy.py	/^                        type=str,$/;"	kind:variable	line:77
type	../gqcnn/examples/policy.py	/^                        type=str,$/;"	kind:variable	line:81
type	../gqcnn/examples/policy.py	/^                        type=str,$/;"	kind:variable	line:85
type	../gqcnn/examples/policy.py	/^        type=str,$/;"	kind:variable	line:69
type	../gqcnn/examples/policy_ros.py	/^                        type=bool,$/;"	kind:variable	line:83
type	../gqcnn/examples/policy_ros.py	/^                        type=float,$/;"	kind:variable	line:75
type	../gqcnn/examples/policy_ros.py	/^                        type=str,$/;"	kind:variable	line:67
type	../gqcnn/examples/policy_ros.py	/^                        type=str,$/;"	kind:variable	line:71
type	../gqcnn/examples/policy_ros.py	/^                        type=str,$/;"	kind:variable	line:79
type	../gqcnn/examples/policy_ros.py	/^        type=str,$/;"	kind:variable	line:63
type	../gqcnn/examples/policy_with_image_proc.py	/^                        type=str,$/;"	kind:variable	line:69
type	../gqcnn/examples/policy_with_image_proc.py	/^                        type=str,$/;"	kind:variable	line:73
type	../gqcnn/examples/policy_with_image_proc.py	/^                        type=str,$/;"	kind:variable	line:77
type	../gqcnn/examples/policy_with_image_proc.py	/^                        type=str,$/;"	kind:variable	line:81
type	../gqcnn/examples/policy_with_image_proc.py	/^                        type=str,$/;"	kind:variable	line:85
type	../gqcnn/examples/policy_with_image_proc.py	/^        type=str,$/;"	kind:variable	line:65
type	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        type=str,$/;"	kind:variable	line:50
type	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        type=str,$/;"	kind:variable	line:54
type	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        type=str,$/;"	kind:variable	line:63
type	../gqcnn/tools/analyze_gqcnn_performance.py	/^                        type=str,$/;"	kind:variable	line:67
type	../gqcnn/tools/analyze_gqcnn_performance.py	/^        type=str,$/;"	kind:variable	line:59
type	../gqcnn/tools/finetune.py	/^                        type=int,$/;"	kind:variable	line:70
type	../gqcnn/tools/finetune.py	/^                        type=int,$/;"	kind:variable	line:74
type	../gqcnn/tools/finetune.py	/^                        type=str,$/;"	kind:variable	line:58
type	../gqcnn/tools/finetune.py	/^                        type=str,$/;"	kind:variable	line:62
type	../gqcnn/tools/finetune.py	/^                        type=str,$/;"	kind:variable	line:66
type	../gqcnn/tools/finetune.py	/^                        type=str,$/;"	kind:variable	line:78
type	../gqcnn/tools/finetune.py	/^                        type=str,$/;"	kind:variable	line:82
type	../gqcnn/tools/finetune.py	/^                        type=str,$/;"	kind:variable	line:86
type	../gqcnn/tools/finetune.py	/^                        type=str,$/;"	kind:variable	line:96
type	../gqcnn/tools/finetune.py	/^        type=bool,$/;"	kind:variable	line:91
type	../gqcnn/tools/finetune.py	/^        type=str,$/;"	kind:variable	line:54
type	../gqcnn/tools/hyperparam_search.py	/^                        type=str,$/;"	kind:variable	line:61
type	../gqcnn/tools/hyperparam_search.py	/^                        type=str,$/;"	kind:variable	line:68
type	../gqcnn/tools/hyperparam_search.py	/^                        type=str,$/;"	kind:variable	line:72
type	../gqcnn/tools/run_policy.py	/^                        type=str,$/;"	kind:variable	line:56
type	../gqcnn/tools/run_policy.py	/^                        type=str,$/;"	kind:variable	line:60
type	../gqcnn/tools/run_policy.py	/^                        type=str,$/;"	kind:variable	line:64
type	../gqcnn/tools/train.py	/^                        type=int,$/;"	kind:variable	line:65
type	../gqcnn/tools/train.py	/^                        type=int,$/;"	kind:variable	line:69
type	../gqcnn/tools/train.py	/^                        type=str,$/;"	kind:variable	line:57
type	../gqcnn/tools/train.py	/^                        type=str,$/;"	kind:variable	line:61
type	../gqcnn/tools/train.py	/^                        type=str,$/;"	kind:variable	line:73
type	../gqcnn/tools/train.py	/^                        type=str,$/;"	kind:variable	line:77
type	../gqcnn/tools/train.py	/^                        type=str,$/;"	kind:variable	line:87
type	../gqcnn/tools/train.py	/^        type=bool,$/;"	kind:variable	line:82
type	../gqcnn/tools/train.py	/^        type=str,$/;"	kind:variable	line:53
type	../perception/perception/image.py	/^    def type(self):$/;"	kind:member	line:193
u_ind	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^        u_ind = f.rfind('_')$/;"	kind:variable	line:37
undistorted	../panda_autograsp/scripts/kinect_processing.py	/^    undistorted = Frame(512, 424, 4)$/;"	kind:variable	line:111
unique_name	../gqcnn/tools/finetune.py	/^        unique_name = time.strftime("%Y%m%d-%H%M%S")$/;"	kind:variable	line:156
unique_name	../gqcnn/tools/train.py	/^        unique_name = time.strftime("%Y%m%d-%H%M%S")$/;"	kind:variable	line:135
unit_vector	../autolab_core/autolab_core/transformations.py	/^def unit_vector(data, axis=None, out=None):$/;"	kind:function	line:1574
until	../moveit_tutorials/_scripts/tutorialformatter.py	/^                       until=unchanged)$/;"	kind:variable	line:88
update	../autolab_core/autolab_core/learning_analysis.py	/^    def update(self, predictions, labels):$/;"	kind:member	line:41
update	../autolab_core/autolab_core/yaml_config.py	/^    def update(self, d):$/;"	kind:member	line:41
update	../gqcnn/gqcnn/utils/train_stats_logger.py	/^    def update(self, **stats):$/;"	kind:member	line:90
update_batch_size	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def update_batch_size(self, batch_size):$/;"	kind:member	line:825
update_by_uid	../autolab_core/autolab_core/csv_model.py	/^    def update_by_uid(self, uid, data):$/;"	kind:member	line:151
update_dict	../gqcnn/gqcnn/search/utils.py	/^def update_dict(dict1, dict2):$/;"	kind:function	line:64
update_master_record	../autolab_core/autolab_core/experiment_logger.py	/^    def update_master_record(self, data):$/;"	kind:member	line:100
url	../autolab_core/setup.py	/^    url = 'https:\/\/github.com\/BerkeleyAutomation\/autolab_core',$/;"	kind:variable	line:30
url	../gqcnn/setup.py	/^    url="https:\/\/github.com\/BerkeleyAutomation\/gqcnn",$/;"	kind:variable	line:174
url	../panda_autograsp/setup.py	/^    url="https:\/\/github.com\/rickstaa\/panyda_autograsp",$/;"	kind:variable	line:247
url	../perception/setup.py	/^      url = 'https:\/\/github.com\/BerkeleyAutomation\/perception',$/;"	kind:variable	line:33
url	../setup.py	/^    url="https:\/\/github.com\/rickstaa\/panda_autograsp",$/;"	kind:variable	line:394
user_options	../gqcnn/setup.py	/^    user_options = getattr(develop, "user_options", []) + user_options_custom$/;"	kind:variable	line:77
user_options	../gqcnn/setup.py	/^    user_options = getattr(install, "user_options", []) + user_options_custom$/;"	kind:variable	line:112
user_options	../panda_autograsp/setup.py	/^    user_options = getattr(develop, "user_options", []) + user_options_custom$/;"	kind:variable	line:141
user_options	../panda_autograsp/setup.py	/^    user_options = getattr(install, "user_options", []) + user_options_custom$/;"	kind:variable	line:182
user_options	../setup.py	/^    user_options = getattr(develop, "user_options", []) + user_options_custom$/;"	kind:variable	line:269
user_options	../setup.py	/^    user_options = getattr(install, "user_options", []) + user_options_custom$/;"	kind:variable	line:312
user_options_custom	../gqcnn/setup.py	/^    user_options_custom = [$/;"	kind:variable	line:109
user_options_custom	../gqcnn/setup.py	/^    user_options_custom = [$/;"	kind:variable	line:74
user_options_custom	../panda_autograsp/setup.py	/^    user_options_custom = [$/;"	kind:variable	line:137
user_options_custom	../panda_autograsp/setup.py	/^    user_options_custom = [$/;"	kind:variable	line:178
user_options_custom	../setup.py	/^    user_options_custom = [("docker", None, "installing in Docker")]$/;"	kind:variable	line:268
user_options_custom	../setup.py	/^    user_options_custom = [("docker", None, "installing in Docker")]$/;"	kind:variable	line:311
utils.py	../autolab_core/autolab_core/utils.py	1;"	kind:file	line:1
utils.py	../gqcnn/gqcnn/search/utils.py	1;"	kind:file	line:1
utils.py	../gqcnn/gqcnn/utils/utils.py	1;"	kind:file	line:1
val	../panda_autograsp/nodes/grasp_planner_server.py	/^                val = download_model(model_name, MODELS_PATH, DOWNLOAD_SCRIPT_PATH)$/;"	kind:variable	line:126
val_errors	../gqcnn/tools/plot_training_losses.py	/^    val_errors = np.load(val_errors_filename)$/;"	kind:variable	line:65
val_errors	../gqcnn/tools/plot_training_losses.py	/^    val_errors = np.r_[pct_pos_val, val_errors]$/;"	kind:variable	line:78
val_errors_filename	../gqcnn/tools/plot_training_losses.py	/^    val_errors_filename = os.path.join(result_dir, GQCNNFilenames.VAL_ERRORS)$/;"	kind:variable	line:57
val_indices_filename	../autolab_core/autolab_core/tensor_dataset.py	/^    def val_indices_filename(self, split_name):$/;"	kind:member	line:439
val_iters	../gqcnn/tools/plot_training_losses.py	/^    val_iters = np.load(val_iters_filename)$/;"	kind:variable	line:67
val_iters	../gqcnn/tools/plot_training_losses.py	/^    val_iters = np.r_[0, val_iters]$/;"	kind:variable	line:79
val_iters_filename	../gqcnn/tools/plot_training_losses.py	/^    val_iters_filename = os.path.join(result_dir, GQCNNFilenames.VAL_ITERS)$/;"	kind:variable	line:59
val_losses	../gqcnn/tools/plot_training_losses.py	/^        val_losses = np.load(val_losses_filename)$/;"	kind:variable	line:74
val_losses	../gqcnn/tools/plot_training_losses.py	/^        val_losses = np.r_[train_losses[0], val_losses]$/;"	kind:variable	line:98
val_losses	../gqcnn/tools/plot_training_losses.py	/^    val_losses = None$/;"	kind:variable	line:72
val_losses_filename	../gqcnn/tools/plot_training_losses.py	/^    val_losses_filename = os.path.join(result_dir, GQCNNFilenames.VAL_LOSS)$/;"	kind:variable	line:62
valid_px_mask	../gqcnn/examples/policy.py	/^    valid_px_mask = depth_im.invalid_pixel_mask().inverse()$/;"	kind:variable	line:203
valid_px_mask	../gqcnn/examples/policy_with_image_proc.py	/^    valid_px_mask = depth_im.invalid_pixel_mask().inverse()$/;"	kind:variable	line:148
vec	../autolab_core/autolab_core/rigid_transformations.py	/^    def vec(self):$/;"	kind:member	line:236
vec	../perception/perception/camera_intrinsics.py	/^    def vec(self):$/;"	kind:member	line:136
vector	../autolab_core/autolab_core/points.py	/^    def vector(self):$/;"	kind:member	line:229
vector_norm	../autolab_core/autolab_core/transformations.py	/^def vector_norm(data, axis=None, out=None):$/;"	kind:function	line:1535
version	../autolab_core/docs/source/conf.py	/^version = __version__$/;"	kind:variable	line:66
version	../autolab_core/setup.py	/^    version = __version__,$/;"	kind:variable	line:24
version	../docs/source/conf.py	/^version = "0.0"$/;"	kind:variable	line:30
version	../gqcnn/docs/source/conf.py	/^version = u"1.1"$/;"	kind:variable	line:69
version	../gqcnn/setup.py	/^    version=__version__,  # noqa F821$/;"	kind:variable	line:168
version	../moveit_tutorials/conf.py	/^version = 'Kinetic'$/;"	kind:variable	line:21
version	../panda_autograsp/setup.py	/^    version=__version__,$/;"	kind:variable	line:240
version	../perception/docs/source/conf.py	/^version = __version__$/;"	kind:variable	line:66
version	../perception/setup.py	/^      version=__version__,$/;"	kind:variable	line:28
version	../setup.py	/^    version=__version__,$/;"	kind:variable	line:389
version.py	../autolab_core/autolab_core/version.py	1;"	kind:file	line:1
version.py	../gqcnn/gqcnn/version.py	1;"	kind:file	line:1
version.py	../panda_autograsp/version.py	1;"	kind:file	line:1
version.py	../perception/perception/version.py	1;"	kind:file	line:1
vgg	../perception/tools/keras_vgg.py	/^    vgg = VGG16(weights_filename=DEFAULT_VGG16_WEIGHTS)$/;"	kind:variable	line:24
video_recorder.py	../perception/perception/video_recorder.py	1;"	kind:file	line:1
virtual_camera_intrinsics	../perception/perception/detector.py	/^    def virtual_camera_intrinsics(self):$/;"	kind:member	line:90
vis	../perception/tools/capture_dataset.py	/^    vis = config['vis']$/;"	kind:variable	line:186
vis	../perception/tools/capture_test_images.py	/^    vis = config['vis']$/;"	kind:variable	line:31
vis_clipping	../perception/tools/filter_images.py	/^vis_clipping = False$/;"	kind:variable	line:25
vis_final_clouds	../perception/tools/filter_images.py	/^vis_final_clouds = False$/;"	kind:variable	line:27
vis_final_images	../perception/tools/filter_images.py	/^vis_final_images = True$/;"	kind:variable	line:28
vis_grasp	../gqcnn/examples/policy_ros.py	/^    vis_grasp = args.vis_grasp$/;"	kind:variable	line:92
vis_segments	../perception/tools/filter_images.py	/^vis_segments = False$/;"	kind:variable	line:26
visualize	../gqcnn/examples/antipodal_grasp_sampling.py	/^                                  visualize=visualize_sampling)$/;"	kind:variable	line:94
visualize_grasp_service	../panda_autograsp/src/panda_autograsp/panda_autograsp_server_ros.py	/^    def visualize_grasp_service(self, req):$/;"	kind:member	line:766
visualize_plan_service	../panda_autograsp/src/panda_autograsp/moveit_planner_server_ros.py	/^    def visualize_plan_service(self, req):$/;"	kind:member	line:542
visualize_plan_srv	../panda_autograsp/nodes/moveit_random_planner_client.py	/^        visualize_plan_srv = rospy.ServiceProxy($/;"	kind:variable	line:121
visualize_sampling	../gqcnn/examples/antipodal_grasp_sampling.py	/^    visualize_sampling = config["visualize_sampling"]$/;"	kind:variable	line:67
vmax	../gqcnn/examples/policy.py	/^                   vmax=policy_config["vis"]["vmax"])$/;"	kind:variable	line:268
vmax	../gqcnn/examples/policy_with_image_proc.py	/^                   vmax=policy_config["vis"]["vmax"])$/;"	kind:variable	line:236
vmax	../gqcnn/tools/run_policy.py	/^                         vmax=policy_config["vis"]["vmax"])$/;"	kind:variable	line:110
vmax	../gqcnn/tools/run_policy.py	/^                         vmax=policy_config["vis"]["vmax"])$/;"	kind:variable	line:119
vmax	../gqcnn/tools/run_policy.py	/^                     vmax=policy_config["vis"]["vmax"])$/;"	kind:variable	line:140
vmax	../gqcnn/tools/run_policy.py	/^                     vmax=policy_config["vis"]["vmax"])$/;"	kind:variable	line:151
vmin	../gqcnn/examples/policy.py	/^                   vmin=policy_config["vis"]["vmin"],$/;"	kind:variable	line:267
vmin	../gqcnn/examples/policy_with_image_proc.py	/^                   vmin=policy_config["vis"]["vmin"],$/;"	kind:variable	line:235
vmin	../gqcnn/tools/run_policy.py	/^                         vmin=policy_config["vis"]["vmin"],$/;"	kind:variable	line:109
vmin	../gqcnn/tools/run_policy.py	/^                         vmin=policy_config["vis"]["vmin"],$/;"	kind:variable	line:118
vmin	../gqcnn/tools/run_policy.py	/^                     vmin=policy_config["vis"]["vmin"],$/;"	kind:variable	line:139
vmin	../gqcnn/tools/run_policy.py	/^                     vmin=policy_config["vis"]["vmin"],$/;"	kind:variable	line:150
wait_for_state_update	../panda_autograsp/src/panda_autograsp/functions/moveit.py	/^def wait_for_state_update($/;"	kind:function	line:498
waypoints	../perception/tools/register_camera.py	/^                waypoints = []$/;"	kind:variable	line:283
webcam_corner_px	../perception/tools/register_webcam.py	/^            webcam_corner_px = corner_px \/ resize_factor$/;"	kind:variable	line:59
webcam_sensor.py	../perception/perception/webcam_sensor.py	1;"	kind:file	line:1
weight_name_to_layer_name	../gqcnn/gqcnn/utils/utils.py	/^def weight_name_to_layer_name(weight_name):$/;"	kind:function	line:160
weight_publisher.py	../perception/ros_nodes/weight_publisher.py	1;"	kind:file	line:1
weight_sensor	../perception/tools/test_weight_sensor.py	/^    weight_sensor = WeightSensor()$/;"	kind:variable	line:18
weight_sensor.py	../perception/perception/weight_sensor.py	1;"	kind:file	line:1
weights	../gqcnn/gqcnn/model/tf/network_tf.py	/^    def weights(self):$/;"	kind:member	line:632
width	../autolab_core/autolab_core/primitives.py	/^    def width(self):$/;"	kind:member	line:69
width	../autolab_core/autolab_core/tensor_dataset.py	/^    def width(self):$/;"	kind:member	line:77
width	../autolab_core/tools/convert_legacy_dataset_to_tensor_dataset.py	/^                width = data.shape[2]$/;"	kind:variable	line:51
width	../gqcnn/examples/policy_ros.py	/^                           width=gripper_width,$/;"	kind:variable	line:144
width	../perception/perception/camera_intrinsics.py	/^    def width(self):$/;"	kind:member	line:118
width	../perception/perception/detector.py	/^    def width(self):$/;"	kind:member	line:58
width	../perception/perception/image.py	/^    def width(self):$/;"	kind:member	line:173
width_px	../gqcnn/gqcnn/grasping/grasp.py	/^    def width_px(self):$/;"	kind:member	line:118
wireframe	../perception/tools/capture_dataset.py	/^                                           wireframe=False)$/;"	kind:variable	line:211
workspace	../perception/tools/capture_test_images.py	/^        workspace = Box(np.array(config['workspace']['min_pt']),$/;"	kind:variable	line:45
workspace	../perception/tools/capture_test_images.py	/^    workspace = None$/;"	kind:variable	line:43
workspace_box	../perception/tools/capture_dataset.py	/^    workspace_box = Box(np.array(workspace_config['min_pt']),$/;"	kind:variable	line:199
workspace_config	../perception/tools/capture_dataset.py	/^    workspace_config = config['workspace']$/;"	kind:variable	line:159
workspace_im	../perception/tools/capture_dataset.py	/^            workspace_im = workspace_ims[sensor_name]$/;"	kind:variable	line:309
workspace_ims	../perception/tools/capture_dataset.py	/^    workspace_ims = {}$/;"	kind:variable	line:220
workspace_objects	../perception/tools/capture_dataset.py	/^    workspace_objects = {}$/;"	kind:variable	line:204
write	../autolab_core/autolab_core/tensor_dataset.py	/^    def write(self):$/;"	kind:member	line:696
ws	../perception/perception/weight_sensor.py	/^    ws = None$/;"	kind:variable	line:129
ws	../perception/perception/weight_sensor.py	/^    ws = WeightSensor()$/;"	kind:variable	line:131
x	../autolab_core/autolab_core/points.py	/^    def x(self):$/;"	kind:member	line:236
x	../perception/tools/register_camera.py	/^                x = -float(grid_width) \/ 2 + grid_center_x + float(i * grid_width) \/ num_pts_x$/;"	kind:variable	line:104
x_axis	../autolab_core/autolab_core/rigid_transformations.py	/^    def x_axis(self):$/;"	kind:member	line:251
x_axis_rotation	../autolab_core/autolab_core/rigid_transformations.py	/^    def x_axis_rotation(theta):$/;"	kind:member	line:843
x_coords	../autolab_core/autolab_core/points.py	/^    def x_coords(self):$/;"	kind:member	line:571
x_coords	../autolab_core/autolab_core/points.py	/^    def x_coords(self):$/;"	kind:member	line:885
xend	../perception/tools/register_webcam.py	/^            xend = sx * (nx \/ 2 - ((nx + 1) % 2) \/ 2.0 + 1)$/;"	kind:variable	line:64
xstart	../perception/tools/register_webcam.py	/^            xstart = -sx * (nx \/ 2 - ((nx + 1) % 2) \/ 2.0)$/;"	kind:variable	line:63
y	../autolab_core/autolab_core/points.py	/^    def y(self):$/;"	kind:member	line:242
y	../perception/tools/register_camera.py	/^                    y = -float(grid_height) \/ 2 + grid_center_y + float(j * grid_height) \/ num_pts_y$/;"	kind:variable	line:106
y	../perception/tools/register_camera.py	/^                y = YuMiRobot(tcp=YMC.TCP_SUCTION_STIFF)$/;"	kind:variable	line:280
y	../perception/tools/register_camera.py	/^            y = YuMiRobot(tcp=YMC.TCP_SUCTION_STIFF)$/;"	kind:variable	line:120
y_axis	../autolab_core/autolab_core/rigid_transformations.py	/^    def y_axis(self):$/;"	kind:member	line:257
y_axis_rotation	../autolab_core/autolab_core/rigid_transformations.py	/^    def y_axis_rotation(theta):$/;"	kind:member	line:863
y_coords	../autolab_core/autolab_core/points.py	/^    def y_coords(self):$/;"	kind:member	line:578
y_coords	../autolab_core/autolab_core/points.py	/^    def y_coords(self):$/;"	kind:member	line:892
yaml_config.py	../autolab_core/autolab_core/yaml_config.py	1;"	kind:file	line:1
yend	../perception/tools/register_webcam.py	/^            yend = sy * (ny \/ 2 - ((ny + 1) % 2) \/ 2.0 + 1)$/;"	kind:variable	line:66
yes_or_no	../panda_autograsp/src/panda_autograsp/functions/functions.py	/^def yes_or_no(question, add_options=True):$/;"	kind:function	line:249
yesno	../perception/tools/register_camera.py	/^            yesno = raw_input('Take measurement. Hit [ENTER] when done')$/;"	kind:variable	line:334
yesno	../perception/tools/register_camera.py	/^            yesno = raw_input('Take measurement. Hit [ENTER] when done')$/;"	kind:variable	line:357
yesno	../perception/tools/register_camera.py	/^            yesno = raw_input('Take measurement. Hit [ENTER] when done')$/;"	kind:variable	line:384
ystart	../perception/tools/register_webcam.py	/^            ystart = -sy * (ny \/ 2 - ((ny + 1) % 2) \/ 2.0)$/;"	kind:variable	line:65
z	../autolab_core/autolab_core/points.py	/^    def z(self):$/;"	kind:member	line:248
z_axis	../autolab_core/autolab_core/rigid_transformations.py	/^    def z_axis(self):$/;"	kind:member	line:263
z_axis_rotation	../autolab_core/autolab_core/rigid_transformations.py	/^    def z_axis_rotation(theta):$/;"	kind:member	line:883
z_coords	../autolab_core/autolab_core/points.py	/^    def z_coords(self):$/;"	kind:member	line:585
z_coords	../autolab_core/autolab_core/points.py	/^    def z_coords(self):$/;"	kind:member	line:899
zero_pixels	../perception/perception/image.py	/^    def zero_pixels(self):$/;"	kind:member	line:828
